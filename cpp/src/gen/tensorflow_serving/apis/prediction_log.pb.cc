// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/prediction_log.proto

#include "tensorflow_serving/apis/prediction_log.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fclassification_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_ClassificationRequest_tensorflow_5fserving_2fapis_2fclassification_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fclassification_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_ClassificationResponse_tensorflow_5fserving_2fapis_2fclassification_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_ClassifyLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fcore_2flogging_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_LogMetadata_tensorflow_5fserving_2fcore_2flogging_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_MultiInferenceLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2finference_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_MultiInferenceRequest_tensorflow_5fserving_2fapis_2finference_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2finference_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<1> scc_info_MultiInferenceResponse_tensorflow_5fserving_2fapis_2finference_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_PredictLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fpredict_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_PredictRequest_tensorflow_5fserving_2fapis_2fpredict_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fpredict_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_PredictResponse_tensorflow_5fserving_2fapis_2fpredict_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_RegressLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fregression_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_RegressionRequest_tensorflow_5fserving_2fapis_2fregression_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fregression_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_RegressionResponse_tensorflow_5fserving_2fapis_2fregression_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_SessionRunLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<3> scc_info_SessionRunRequest_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto;
extern PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto ::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<3> scc_info_SessionRunResponse_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto;
namespace tensorflow {
namespace serving {
class ClassifyLogDefaultTypeInternal {
 public:
  ::PROTOBUF_NAMESPACE_ID::internal::ExplicitlyConstructed<ClassifyLog> _instance;
} _ClassifyLog_default_instance_;
class RegressLogDefaultTypeInternal {
 public:
  ::PROTOBUF_NAMESPACE_ID::internal::ExplicitlyConstructed<RegressLog> _instance;
} _RegressLog_default_instance_;
class PredictLogDefaultTypeInternal {
 public:
  ::PROTOBUF_NAMESPACE_ID::internal::ExplicitlyConstructed<PredictLog> _instance;
} _PredictLog_default_instance_;
class MultiInferenceLogDefaultTypeInternal {
 public:
  ::PROTOBUF_NAMESPACE_ID::internal::ExplicitlyConstructed<MultiInferenceLog> _instance;
} _MultiInferenceLog_default_instance_;
class SessionRunLogDefaultTypeInternal {
 public:
  ::PROTOBUF_NAMESPACE_ID::internal::ExplicitlyConstructed<SessionRunLog> _instance;
} _SessionRunLog_default_instance_;
class PredictionLogDefaultTypeInternal {
 public:
  ::PROTOBUF_NAMESPACE_ID::internal::ExplicitlyConstructed<PredictionLog> _instance;
  const ::tensorflow::serving::ClassifyLog* classify_log_;
  const ::tensorflow::serving::RegressLog* regress_log_;
  const ::tensorflow::serving::PredictLog* predict_log_;
  const ::tensorflow::serving::MultiInferenceLog* multi_inference_log_;
  const ::tensorflow::serving::SessionRunLog* session_run_log_;
} _PredictionLog_default_instance_;
}  // namespace serving
}  // namespace tensorflow
static void InitDefaultsscc_info_ClassifyLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_ClassifyLog_default_instance_;
    new (ptr) ::tensorflow::serving::ClassifyLog();
    ::PROTOBUF_NAMESPACE_ID::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::ClassifyLog::InitAsDefaultInstance();
}

::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_ClassifyLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto =
    {{ATOMIC_VAR_INIT(::PROTOBUF_NAMESPACE_ID::internal::SCCInfoBase::kUninitialized), 2, InitDefaultsscc_info_ClassifyLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto}, {
      &scc_info_ClassificationRequest_tensorflow_5fserving_2fapis_2fclassification_2eproto.base,
      &scc_info_ClassificationResponse_tensorflow_5fserving_2fapis_2fclassification_2eproto.base,}};

static void InitDefaultsscc_info_MultiInferenceLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_MultiInferenceLog_default_instance_;
    new (ptr) ::tensorflow::serving::MultiInferenceLog();
    ::PROTOBUF_NAMESPACE_ID::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::MultiInferenceLog::InitAsDefaultInstance();
}

::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_MultiInferenceLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto =
    {{ATOMIC_VAR_INIT(::PROTOBUF_NAMESPACE_ID::internal::SCCInfoBase::kUninitialized), 2, InitDefaultsscc_info_MultiInferenceLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto}, {
      &scc_info_MultiInferenceRequest_tensorflow_5fserving_2fapis_2finference_2eproto.base,
      &scc_info_MultiInferenceResponse_tensorflow_5fserving_2fapis_2finference_2eproto.base,}};

static void InitDefaultsscc_info_PredictLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_PredictLog_default_instance_;
    new (ptr) ::tensorflow::serving::PredictLog();
    ::PROTOBUF_NAMESPACE_ID::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::PredictLog::InitAsDefaultInstance();
}

::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_PredictLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto =
    {{ATOMIC_VAR_INIT(::PROTOBUF_NAMESPACE_ID::internal::SCCInfoBase::kUninitialized), 2, InitDefaultsscc_info_PredictLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto}, {
      &scc_info_PredictRequest_tensorflow_5fserving_2fapis_2fpredict_2eproto.base,
      &scc_info_PredictResponse_tensorflow_5fserving_2fapis_2fpredict_2eproto.base,}};

static void InitDefaultsscc_info_PredictionLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_PredictionLog_default_instance_;
    new (ptr) ::tensorflow::serving::PredictionLog();
    ::PROTOBUF_NAMESPACE_ID::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::PredictionLog::InitAsDefaultInstance();
}

::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<6> scc_info_PredictionLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto =
    {{ATOMIC_VAR_INIT(::PROTOBUF_NAMESPACE_ID::internal::SCCInfoBase::kUninitialized), 6, InitDefaultsscc_info_PredictionLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto}, {
      &scc_info_LogMetadata_tensorflow_5fserving_2fcore_2flogging_2eproto.base,
      &scc_info_ClassifyLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base,
      &scc_info_RegressLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base,
      &scc_info_PredictLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base,
      &scc_info_MultiInferenceLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base,
      &scc_info_SessionRunLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base,}};

static void InitDefaultsscc_info_RegressLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_RegressLog_default_instance_;
    new (ptr) ::tensorflow::serving::RegressLog();
    ::PROTOBUF_NAMESPACE_ID::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::RegressLog::InitAsDefaultInstance();
}

::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_RegressLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto =
    {{ATOMIC_VAR_INIT(::PROTOBUF_NAMESPACE_ID::internal::SCCInfoBase::kUninitialized), 2, InitDefaultsscc_info_RegressLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto}, {
      &scc_info_RegressionRequest_tensorflow_5fserving_2fapis_2fregression_2eproto.base,
      &scc_info_RegressionResponse_tensorflow_5fserving_2fapis_2fregression_2eproto.base,}};

static void InitDefaultsscc_info_SessionRunLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_SessionRunLog_default_instance_;
    new (ptr) ::tensorflow::serving::SessionRunLog();
    ::PROTOBUF_NAMESPACE_ID::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::SessionRunLog::InitAsDefaultInstance();
}

::PROTOBUF_NAMESPACE_ID::internal::SCCInfo<2> scc_info_SessionRunLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto =
    {{ATOMIC_VAR_INIT(::PROTOBUF_NAMESPACE_ID::internal::SCCInfoBase::kUninitialized), 2, InitDefaultsscc_info_SessionRunLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto}, {
      &scc_info_SessionRunRequest_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto.base,
      &scc_info_SessionRunResponse_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto.base,}};

static ::PROTOBUF_NAMESPACE_ID::Metadata file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto[6];
static constexpr ::PROTOBUF_NAMESPACE_ID::EnumDescriptor const** file_level_enum_descriptors_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto = nullptr;
static constexpr ::PROTOBUF_NAMESPACE_ID::ServiceDescriptor const** file_level_service_descriptors_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto = nullptr;

const ::PROTOBUF_NAMESPACE_ID::uint32 TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::ClassifyLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::ClassifyLog, request_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::ClassifyLog, response_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::RegressLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::RegressLog, request_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::RegressLog, response_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictLog, request_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictLog, response_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::MultiInferenceLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::MultiInferenceLog, request_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::MultiInferenceLog, response_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::SessionRunLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::SessionRunLog, request_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::SessionRunLog, response_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictionLog, _internal_metadata_),
  ~0u,  // no _extensions_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictionLog, _oneof_case_[0]),
  ~0u,  // no _weak_field_map_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictionLog, log_metadata_),
  offsetof(::tensorflow::serving::PredictionLogDefaultTypeInternal, classify_log_),
  offsetof(::tensorflow::serving::PredictionLogDefaultTypeInternal, regress_log_),
  offsetof(::tensorflow::serving::PredictionLogDefaultTypeInternal, predict_log_),
  offsetof(::tensorflow::serving::PredictionLogDefaultTypeInternal, multi_inference_log_),
  offsetof(::tensorflow::serving::PredictionLogDefaultTypeInternal, session_run_log_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictionLog, log_type_),
};
static const ::PROTOBUF_NAMESPACE_ID::internal::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, sizeof(::tensorflow::serving::ClassifyLog)},
  { 7, -1, sizeof(::tensorflow::serving::RegressLog)},
  { 14, -1, sizeof(::tensorflow::serving::PredictLog)},
  { 21, -1, sizeof(::tensorflow::serving::MultiInferenceLog)},
  { 28, -1, sizeof(::tensorflow::serving::SessionRunLog)},
  { 35, -1, sizeof(::tensorflow::serving::PredictionLog)},
};

static ::PROTOBUF_NAMESPACE_ID::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::tensorflow::serving::_ClassifyLog_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::tensorflow::serving::_RegressLog_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::tensorflow::serving::_PredictLog_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::tensorflow::serving::_MultiInferenceLog_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::tensorflow::serving::_SessionRunLog_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::tensorflow::serving::_PredictionLog_default_instance_),
};

const char descriptor_table_protodef_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto[] =
  "\n,tensorflow_serving/apis/prediction_log"
  ".proto\022\022tensorflow.serving\032,tensorflow_s"
  "erving/apis/classification.proto\032\'tensor"
  "flow_serving/apis/inference.proto\032%tenso"
  "rflow_serving/apis/predict.proto\032(tensor"
  "flow_serving/apis/regression.proto\032-tens"
  "orflow_serving/apis/session_service.prot"
  "o\032%tensorflow_serving/core/logging.proto"
  "\"\207\001\n\013ClassifyLog\022:\n\007request\030\001 \001(\0132).tens"
  "orflow.serving.ClassificationRequest\022<\n\010"
  "response\030\002 \001(\0132*.tensorflow.serving.Clas"
  "sificationResponse\"~\n\nRegressLog\0226\n\007requ"
  "est\030\001 \001(\0132%.tensorflow.serving.Regressio"
  "nRequest\0228\n\010response\030\002 \001(\0132&.tensorflow."
  "serving.RegressionResponse\"x\n\nPredictLog"
  "\0223\n\007request\030\001 \001(\0132\".tensorflow.serving.P"
  "redictRequest\0225\n\010response\030\002 \001(\0132#.tensor"
  "flow.serving.PredictResponse\"\215\001\n\021MultiIn"
  "ferenceLog\022:\n\007request\030\001 \001(\0132).tensorflow"
  ".serving.MultiInferenceRequest\022<\n\010respon"
  "se\030\002 \001(\0132*.tensorflow.serving.MultiInfer"
  "enceResponse\"\201\001\n\rSessionRunLog\0226\n\007reques"
  "t\030\001 \001(\0132%.tensorflow.serving.SessionRunR"
  "equest\0228\n\010response\030\002 \001(\0132&.tensorflow.se"
  "rving.SessionRunResponse\"\375\002\n\rPredictionL"
  "og\0225\n\014log_metadata\030\001 \001(\0132\037.tensorflow.se"
  "rving.LogMetadata\0227\n\014classify_log\030\002 \001(\0132"
  "\037.tensorflow.serving.ClassifyLogH\000\0225\n\013re"
  "gress_log\030\003 \001(\0132\036.tensorflow.serving.Reg"
  "ressLogH\000\0225\n\013predict_log\030\006 \001(\0132\036.tensorf"
  "low.serving.PredictLogH\000\022D\n\023multi_infere"
  "nce_log\030\004 \001(\0132%.tensorflow.serving.Multi"
  "InferenceLogH\000\022<\n\017session_run_log\030\005 \001(\0132"
  "!.tensorflow.serving.SessionRunLogH\000B\n\n\010"
  "log_typeB\003\370\001\001b\006proto3"
  ;
static const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable*const descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_deps[6] = {
  &::descriptor_table_tensorflow_5fserving_2fapis_2fclassification_2eproto,
  &::descriptor_table_tensorflow_5fserving_2fapis_2finference_2eproto,
  &::descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto,
  &::descriptor_table_tensorflow_5fserving_2fapis_2fregression_2eproto,
  &::descriptor_table_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto,
  &::descriptor_table_tensorflow_5fserving_2fcore_2flogging_2eproto,
};
static ::PROTOBUF_NAMESPACE_ID::internal::SCCInfoBase*const descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_sccs[6] = {
  &scc_info_ClassifyLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base,
  &scc_info_MultiInferenceLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base,
  &scc_info_PredictLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base,
  &scc_info_PredictionLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base,
  &scc_info_RegressLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base,
  &scc_info_SessionRunLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base,
};
static ::PROTOBUF_NAMESPACE_ID::internal::once_flag descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_once;
static bool descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_initialized = false;
const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto = {
  &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_initialized, descriptor_table_protodef_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto, "tensorflow_serving/apis/prediction_log.proto", 1381,
  &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_once, descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_sccs, descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_deps, 6, 6,
  schemas, file_default_instances, TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::offsets,
  file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto, 6, file_level_enum_descriptors_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto, file_level_service_descriptors_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto,
};

// Force running AddDescriptors() at dynamic initialization time.
static bool dynamic_init_dummy_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto = (  ::PROTOBUF_NAMESPACE_ID::internal::AddDescriptors(&descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto), true);
namespace tensorflow {
namespace serving {

// ===================================================================

void ClassifyLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_ClassifyLog_default_instance_._instance.get_mutable()->request_ = const_cast< ::tensorflow::serving::ClassificationRequest*>(
      ::tensorflow::serving::ClassificationRequest::internal_default_instance());
  ::tensorflow::serving::_ClassifyLog_default_instance_._instance.get_mutable()->response_ = const_cast< ::tensorflow::serving::ClassificationResponse*>(
      ::tensorflow::serving::ClassificationResponse::internal_default_instance());
}
class ClassifyLog::HasBitSetters {
 public:
  static const ::tensorflow::serving::ClassificationRequest& request(const ClassifyLog* msg);
  static const ::tensorflow::serving::ClassificationResponse& response(const ClassifyLog* msg);
};

const ::tensorflow::serving::ClassificationRequest&
ClassifyLog::HasBitSetters::request(const ClassifyLog* msg) {
  return *msg->request_;
}
const ::tensorflow::serving::ClassificationResponse&
ClassifyLog::HasBitSetters::response(const ClassifyLog* msg) {
  return *msg->response_;
}
void ClassifyLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::ClassificationRequest* request) {
  if (GetArenaNoVirtual() == nullptr) {
    delete request_;
  }
  request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ClassifyLog.request)
}
void ClassifyLog::clear_request() {
  if (GetArenaNoVirtual() == nullptr && request_ != nullptr) {
    delete request_;
  }
  request_ = nullptr;
}
void ClassifyLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::ClassificationResponse* response) {
  if (GetArenaNoVirtual() == nullptr) {
    delete response_;
  }
  response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ClassifyLog.response)
}
void ClassifyLog::clear_response() {
  if (GetArenaNoVirtual() == nullptr && response_ != nullptr) {
    delete response_;
  }
  response_ = nullptr;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ClassifyLog::kRequestFieldNumber;
const int ClassifyLog::kResponseFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ClassifyLog::ClassifyLog()
  : ::PROTOBUF_NAMESPACE_ID::Message(), _internal_metadata_(nullptr) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ClassifyLog)
}
ClassifyLog::ClassifyLog(::PROTOBUF_NAMESPACE_ID::Arena* arena)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ClassifyLog)
}
ClassifyLog::ClassifyLog(const ClassifyLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      _internal_metadata_(nullptr) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_request()) {
    request_ = new ::tensorflow::serving::ClassificationRequest(*from.request_);
  } else {
    request_ = nullptr;
  }
  if (from.has_response()) {
    response_ = new ::tensorflow::serving::ClassificationResponse(*from.response_);
  } else {
    response_ = nullptr;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ClassifyLog)
}

void ClassifyLog::SharedCtor() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&scc_info_ClassifyLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  ::memset(&request_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&response_) -
      reinterpret_cast<char*>(&request_)) + sizeof(response_));
}

ClassifyLog::~ClassifyLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ClassifyLog)
  SharedDtor();
}

void ClassifyLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == nullptr);
  if (this != internal_default_instance()) delete request_;
  if (this != internal_default_instance()) delete response_;
}

void ClassifyLog::ArenaDtor(void* object) {
  ClassifyLog* _this = reinterpret_cast< ClassifyLog* >(object);
  (void)_this;
}
void ClassifyLog::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void ClassifyLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ClassifyLog& ClassifyLog::default_instance() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&::scc_info_ClassifyLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  return *internal_default_instance();
}


void ClassifyLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ClassifyLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == nullptr && request_ != nullptr) {
    delete request_;
  }
  request_ = nullptr;
  if (GetArenaNoVirtual() == nullptr && response_ != nullptr) {
    delete response_;
  }
  response_ = nullptr;
  _internal_metadata_.Clear();
}

#if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
const char* ClassifyLog::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  ::PROTOBUF_NAMESPACE_ID::Arena* arena = GetArenaNoVirtual(); (void)arena;
  while (!ctx->Done(&ptr)) {
    ::PROTOBUF_NAMESPACE_ID::uint32 tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    CHK_(ptr);
    switch (tag >> 3) {
      // .tensorflow.serving.ClassificationRequest request = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 10)) {
          ptr = ctx->ParseMessage(mutable_request(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // .tensorflow.serving.ClassificationResponse response = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 18)) {
          ptr = ctx->ParseMessage(mutable_response(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      default: {
      handle_unusual:
        if ((tag & 7) == 4 || tag == 0) {
          ctx->SetLastTag(tag);
          goto success;
        }
        ptr = UnknownFieldParse(tag, &_internal_metadata_, ptr, ctx);
        CHK_(ptr != nullptr);
        continue;
      }
    }  // switch
  }  // while
success:
  return ptr;
failure:
  ptr = nullptr;
  goto success;
#undef CHK_
}
#else  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
bool ClassifyLog::MergePartialFromCodedStream(
    ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!PROTOBUF_PREDICT_TRUE(EXPRESSION)) goto failure
  ::PROTOBUF_NAMESPACE_ID::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ClassifyLog)
  for (;;) {
    ::std::pair<::PROTOBUF_NAMESPACE_ID::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.ClassificationRequest request = 1;
      case 1: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (10 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_request()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.ClassificationResponse response = 2;
      case 2: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (18 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_response()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ClassifyLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ClassifyLog)
  return false;
#undef DO_
}
#endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER

void ClassifyLog::SerializeWithCachedSizes(
    ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ClassifyLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.ClassificationRequest request = 1;
  if (this->has_request()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, HasBitSetters::request(this), output);
  }

  // .tensorflow.serving.ClassificationResponse response = 2;
  if (this->has_response()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, HasBitSetters::response(this), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ClassifyLog)
}

::PROTOBUF_NAMESPACE_ID::uint8* ClassifyLog::InternalSerializeWithCachedSizesToArray(
    ::PROTOBUF_NAMESPACE_ID::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ClassifyLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.ClassificationRequest request = 1;
  if (this->has_request()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, HasBitSetters::request(this), target);
  }

  // .tensorflow.serving.ClassificationResponse response = 2;
  if (this->has_response()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, HasBitSetters::response(this), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ClassifyLog)
  return target;
}

size_t ClassifyLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ClassifyLog)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.ClassificationRequest request = 1;
  if (this->has_request()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *request_);
  }

  // .tensorflow.serving.ClassificationResponse response = 2;
  if (this->has_response()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *response_);
  }

  int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void ClassifyLog::MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ClassifyLog)
  GOOGLE_DCHECK_NE(&from, this);
  const ClassifyLog* source =
      ::PROTOBUF_NAMESPACE_ID::DynamicCastToGenerated<ClassifyLog>(
          &from);
  if (source == nullptr) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ClassifyLog)
    ::PROTOBUF_NAMESPACE_ID::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ClassifyLog)
    MergeFrom(*source);
  }
}

void ClassifyLog::MergeFrom(const ClassifyLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ClassifyLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_request()) {
    mutable_request()->::tensorflow::serving::ClassificationRequest::MergeFrom(from.request());
  }
  if (from.has_response()) {
    mutable_response()->::tensorflow::serving::ClassificationResponse::MergeFrom(from.response());
  }
}

void ClassifyLog::CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ClassifyLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ClassifyLog::CopyFrom(const ClassifyLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ClassifyLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ClassifyLog::IsInitialized() const {
  return true;
}

void ClassifyLog::Swap(ClassifyLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ClassifyLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == nullptr) {
      delete temp;
    }
  }
}
void ClassifyLog::UnsafeArenaSwap(ClassifyLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ClassifyLog::InternalSwap(ClassifyLog* other) {
  using std::swap;
  _internal_metadata_.Swap(&other->_internal_metadata_);
  swap(request_, other->request_);
  swap(response_, other->response_);
}

::PROTOBUF_NAMESPACE_ID::Metadata ClassifyLog::GetMetadata() const {
  return GetMetadataStatic();
}


// ===================================================================

void RegressLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_RegressLog_default_instance_._instance.get_mutable()->request_ = const_cast< ::tensorflow::serving::RegressionRequest*>(
      ::tensorflow::serving::RegressionRequest::internal_default_instance());
  ::tensorflow::serving::_RegressLog_default_instance_._instance.get_mutable()->response_ = const_cast< ::tensorflow::serving::RegressionResponse*>(
      ::tensorflow::serving::RegressionResponse::internal_default_instance());
}
class RegressLog::HasBitSetters {
 public:
  static const ::tensorflow::serving::RegressionRequest& request(const RegressLog* msg);
  static const ::tensorflow::serving::RegressionResponse& response(const RegressLog* msg);
};

const ::tensorflow::serving::RegressionRequest&
RegressLog::HasBitSetters::request(const RegressLog* msg) {
  return *msg->request_;
}
const ::tensorflow::serving::RegressionResponse&
RegressLog::HasBitSetters::response(const RegressLog* msg) {
  return *msg->response_;
}
void RegressLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::RegressionRequest* request) {
  if (GetArenaNoVirtual() == nullptr) {
    delete request_;
  }
  request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.RegressLog.request)
}
void RegressLog::clear_request() {
  if (GetArenaNoVirtual() == nullptr && request_ != nullptr) {
    delete request_;
  }
  request_ = nullptr;
}
void RegressLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::RegressionResponse* response) {
  if (GetArenaNoVirtual() == nullptr) {
    delete response_;
  }
  response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.RegressLog.response)
}
void RegressLog::clear_response() {
  if (GetArenaNoVirtual() == nullptr && response_ != nullptr) {
    delete response_;
  }
  response_ = nullptr;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RegressLog::kRequestFieldNumber;
const int RegressLog::kResponseFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RegressLog::RegressLog()
  : ::PROTOBUF_NAMESPACE_ID::Message(), _internal_metadata_(nullptr) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.RegressLog)
}
RegressLog::RegressLog(::PROTOBUF_NAMESPACE_ID::Arena* arena)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.RegressLog)
}
RegressLog::RegressLog(const RegressLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      _internal_metadata_(nullptr) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_request()) {
    request_ = new ::tensorflow::serving::RegressionRequest(*from.request_);
  } else {
    request_ = nullptr;
  }
  if (from.has_response()) {
    response_ = new ::tensorflow::serving::RegressionResponse(*from.response_);
  } else {
    response_ = nullptr;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.RegressLog)
}

void RegressLog::SharedCtor() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&scc_info_RegressLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  ::memset(&request_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&response_) -
      reinterpret_cast<char*>(&request_)) + sizeof(response_));
}

RegressLog::~RegressLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.RegressLog)
  SharedDtor();
}

void RegressLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == nullptr);
  if (this != internal_default_instance()) delete request_;
  if (this != internal_default_instance()) delete response_;
}

void RegressLog::ArenaDtor(void* object) {
  RegressLog* _this = reinterpret_cast< RegressLog* >(object);
  (void)_this;
}
void RegressLog::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void RegressLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const RegressLog& RegressLog::default_instance() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&::scc_info_RegressLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  return *internal_default_instance();
}


void RegressLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.RegressLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == nullptr && request_ != nullptr) {
    delete request_;
  }
  request_ = nullptr;
  if (GetArenaNoVirtual() == nullptr && response_ != nullptr) {
    delete response_;
  }
  response_ = nullptr;
  _internal_metadata_.Clear();
}

#if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
const char* RegressLog::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  ::PROTOBUF_NAMESPACE_ID::Arena* arena = GetArenaNoVirtual(); (void)arena;
  while (!ctx->Done(&ptr)) {
    ::PROTOBUF_NAMESPACE_ID::uint32 tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    CHK_(ptr);
    switch (tag >> 3) {
      // .tensorflow.serving.RegressionRequest request = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 10)) {
          ptr = ctx->ParseMessage(mutable_request(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // .tensorflow.serving.RegressionResponse response = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 18)) {
          ptr = ctx->ParseMessage(mutable_response(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      default: {
      handle_unusual:
        if ((tag & 7) == 4 || tag == 0) {
          ctx->SetLastTag(tag);
          goto success;
        }
        ptr = UnknownFieldParse(tag, &_internal_metadata_, ptr, ctx);
        CHK_(ptr != nullptr);
        continue;
      }
    }  // switch
  }  // while
success:
  return ptr;
failure:
  ptr = nullptr;
  goto success;
#undef CHK_
}
#else  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
bool RegressLog::MergePartialFromCodedStream(
    ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!PROTOBUF_PREDICT_TRUE(EXPRESSION)) goto failure
  ::PROTOBUF_NAMESPACE_ID::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.RegressLog)
  for (;;) {
    ::std::pair<::PROTOBUF_NAMESPACE_ID::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.RegressionRequest request = 1;
      case 1: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (10 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_request()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.RegressionResponse response = 2;
      case 2: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (18 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_response()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.RegressLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.RegressLog)
  return false;
#undef DO_
}
#endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER

void RegressLog::SerializeWithCachedSizes(
    ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.RegressLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.RegressionRequest request = 1;
  if (this->has_request()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, HasBitSetters::request(this), output);
  }

  // .tensorflow.serving.RegressionResponse response = 2;
  if (this->has_response()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, HasBitSetters::response(this), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.RegressLog)
}

::PROTOBUF_NAMESPACE_ID::uint8* RegressLog::InternalSerializeWithCachedSizesToArray(
    ::PROTOBUF_NAMESPACE_ID::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.RegressLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.RegressionRequest request = 1;
  if (this->has_request()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, HasBitSetters::request(this), target);
  }

  // .tensorflow.serving.RegressionResponse response = 2;
  if (this->has_response()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, HasBitSetters::response(this), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.RegressLog)
  return target;
}

size_t RegressLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.RegressLog)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.RegressionRequest request = 1;
  if (this->has_request()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *request_);
  }

  // .tensorflow.serving.RegressionResponse response = 2;
  if (this->has_response()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *response_);
  }

  int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void RegressLog::MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.RegressLog)
  GOOGLE_DCHECK_NE(&from, this);
  const RegressLog* source =
      ::PROTOBUF_NAMESPACE_ID::DynamicCastToGenerated<RegressLog>(
          &from);
  if (source == nullptr) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.RegressLog)
    ::PROTOBUF_NAMESPACE_ID::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.RegressLog)
    MergeFrom(*source);
  }
}

void RegressLog::MergeFrom(const RegressLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.RegressLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_request()) {
    mutable_request()->::tensorflow::serving::RegressionRequest::MergeFrom(from.request());
  }
  if (from.has_response()) {
    mutable_response()->::tensorflow::serving::RegressionResponse::MergeFrom(from.response());
  }
}

void RegressLog::CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.RegressLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RegressLog::CopyFrom(const RegressLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.RegressLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RegressLog::IsInitialized() const {
  return true;
}

void RegressLog::Swap(RegressLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    RegressLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == nullptr) {
      delete temp;
    }
  }
}
void RegressLog::UnsafeArenaSwap(RegressLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void RegressLog::InternalSwap(RegressLog* other) {
  using std::swap;
  _internal_metadata_.Swap(&other->_internal_metadata_);
  swap(request_, other->request_);
  swap(response_, other->response_);
}

::PROTOBUF_NAMESPACE_ID::Metadata RegressLog::GetMetadata() const {
  return GetMetadataStatic();
}


// ===================================================================

void PredictLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_PredictLog_default_instance_._instance.get_mutable()->request_ = const_cast< ::tensorflow::serving::PredictRequest*>(
      ::tensorflow::serving::PredictRequest::internal_default_instance());
  ::tensorflow::serving::_PredictLog_default_instance_._instance.get_mutable()->response_ = const_cast< ::tensorflow::serving::PredictResponse*>(
      ::tensorflow::serving::PredictResponse::internal_default_instance());
}
class PredictLog::HasBitSetters {
 public:
  static const ::tensorflow::serving::PredictRequest& request(const PredictLog* msg);
  static const ::tensorflow::serving::PredictResponse& response(const PredictLog* msg);
};

const ::tensorflow::serving::PredictRequest&
PredictLog::HasBitSetters::request(const PredictLog* msg) {
  return *msg->request_;
}
const ::tensorflow::serving::PredictResponse&
PredictLog::HasBitSetters::response(const PredictLog* msg) {
  return *msg->response_;
}
void PredictLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::PredictRequest* request) {
  if (GetArenaNoVirtual() == nullptr) {
    delete request_;
  }
  request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictLog.request)
}
void PredictLog::clear_request() {
  if (GetArenaNoVirtual() == nullptr && request_ != nullptr) {
    delete request_;
  }
  request_ = nullptr;
}
void PredictLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::PredictResponse* response) {
  if (GetArenaNoVirtual() == nullptr) {
    delete response_;
  }
  response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictLog.response)
}
void PredictLog::clear_response() {
  if (GetArenaNoVirtual() == nullptr && response_ != nullptr) {
    delete response_;
  }
  response_ = nullptr;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int PredictLog::kRequestFieldNumber;
const int PredictLog::kResponseFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

PredictLog::PredictLog()
  : ::PROTOBUF_NAMESPACE_ID::Message(), _internal_metadata_(nullptr) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.PredictLog)
}
PredictLog::PredictLog(::PROTOBUF_NAMESPACE_ID::Arena* arena)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.PredictLog)
}
PredictLog::PredictLog(const PredictLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      _internal_metadata_(nullptr) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_request()) {
    request_ = new ::tensorflow::serving::PredictRequest(*from.request_);
  } else {
    request_ = nullptr;
  }
  if (from.has_response()) {
    response_ = new ::tensorflow::serving::PredictResponse(*from.response_);
  } else {
    response_ = nullptr;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.PredictLog)
}

void PredictLog::SharedCtor() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&scc_info_PredictLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  ::memset(&request_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&response_) -
      reinterpret_cast<char*>(&request_)) + sizeof(response_));
}

PredictLog::~PredictLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.PredictLog)
  SharedDtor();
}

void PredictLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == nullptr);
  if (this != internal_default_instance()) delete request_;
  if (this != internal_default_instance()) delete response_;
}

void PredictLog::ArenaDtor(void* object) {
  PredictLog* _this = reinterpret_cast< PredictLog* >(object);
  (void)_this;
}
void PredictLog::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void PredictLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const PredictLog& PredictLog::default_instance() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&::scc_info_PredictLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  return *internal_default_instance();
}


void PredictLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.PredictLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == nullptr && request_ != nullptr) {
    delete request_;
  }
  request_ = nullptr;
  if (GetArenaNoVirtual() == nullptr && response_ != nullptr) {
    delete response_;
  }
  response_ = nullptr;
  _internal_metadata_.Clear();
}

#if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
const char* PredictLog::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  ::PROTOBUF_NAMESPACE_ID::Arena* arena = GetArenaNoVirtual(); (void)arena;
  while (!ctx->Done(&ptr)) {
    ::PROTOBUF_NAMESPACE_ID::uint32 tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    CHK_(ptr);
    switch (tag >> 3) {
      // .tensorflow.serving.PredictRequest request = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 10)) {
          ptr = ctx->ParseMessage(mutable_request(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // .tensorflow.serving.PredictResponse response = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 18)) {
          ptr = ctx->ParseMessage(mutable_response(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      default: {
      handle_unusual:
        if ((tag & 7) == 4 || tag == 0) {
          ctx->SetLastTag(tag);
          goto success;
        }
        ptr = UnknownFieldParse(tag, &_internal_metadata_, ptr, ctx);
        CHK_(ptr != nullptr);
        continue;
      }
    }  // switch
  }  // while
success:
  return ptr;
failure:
  ptr = nullptr;
  goto success;
#undef CHK_
}
#else  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
bool PredictLog::MergePartialFromCodedStream(
    ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!PROTOBUF_PREDICT_TRUE(EXPRESSION)) goto failure
  ::PROTOBUF_NAMESPACE_ID::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.PredictLog)
  for (;;) {
    ::std::pair<::PROTOBUF_NAMESPACE_ID::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.PredictRequest request = 1;
      case 1: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (10 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_request()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.PredictResponse response = 2;
      case 2: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (18 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_response()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.PredictLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.PredictLog)
  return false;
#undef DO_
}
#endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER

void PredictLog::SerializeWithCachedSizes(
    ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.PredictLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.PredictRequest request = 1;
  if (this->has_request()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, HasBitSetters::request(this), output);
  }

  // .tensorflow.serving.PredictResponse response = 2;
  if (this->has_response()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, HasBitSetters::response(this), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.PredictLog)
}

::PROTOBUF_NAMESPACE_ID::uint8* PredictLog::InternalSerializeWithCachedSizesToArray(
    ::PROTOBUF_NAMESPACE_ID::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.PredictLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.PredictRequest request = 1;
  if (this->has_request()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, HasBitSetters::request(this), target);
  }

  // .tensorflow.serving.PredictResponse response = 2;
  if (this->has_response()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, HasBitSetters::response(this), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.PredictLog)
  return target;
}

size_t PredictLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.PredictLog)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.PredictRequest request = 1;
  if (this->has_request()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *request_);
  }

  // .tensorflow.serving.PredictResponse response = 2;
  if (this->has_response()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *response_);
  }

  int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void PredictLog::MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.PredictLog)
  GOOGLE_DCHECK_NE(&from, this);
  const PredictLog* source =
      ::PROTOBUF_NAMESPACE_ID::DynamicCastToGenerated<PredictLog>(
          &from);
  if (source == nullptr) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.PredictLog)
    ::PROTOBUF_NAMESPACE_ID::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.PredictLog)
    MergeFrom(*source);
  }
}

void PredictLog::MergeFrom(const PredictLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.PredictLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_request()) {
    mutable_request()->::tensorflow::serving::PredictRequest::MergeFrom(from.request());
  }
  if (from.has_response()) {
    mutable_response()->::tensorflow::serving::PredictResponse::MergeFrom(from.response());
  }
}

void PredictLog::CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.PredictLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void PredictLog::CopyFrom(const PredictLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.PredictLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool PredictLog::IsInitialized() const {
  return true;
}

void PredictLog::Swap(PredictLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    PredictLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == nullptr) {
      delete temp;
    }
  }
}
void PredictLog::UnsafeArenaSwap(PredictLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void PredictLog::InternalSwap(PredictLog* other) {
  using std::swap;
  _internal_metadata_.Swap(&other->_internal_metadata_);
  swap(request_, other->request_);
  swap(response_, other->response_);
}

::PROTOBUF_NAMESPACE_ID::Metadata PredictLog::GetMetadata() const {
  return GetMetadataStatic();
}


// ===================================================================

void MultiInferenceLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_MultiInferenceLog_default_instance_._instance.get_mutable()->request_ = const_cast< ::tensorflow::serving::MultiInferenceRequest*>(
      ::tensorflow::serving::MultiInferenceRequest::internal_default_instance());
  ::tensorflow::serving::_MultiInferenceLog_default_instance_._instance.get_mutable()->response_ = const_cast< ::tensorflow::serving::MultiInferenceResponse*>(
      ::tensorflow::serving::MultiInferenceResponse::internal_default_instance());
}
class MultiInferenceLog::HasBitSetters {
 public:
  static const ::tensorflow::serving::MultiInferenceRequest& request(const MultiInferenceLog* msg);
  static const ::tensorflow::serving::MultiInferenceResponse& response(const MultiInferenceLog* msg);
};

const ::tensorflow::serving::MultiInferenceRequest&
MultiInferenceLog::HasBitSetters::request(const MultiInferenceLog* msg) {
  return *msg->request_;
}
const ::tensorflow::serving::MultiInferenceResponse&
MultiInferenceLog::HasBitSetters::response(const MultiInferenceLog* msg) {
  return *msg->response_;
}
void MultiInferenceLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::MultiInferenceRequest* request) {
  if (GetArenaNoVirtual() == nullptr) {
    delete request_;
  }
  request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.MultiInferenceLog.request)
}
void MultiInferenceLog::clear_request() {
  if (GetArenaNoVirtual() == nullptr && request_ != nullptr) {
    delete request_;
  }
  request_ = nullptr;
}
void MultiInferenceLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::MultiInferenceResponse* response) {
  if (GetArenaNoVirtual() == nullptr) {
    delete response_;
  }
  response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.MultiInferenceLog.response)
}
void MultiInferenceLog::clear_response() {
  if (GetArenaNoVirtual() == nullptr && response_ != nullptr) {
    delete response_;
  }
  response_ = nullptr;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int MultiInferenceLog::kRequestFieldNumber;
const int MultiInferenceLog::kResponseFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

MultiInferenceLog::MultiInferenceLog()
  : ::PROTOBUF_NAMESPACE_ID::Message(), _internal_metadata_(nullptr) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.MultiInferenceLog)
}
MultiInferenceLog::MultiInferenceLog(::PROTOBUF_NAMESPACE_ID::Arena* arena)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.MultiInferenceLog)
}
MultiInferenceLog::MultiInferenceLog(const MultiInferenceLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      _internal_metadata_(nullptr) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_request()) {
    request_ = new ::tensorflow::serving::MultiInferenceRequest(*from.request_);
  } else {
    request_ = nullptr;
  }
  if (from.has_response()) {
    response_ = new ::tensorflow::serving::MultiInferenceResponse(*from.response_);
  } else {
    response_ = nullptr;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.MultiInferenceLog)
}

void MultiInferenceLog::SharedCtor() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&scc_info_MultiInferenceLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  ::memset(&request_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&response_) -
      reinterpret_cast<char*>(&request_)) + sizeof(response_));
}

MultiInferenceLog::~MultiInferenceLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.MultiInferenceLog)
  SharedDtor();
}

void MultiInferenceLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == nullptr);
  if (this != internal_default_instance()) delete request_;
  if (this != internal_default_instance()) delete response_;
}

void MultiInferenceLog::ArenaDtor(void* object) {
  MultiInferenceLog* _this = reinterpret_cast< MultiInferenceLog* >(object);
  (void)_this;
}
void MultiInferenceLog::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void MultiInferenceLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const MultiInferenceLog& MultiInferenceLog::default_instance() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&::scc_info_MultiInferenceLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  return *internal_default_instance();
}


void MultiInferenceLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.MultiInferenceLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == nullptr && request_ != nullptr) {
    delete request_;
  }
  request_ = nullptr;
  if (GetArenaNoVirtual() == nullptr && response_ != nullptr) {
    delete response_;
  }
  response_ = nullptr;
  _internal_metadata_.Clear();
}

#if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
const char* MultiInferenceLog::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  ::PROTOBUF_NAMESPACE_ID::Arena* arena = GetArenaNoVirtual(); (void)arena;
  while (!ctx->Done(&ptr)) {
    ::PROTOBUF_NAMESPACE_ID::uint32 tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    CHK_(ptr);
    switch (tag >> 3) {
      // .tensorflow.serving.MultiInferenceRequest request = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 10)) {
          ptr = ctx->ParseMessage(mutable_request(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // .tensorflow.serving.MultiInferenceResponse response = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 18)) {
          ptr = ctx->ParseMessage(mutable_response(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      default: {
      handle_unusual:
        if ((tag & 7) == 4 || tag == 0) {
          ctx->SetLastTag(tag);
          goto success;
        }
        ptr = UnknownFieldParse(tag, &_internal_metadata_, ptr, ctx);
        CHK_(ptr != nullptr);
        continue;
      }
    }  // switch
  }  // while
success:
  return ptr;
failure:
  ptr = nullptr;
  goto success;
#undef CHK_
}
#else  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
bool MultiInferenceLog::MergePartialFromCodedStream(
    ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!PROTOBUF_PREDICT_TRUE(EXPRESSION)) goto failure
  ::PROTOBUF_NAMESPACE_ID::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.MultiInferenceLog)
  for (;;) {
    ::std::pair<::PROTOBUF_NAMESPACE_ID::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.MultiInferenceRequest request = 1;
      case 1: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (10 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_request()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.MultiInferenceResponse response = 2;
      case 2: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (18 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_response()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.MultiInferenceLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.MultiInferenceLog)
  return false;
#undef DO_
}
#endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER

void MultiInferenceLog::SerializeWithCachedSizes(
    ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.MultiInferenceLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.MultiInferenceRequest request = 1;
  if (this->has_request()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, HasBitSetters::request(this), output);
  }

  // .tensorflow.serving.MultiInferenceResponse response = 2;
  if (this->has_response()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, HasBitSetters::response(this), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.MultiInferenceLog)
}

::PROTOBUF_NAMESPACE_ID::uint8* MultiInferenceLog::InternalSerializeWithCachedSizesToArray(
    ::PROTOBUF_NAMESPACE_ID::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.MultiInferenceLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.MultiInferenceRequest request = 1;
  if (this->has_request()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, HasBitSetters::request(this), target);
  }

  // .tensorflow.serving.MultiInferenceResponse response = 2;
  if (this->has_response()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, HasBitSetters::response(this), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.MultiInferenceLog)
  return target;
}

size_t MultiInferenceLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.MultiInferenceLog)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.MultiInferenceRequest request = 1;
  if (this->has_request()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *request_);
  }

  // .tensorflow.serving.MultiInferenceResponse response = 2;
  if (this->has_response()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *response_);
  }

  int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void MultiInferenceLog::MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.MultiInferenceLog)
  GOOGLE_DCHECK_NE(&from, this);
  const MultiInferenceLog* source =
      ::PROTOBUF_NAMESPACE_ID::DynamicCastToGenerated<MultiInferenceLog>(
          &from);
  if (source == nullptr) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.MultiInferenceLog)
    ::PROTOBUF_NAMESPACE_ID::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.MultiInferenceLog)
    MergeFrom(*source);
  }
}

void MultiInferenceLog::MergeFrom(const MultiInferenceLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.MultiInferenceLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_request()) {
    mutable_request()->::tensorflow::serving::MultiInferenceRequest::MergeFrom(from.request());
  }
  if (from.has_response()) {
    mutable_response()->::tensorflow::serving::MultiInferenceResponse::MergeFrom(from.response());
  }
}

void MultiInferenceLog::CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.MultiInferenceLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void MultiInferenceLog::CopyFrom(const MultiInferenceLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.MultiInferenceLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool MultiInferenceLog::IsInitialized() const {
  return true;
}

void MultiInferenceLog::Swap(MultiInferenceLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    MultiInferenceLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == nullptr) {
      delete temp;
    }
  }
}
void MultiInferenceLog::UnsafeArenaSwap(MultiInferenceLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void MultiInferenceLog::InternalSwap(MultiInferenceLog* other) {
  using std::swap;
  _internal_metadata_.Swap(&other->_internal_metadata_);
  swap(request_, other->request_);
  swap(response_, other->response_);
}

::PROTOBUF_NAMESPACE_ID::Metadata MultiInferenceLog::GetMetadata() const {
  return GetMetadataStatic();
}


// ===================================================================

void SessionRunLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_SessionRunLog_default_instance_._instance.get_mutable()->request_ = const_cast< ::tensorflow::serving::SessionRunRequest*>(
      ::tensorflow::serving::SessionRunRequest::internal_default_instance());
  ::tensorflow::serving::_SessionRunLog_default_instance_._instance.get_mutable()->response_ = const_cast< ::tensorflow::serving::SessionRunResponse*>(
      ::tensorflow::serving::SessionRunResponse::internal_default_instance());
}
class SessionRunLog::HasBitSetters {
 public:
  static const ::tensorflow::serving::SessionRunRequest& request(const SessionRunLog* msg);
  static const ::tensorflow::serving::SessionRunResponse& response(const SessionRunLog* msg);
};

const ::tensorflow::serving::SessionRunRequest&
SessionRunLog::HasBitSetters::request(const SessionRunLog* msg) {
  return *msg->request_;
}
const ::tensorflow::serving::SessionRunResponse&
SessionRunLog::HasBitSetters::response(const SessionRunLog* msg) {
  return *msg->response_;
}
void SessionRunLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::SessionRunRequest* request) {
  if (GetArenaNoVirtual() == nullptr) {
    delete request_;
  }
  request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunLog.request)
}
void SessionRunLog::clear_request() {
  if (GetArenaNoVirtual() == nullptr && request_ != nullptr) {
    delete request_;
  }
  request_ = nullptr;
}
void SessionRunLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::SessionRunResponse* response) {
  if (GetArenaNoVirtual() == nullptr) {
    delete response_;
  }
  response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunLog.response)
}
void SessionRunLog::clear_response() {
  if (GetArenaNoVirtual() == nullptr && response_ != nullptr) {
    delete response_;
  }
  response_ = nullptr;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SessionRunLog::kRequestFieldNumber;
const int SessionRunLog::kResponseFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SessionRunLog::SessionRunLog()
  : ::PROTOBUF_NAMESPACE_ID::Message(), _internal_metadata_(nullptr) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.SessionRunLog)
}
SessionRunLog::SessionRunLog(::PROTOBUF_NAMESPACE_ID::Arena* arena)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.SessionRunLog)
}
SessionRunLog::SessionRunLog(const SessionRunLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      _internal_metadata_(nullptr) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_request()) {
    request_ = new ::tensorflow::serving::SessionRunRequest(*from.request_);
  } else {
    request_ = nullptr;
  }
  if (from.has_response()) {
    response_ = new ::tensorflow::serving::SessionRunResponse(*from.response_);
  } else {
    response_ = nullptr;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.SessionRunLog)
}

void SessionRunLog::SharedCtor() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&scc_info_SessionRunLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  ::memset(&request_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&response_) -
      reinterpret_cast<char*>(&request_)) + sizeof(response_));
}

SessionRunLog::~SessionRunLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.SessionRunLog)
  SharedDtor();
}

void SessionRunLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == nullptr);
  if (this != internal_default_instance()) delete request_;
  if (this != internal_default_instance()) delete response_;
}

void SessionRunLog::ArenaDtor(void* object) {
  SessionRunLog* _this = reinterpret_cast< SessionRunLog* >(object);
  (void)_this;
}
void SessionRunLog::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void SessionRunLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const SessionRunLog& SessionRunLog::default_instance() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&::scc_info_SessionRunLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  return *internal_default_instance();
}


void SessionRunLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.SessionRunLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == nullptr && request_ != nullptr) {
    delete request_;
  }
  request_ = nullptr;
  if (GetArenaNoVirtual() == nullptr && response_ != nullptr) {
    delete response_;
  }
  response_ = nullptr;
  _internal_metadata_.Clear();
}

#if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
const char* SessionRunLog::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  ::PROTOBUF_NAMESPACE_ID::Arena* arena = GetArenaNoVirtual(); (void)arena;
  while (!ctx->Done(&ptr)) {
    ::PROTOBUF_NAMESPACE_ID::uint32 tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    CHK_(ptr);
    switch (tag >> 3) {
      // .tensorflow.serving.SessionRunRequest request = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 10)) {
          ptr = ctx->ParseMessage(mutable_request(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // .tensorflow.serving.SessionRunResponse response = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 18)) {
          ptr = ctx->ParseMessage(mutable_response(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      default: {
      handle_unusual:
        if ((tag & 7) == 4 || tag == 0) {
          ctx->SetLastTag(tag);
          goto success;
        }
        ptr = UnknownFieldParse(tag, &_internal_metadata_, ptr, ctx);
        CHK_(ptr != nullptr);
        continue;
      }
    }  // switch
  }  // while
success:
  return ptr;
failure:
  ptr = nullptr;
  goto success;
#undef CHK_
}
#else  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
bool SessionRunLog::MergePartialFromCodedStream(
    ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!PROTOBUF_PREDICT_TRUE(EXPRESSION)) goto failure
  ::PROTOBUF_NAMESPACE_ID::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.SessionRunLog)
  for (;;) {
    ::std::pair<::PROTOBUF_NAMESPACE_ID::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.SessionRunRequest request = 1;
      case 1: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (10 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_request()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.SessionRunResponse response = 2;
      case 2: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (18 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_response()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.SessionRunLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.SessionRunLog)
  return false;
#undef DO_
}
#endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER

void SessionRunLog::SerializeWithCachedSizes(
    ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.SessionRunLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.SessionRunRequest request = 1;
  if (this->has_request()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, HasBitSetters::request(this), output);
  }

  // .tensorflow.serving.SessionRunResponse response = 2;
  if (this->has_response()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, HasBitSetters::response(this), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.SessionRunLog)
}

::PROTOBUF_NAMESPACE_ID::uint8* SessionRunLog::InternalSerializeWithCachedSizesToArray(
    ::PROTOBUF_NAMESPACE_ID::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.SessionRunLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.SessionRunRequest request = 1;
  if (this->has_request()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, HasBitSetters::request(this), target);
  }

  // .tensorflow.serving.SessionRunResponse response = 2;
  if (this->has_response()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, HasBitSetters::response(this), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.SessionRunLog)
  return target;
}

size_t SessionRunLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.SessionRunLog)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.SessionRunRequest request = 1;
  if (this->has_request()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *request_);
  }

  // .tensorflow.serving.SessionRunResponse response = 2;
  if (this->has_response()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *response_);
  }

  int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void SessionRunLog::MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.SessionRunLog)
  GOOGLE_DCHECK_NE(&from, this);
  const SessionRunLog* source =
      ::PROTOBUF_NAMESPACE_ID::DynamicCastToGenerated<SessionRunLog>(
          &from);
  if (source == nullptr) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.SessionRunLog)
    ::PROTOBUF_NAMESPACE_ID::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.SessionRunLog)
    MergeFrom(*source);
  }
}

void SessionRunLog::MergeFrom(const SessionRunLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.SessionRunLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_request()) {
    mutable_request()->::tensorflow::serving::SessionRunRequest::MergeFrom(from.request());
  }
  if (from.has_response()) {
    mutable_response()->::tensorflow::serving::SessionRunResponse::MergeFrom(from.response());
  }
}

void SessionRunLog::CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.SessionRunLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SessionRunLog::CopyFrom(const SessionRunLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.SessionRunLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SessionRunLog::IsInitialized() const {
  return true;
}

void SessionRunLog::Swap(SessionRunLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    SessionRunLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == nullptr) {
      delete temp;
    }
  }
}
void SessionRunLog::UnsafeArenaSwap(SessionRunLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void SessionRunLog::InternalSwap(SessionRunLog* other) {
  using std::swap;
  _internal_metadata_.Swap(&other->_internal_metadata_);
  swap(request_, other->request_);
  swap(response_, other->response_);
}

::PROTOBUF_NAMESPACE_ID::Metadata SessionRunLog::GetMetadata() const {
  return GetMetadataStatic();
}


// ===================================================================

void PredictionLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_PredictionLog_default_instance_._instance.get_mutable()->log_metadata_ = const_cast< ::tensorflow::serving::LogMetadata*>(
      ::tensorflow::serving::LogMetadata::internal_default_instance());
  ::tensorflow::serving::_PredictionLog_default_instance_.classify_log_ = const_cast< ::tensorflow::serving::ClassifyLog*>(
      ::tensorflow::serving::ClassifyLog::internal_default_instance());
  ::tensorflow::serving::_PredictionLog_default_instance_.regress_log_ = const_cast< ::tensorflow::serving::RegressLog*>(
      ::tensorflow::serving::RegressLog::internal_default_instance());
  ::tensorflow::serving::_PredictionLog_default_instance_.predict_log_ = const_cast< ::tensorflow::serving::PredictLog*>(
      ::tensorflow::serving::PredictLog::internal_default_instance());
  ::tensorflow::serving::_PredictionLog_default_instance_.multi_inference_log_ = const_cast< ::tensorflow::serving::MultiInferenceLog*>(
      ::tensorflow::serving::MultiInferenceLog::internal_default_instance());
  ::tensorflow::serving::_PredictionLog_default_instance_.session_run_log_ = const_cast< ::tensorflow::serving::SessionRunLog*>(
      ::tensorflow::serving::SessionRunLog::internal_default_instance());
}
class PredictionLog::HasBitSetters {
 public:
  static const ::tensorflow::serving::LogMetadata& log_metadata(const PredictionLog* msg);
  static const ::tensorflow::serving::ClassifyLog& classify_log(const PredictionLog* msg);
  static const ::tensorflow::serving::RegressLog& regress_log(const PredictionLog* msg);
  static const ::tensorflow::serving::PredictLog& predict_log(const PredictionLog* msg);
  static const ::tensorflow::serving::MultiInferenceLog& multi_inference_log(const PredictionLog* msg);
  static const ::tensorflow::serving::SessionRunLog& session_run_log(const PredictionLog* msg);
};

const ::tensorflow::serving::LogMetadata&
PredictionLog::HasBitSetters::log_metadata(const PredictionLog* msg) {
  return *msg->log_metadata_;
}
const ::tensorflow::serving::ClassifyLog&
PredictionLog::HasBitSetters::classify_log(const PredictionLog* msg) {
  return *msg->log_type_.classify_log_;
}
const ::tensorflow::serving::RegressLog&
PredictionLog::HasBitSetters::regress_log(const PredictionLog* msg) {
  return *msg->log_type_.regress_log_;
}
const ::tensorflow::serving::PredictLog&
PredictionLog::HasBitSetters::predict_log(const PredictionLog* msg) {
  return *msg->log_type_.predict_log_;
}
const ::tensorflow::serving::MultiInferenceLog&
PredictionLog::HasBitSetters::multi_inference_log(const PredictionLog* msg) {
  return *msg->log_type_.multi_inference_log_;
}
const ::tensorflow::serving::SessionRunLog&
PredictionLog::HasBitSetters::session_run_log(const PredictionLog* msg) {
  return *msg->log_type_.session_run_log_;
}
void PredictionLog::unsafe_arena_set_allocated_log_metadata(
    ::tensorflow::serving::LogMetadata* log_metadata) {
  if (GetArenaNoVirtual() == nullptr) {
    delete log_metadata_;
  }
  log_metadata_ = log_metadata;
  if (log_metadata) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.log_metadata)
}
void PredictionLog::clear_log_metadata() {
  if (GetArenaNoVirtual() == nullptr && log_metadata_ != nullptr) {
    delete log_metadata_;
  }
  log_metadata_ = nullptr;
}
void PredictionLog::set_allocated_classify_log(::tensorflow::serving::ClassifyLog* classify_log) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaNoVirtual();
  clear_log_type();
  if (classify_log) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::GetArena(classify_log);
    if (message_arena != submessage_arena) {
      classify_log = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, classify_log, submessage_arena);
    }
    set_has_classify_log();
    log_type_.classify_log_ = classify_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.classify_log)
}
void PredictionLog::set_allocated_regress_log(::tensorflow::serving::RegressLog* regress_log) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaNoVirtual();
  clear_log_type();
  if (regress_log) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::GetArena(regress_log);
    if (message_arena != submessage_arena) {
      regress_log = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, regress_log, submessage_arena);
    }
    set_has_regress_log();
    log_type_.regress_log_ = regress_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.regress_log)
}
void PredictionLog::set_allocated_predict_log(::tensorflow::serving::PredictLog* predict_log) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaNoVirtual();
  clear_log_type();
  if (predict_log) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::GetArena(predict_log);
    if (message_arena != submessage_arena) {
      predict_log = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, predict_log, submessage_arena);
    }
    set_has_predict_log();
    log_type_.predict_log_ = predict_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.predict_log)
}
void PredictionLog::set_allocated_multi_inference_log(::tensorflow::serving::MultiInferenceLog* multi_inference_log) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaNoVirtual();
  clear_log_type();
  if (multi_inference_log) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::GetArena(multi_inference_log);
    if (message_arena != submessage_arena) {
      multi_inference_log = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, multi_inference_log, submessage_arena);
    }
    set_has_multi_inference_log();
    log_type_.multi_inference_log_ = multi_inference_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.multi_inference_log)
}
void PredictionLog::set_allocated_session_run_log(::tensorflow::serving::SessionRunLog* session_run_log) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaNoVirtual();
  clear_log_type();
  if (session_run_log) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::GetArena(session_run_log);
    if (message_arena != submessage_arena) {
      session_run_log = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, session_run_log, submessage_arena);
    }
    set_has_session_run_log();
    log_type_.session_run_log_ = session_run_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.session_run_log)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int PredictionLog::kLogMetadataFieldNumber;
const int PredictionLog::kClassifyLogFieldNumber;
const int PredictionLog::kRegressLogFieldNumber;
const int PredictionLog::kPredictLogFieldNumber;
const int PredictionLog::kMultiInferenceLogFieldNumber;
const int PredictionLog::kSessionRunLogFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

PredictionLog::PredictionLog()
  : ::PROTOBUF_NAMESPACE_ID::Message(), _internal_metadata_(nullptr) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.PredictionLog)
}
PredictionLog::PredictionLog(::PROTOBUF_NAMESPACE_ID::Arena* arena)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.PredictionLog)
}
PredictionLog::PredictionLog(const PredictionLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      _internal_metadata_(nullptr) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_log_metadata()) {
    log_metadata_ = new ::tensorflow::serving::LogMetadata(*from.log_metadata_);
  } else {
    log_metadata_ = nullptr;
  }
  clear_has_log_type();
  switch (from.log_type_case()) {
    case kClassifyLog: {
      mutable_classify_log()->::tensorflow::serving::ClassifyLog::MergeFrom(from.classify_log());
      break;
    }
    case kRegressLog: {
      mutable_regress_log()->::tensorflow::serving::RegressLog::MergeFrom(from.regress_log());
      break;
    }
    case kPredictLog: {
      mutable_predict_log()->::tensorflow::serving::PredictLog::MergeFrom(from.predict_log());
      break;
    }
    case kMultiInferenceLog: {
      mutable_multi_inference_log()->::tensorflow::serving::MultiInferenceLog::MergeFrom(from.multi_inference_log());
      break;
    }
    case kSessionRunLog: {
      mutable_session_run_log()->::tensorflow::serving::SessionRunLog::MergeFrom(from.session_run_log());
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.PredictionLog)
}

void PredictionLog::SharedCtor() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&scc_info_PredictionLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  log_metadata_ = nullptr;
  clear_has_log_type();
}

PredictionLog::~PredictionLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.PredictionLog)
  SharedDtor();
}

void PredictionLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == nullptr);
  if (this != internal_default_instance()) delete log_metadata_;
  if (has_log_type()) {
    clear_log_type();
  }
}

void PredictionLog::ArenaDtor(void* object) {
  PredictionLog* _this = reinterpret_cast< PredictionLog* >(object);
  (void)_this;
}
void PredictionLog::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void PredictionLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const PredictionLog& PredictionLog::default_instance() {
  ::PROTOBUF_NAMESPACE_ID::internal::InitSCC(&::scc_info_PredictionLog_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto.base);
  return *internal_default_instance();
}


void PredictionLog::clear_log_type() {
// @@protoc_insertion_point(one_of_clear_start:tensorflow.serving.PredictionLog)
  switch (log_type_case()) {
    case kClassifyLog: {
      if (GetArenaNoVirtual() == nullptr) {
        delete log_type_.classify_log_;
      }
      break;
    }
    case kRegressLog: {
      if (GetArenaNoVirtual() == nullptr) {
        delete log_type_.regress_log_;
      }
      break;
    }
    case kPredictLog: {
      if (GetArenaNoVirtual() == nullptr) {
        delete log_type_.predict_log_;
      }
      break;
    }
    case kMultiInferenceLog: {
      if (GetArenaNoVirtual() == nullptr) {
        delete log_type_.multi_inference_log_;
      }
      break;
    }
    case kSessionRunLog: {
      if (GetArenaNoVirtual() == nullptr) {
        delete log_type_.session_run_log_;
      }
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = LOG_TYPE_NOT_SET;
}


void PredictionLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.PredictionLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == nullptr && log_metadata_ != nullptr) {
    delete log_metadata_;
  }
  log_metadata_ = nullptr;
  clear_log_type();
  _internal_metadata_.Clear();
}

#if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
const char* PredictionLog::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  ::PROTOBUF_NAMESPACE_ID::Arena* arena = GetArenaNoVirtual(); (void)arena;
  while (!ctx->Done(&ptr)) {
    ::PROTOBUF_NAMESPACE_ID::uint32 tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    CHK_(ptr);
    switch (tag >> 3) {
      // .tensorflow.serving.LogMetadata log_metadata = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 10)) {
          ptr = ctx->ParseMessage(mutable_log_metadata(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // .tensorflow.serving.ClassifyLog classify_log = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 18)) {
          ptr = ctx->ParseMessage(mutable_classify_log(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // .tensorflow.serving.RegressLog regress_log = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 26)) {
          ptr = ctx->ParseMessage(mutable_regress_log(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 34)) {
          ptr = ctx->ParseMessage(mutable_multi_inference_log(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // .tensorflow.serving.SessionRunLog session_run_log = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 42)) {
          ptr = ctx->ParseMessage(mutable_session_run_log(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      // .tensorflow.serving.PredictLog predict_log = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<::PROTOBUF_NAMESPACE_ID::uint8>(tag) == 50)) {
          ptr = ctx->ParseMessage(mutable_predict_log(), ptr);
          CHK_(ptr);
        } else goto handle_unusual;
        continue;
      default: {
      handle_unusual:
        if ((tag & 7) == 4 || tag == 0) {
          ctx->SetLastTag(tag);
          goto success;
        }
        ptr = UnknownFieldParse(tag, &_internal_metadata_, ptr, ctx);
        CHK_(ptr != nullptr);
        continue;
      }
    }  // switch
  }  // while
success:
  return ptr;
failure:
  ptr = nullptr;
  goto success;
#undef CHK_
}
#else  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
bool PredictionLog::MergePartialFromCodedStream(
    ::PROTOBUF_NAMESPACE_ID::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!PROTOBUF_PREDICT_TRUE(EXPRESSION)) goto failure
  ::PROTOBUF_NAMESPACE_ID::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.PredictionLog)
  for (;;) {
    ::std::pair<::PROTOBUF_NAMESPACE_ID::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.LogMetadata log_metadata = 1;
      case 1: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (10 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_log_metadata()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.ClassifyLog classify_log = 2;
      case 2: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (18 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_classify_log()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.RegressLog regress_log = 3;
      case 3: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (26 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_regress_log()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
      case 4: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (34 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_multi_inference_log()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.SessionRunLog session_run_log = 5;
      case 5: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (42 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_session_run_log()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.PredictLog predict_log = 6;
      case 6: {
        if (static_cast< ::PROTOBUF_NAMESPACE_ID::uint8>(tag) == (50 & 0xFF)) {
          DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::ReadMessage(
               input, mutable_predict_log()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.PredictionLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.PredictionLog)
  return false;
#undef DO_
}
#endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER

void PredictionLog::SerializeWithCachedSizes(
    ::PROTOBUF_NAMESPACE_ID::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.PredictionLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.LogMetadata log_metadata = 1;
  if (this->has_log_metadata()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, HasBitSetters::log_metadata(this), output);
  }

  // .tensorflow.serving.ClassifyLog classify_log = 2;
  if (has_classify_log()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, HasBitSetters::classify_log(this), output);
  }

  // .tensorflow.serving.RegressLog regress_log = 3;
  if (has_regress_log()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, HasBitSetters::regress_log(this), output);
  }

  // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
  if (has_multi_inference_log()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, HasBitSetters::multi_inference_log(this), output);
  }

  // .tensorflow.serving.SessionRunLog session_run_log = 5;
  if (has_session_run_log()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      5, HasBitSetters::session_run_log(this), output);
  }

  // .tensorflow.serving.PredictLog predict_log = 6;
  if (has_predict_log()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteMessageMaybeToArray(
      6, HasBitSetters::predict_log(this), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.PredictionLog)
}

::PROTOBUF_NAMESPACE_ID::uint8* PredictionLog::InternalSerializeWithCachedSizesToArray(
    ::PROTOBUF_NAMESPACE_ID::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.PredictionLog)
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.LogMetadata log_metadata = 1;
  if (this->has_log_metadata()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, HasBitSetters::log_metadata(this), target);
  }

  // .tensorflow.serving.ClassifyLog classify_log = 2;
  if (has_classify_log()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, HasBitSetters::classify_log(this), target);
  }

  // .tensorflow.serving.RegressLog regress_log = 3;
  if (has_regress_log()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        3, HasBitSetters::regress_log(this), target);
  }

  // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
  if (has_multi_inference_log()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        4, HasBitSetters::multi_inference_log(this), target);
  }

  // .tensorflow.serving.SessionRunLog session_run_log = 5;
  if (has_session_run_log()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        5, HasBitSetters::session_run_log(this), target);
  }

  // .tensorflow.serving.PredictLog predict_log = 6;
  if (has_predict_log()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessageToArray(
        6, HasBitSetters::predict_log(this), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.PredictionLog)
  return target;
}

size_t PredictionLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.PredictionLog)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.LogMetadata log_metadata = 1;
  if (this->has_log_metadata()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *log_metadata_);
  }

  switch (log_type_case()) {
    // .tensorflow.serving.ClassifyLog classify_log = 2;
    case kClassifyLog: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *log_type_.classify_log_);
      break;
    }
    // .tensorflow.serving.RegressLog regress_log = 3;
    case kRegressLog: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *log_type_.regress_log_);
      break;
    }
    // .tensorflow.serving.PredictLog predict_log = 6;
    case kPredictLog: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *log_type_.predict_log_);
      break;
    }
    // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
    case kMultiInferenceLog: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *log_type_.multi_inference_log_);
      break;
    }
    // .tensorflow.serving.SessionRunLog session_run_log = 5;
    case kSessionRunLog: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *log_type_.session_run_log_);
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
  int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void PredictionLog::MergeFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.PredictionLog)
  GOOGLE_DCHECK_NE(&from, this);
  const PredictionLog* source =
      ::PROTOBUF_NAMESPACE_ID::DynamicCastToGenerated<PredictionLog>(
          &from);
  if (source == nullptr) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.PredictionLog)
    ::PROTOBUF_NAMESPACE_ID::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.PredictionLog)
    MergeFrom(*source);
  }
}

void PredictionLog::MergeFrom(const PredictionLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.PredictionLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_log_metadata()) {
    mutable_log_metadata()->::tensorflow::serving::LogMetadata::MergeFrom(from.log_metadata());
  }
  switch (from.log_type_case()) {
    case kClassifyLog: {
      mutable_classify_log()->::tensorflow::serving::ClassifyLog::MergeFrom(from.classify_log());
      break;
    }
    case kRegressLog: {
      mutable_regress_log()->::tensorflow::serving::RegressLog::MergeFrom(from.regress_log());
      break;
    }
    case kPredictLog: {
      mutable_predict_log()->::tensorflow::serving::PredictLog::MergeFrom(from.predict_log());
      break;
    }
    case kMultiInferenceLog: {
      mutable_multi_inference_log()->::tensorflow::serving::MultiInferenceLog::MergeFrom(from.multi_inference_log());
      break;
    }
    case kSessionRunLog: {
      mutable_session_run_log()->::tensorflow::serving::SessionRunLog::MergeFrom(from.session_run_log());
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
}

void PredictionLog::CopyFrom(const ::PROTOBUF_NAMESPACE_ID::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.PredictionLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void PredictionLog::CopyFrom(const PredictionLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.PredictionLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool PredictionLog::IsInitialized() const {
  return true;
}

void PredictionLog::Swap(PredictionLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    PredictionLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == nullptr) {
      delete temp;
    }
  }
}
void PredictionLog::UnsafeArenaSwap(PredictionLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void PredictionLog::InternalSwap(PredictionLog* other) {
  using std::swap;
  _internal_metadata_.Swap(&other->_internal_metadata_);
  swap(log_metadata_, other->log_metadata_);
  swap(log_type_, other->log_type_);
  swap(_oneof_case_[0], other->_oneof_case_[0]);
}

::PROTOBUF_NAMESPACE_ID::Metadata PredictionLog::GetMetadata() const {
  return GetMetadataStatic();
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace serving
}  // namespace tensorflow
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::tensorflow::serving::ClassifyLog* Arena::CreateMaybeMessage< ::tensorflow::serving::ClassifyLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::ClassifyLog >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::RegressLog* Arena::CreateMaybeMessage< ::tensorflow::serving::RegressLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::RegressLog >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictLog* Arena::CreateMaybeMessage< ::tensorflow::serving::PredictLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictLog >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::MultiInferenceLog* Arena::CreateMaybeMessage< ::tensorflow::serving::MultiInferenceLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::MultiInferenceLog >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::SessionRunLog* Arena::CreateMaybeMessage< ::tensorflow::serving::SessionRunLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::SessionRunLog >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictionLog* Arena::CreateMaybeMessage< ::tensorflow::serving::PredictionLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictionLog >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
