// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/config/model_server_config.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow_serving/config/model_server_config.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {
namespace serving {

namespace {

const ::google::protobuf::Descriptor* ModelConfig_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ModelConfig_reflection_ = NULL;
const ::google::protobuf::Descriptor* ModelConfig_VersionLabelsEntry_descriptor_ = NULL;
const ::google::protobuf::Descriptor* ModelConfigList_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ModelConfigList_reflection_ = NULL;
const ::google::protobuf::Descriptor* ModelServerConfig_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ModelServerConfig_reflection_ = NULL;
struct ModelServerConfigOneofInstance {
  const ::tensorflow::serving::ModelConfigList* model_config_list_;
  const ::google::protobuf::Any* custom_model_config_;
}* ModelServerConfig_default_oneof_instance_ = NULL;
const ::google::protobuf::EnumDescriptor* ModelType_descriptor_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AssignDesc_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto() {
  protobuf_AddDesc_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow_serving/config/model_server_config.proto");
  GOOGLE_CHECK(file != NULL);
  ModelConfig_descriptor_ = file->message_type(0);
  static const int ModelConfig_offsets_[7] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, name_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, base_path_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, model_type_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, model_platform_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, model_version_policy_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, version_labels_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, logging_config_),
  };
  ModelConfig_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ModelConfig_descriptor_,
      ModelConfig::default_instance_,
      ModelConfig_offsets_,
      -1,
      -1,
      -1,
      sizeof(ModelConfig),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, _is_default_instance_));
  ModelConfig_VersionLabelsEntry_descriptor_ = ModelConfig_descriptor_->nested_type(0);
  ModelConfigList_descriptor_ = file->message_type(1);
  static const int ModelConfigList_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfigList, config_),
  };
  ModelConfigList_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ModelConfigList_descriptor_,
      ModelConfigList::default_instance_,
      ModelConfigList_offsets_,
      -1,
      -1,
      -1,
      sizeof(ModelConfigList),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfigList, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfigList, _is_default_instance_));
  ModelServerConfig_descriptor_ = file->message_type(2);
  static const int ModelServerConfig_offsets_[3] = {
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(ModelServerConfig_default_oneof_instance_, model_config_list_),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(ModelServerConfig_default_oneof_instance_, custom_model_config_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelServerConfig, config_),
  };
  ModelServerConfig_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ModelServerConfig_descriptor_,
      ModelServerConfig::default_instance_,
      ModelServerConfig_offsets_,
      -1,
      -1,
      -1,
      ModelServerConfig_default_oneof_instance_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelServerConfig, _oneof_case_[0]),
      sizeof(ModelServerConfig),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelServerConfig, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelServerConfig, _is_default_instance_));
  ModelType_descriptor_ = file->enum_type(0);
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ModelConfig_descriptor_, &ModelConfig::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
        ModelConfig_VersionLabelsEntry_descriptor_,
        ::google::protobuf::internal::MapEntry<
            ::std::string,
            ::google::protobuf::int64,
            ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
            ::google::protobuf::internal::WireFormatLite::TYPE_INT64,
            0>::CreateDefaultInstance(
                ModelConfig_VersionLabelsEntry_descriptor_));
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ModelConfigList_descriptor_, &ModelConfigList::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ModelServerConfig_descriptor_, &ModelServerConfig::default_instance());
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto() {
  delete ModelConfig::default_instance_;
  delete ModelConfig_reflection_;
  delete ModelConfigList::default_instance_;
  delete ModelConfigList_reflection_;
  delete ModelServerConfig::default_instance_;
  delete ModelServerConfig_default_oneof_instance_;
  delete ModelServerConfig_reflection_;
}

void protobuf_AddDesc_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AddDesc_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::protobuf_AddDesc_google_2fprotobuf_2fany_2eproto();
  ::tensorflow::serving::protobuf_AddDesc_tensorflow_5fserving_2fconfig_2flogging_5fconfig_2eproto();
  ::tensorflow::serving::protobuf_AddDesc_tensorflow_5fserving_2fsources_2fstorage_5fpath_2ffile_5fsystem_5fstorage_5fpath_5fsource_2eproto();
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n3tensorflow_serving/config/model_server"
    "_config.proto\022\022tensorflow.serving\032\031googl"
    "e/protobuf/any.proto\032.tensorflow_serving"
    "/config/logging_config.proto\032Mtensorflow"
    "_serving/sources/storage_path/file_syste"
    "m_storage_path_source.proto\"\253\003\n\013ModelCon"
    "fig\022\014\n\004name\030\001 \001(\t\022\021\n\tbase_path\030\002 \001(\t\0225\n\n"
    "model_type\030\003 \001(\0162\035.tensorflow.serving.Mo"
    "delTypeB\002\030\001\022\026\n\016model_platform\030\004 \001(\t\022i\n\024m"
    "odel_version_policy\030\007 \001(\0132K.tensorflow.s"
    "erving.FileSystemStoragePathSourceConfig"
    ".ServableVersionPolicy\022J\n\016version_labels"
    "\030\010 \003(\01322.tensorflow.serving.ModelConfig."
    "VersionLabelsEntry\0229\n\016logging_config\030\006 \001"
    "(\0132!.tensorflow.serving.LoggingConfig\0324\n"
    "\022VersionLabelsEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005valu"
    "e\030\002 \001(\003:\0028\001J\004\010\005\020\006\"B\n\017ModelConfigList\022/\n\006"
    "config\030\001 \003(\0132\037.tensorflow.serving.ModelC"
    "onfig\"\224\001\n\021ModelServerConfig\022@\n\021model_con"
    "fig_list\030\001 \001(\0132#.tensorflow.serving.Mode"
    "lConfigListH\000\0223\n\023custom_model_config\030\002 \001"
    "(\0132\024.google.protobuf.AnyH\000B\010\n\006config*N\n\t"
    "ModelType\022\036\n\026MODEL_TYPE_UNSPECIFIED\020\000\032\002\010"
    "\001\022\022\n\nTENSORFLOW\020\001\032\002\010\001\022\r\n\005OTHER\020\002\032\002\010\001B\003\370\001"
    "\001b\006proto3", 969);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/config/model_server_config.proto", &protobuf_RegisterTypes);
  ModelConfig::default_instance_ = new ModelConfig();
  ModelConfigList::default_instance_ = new ModelConfigList();
  ModelServerConfig::default_instance_ = new ModelServerConfig();
  ModelServerConfig_default_oneof_instance_ = new ModelServerConfigOneofInstance();
  ModelConfig::default_instance_->InitAsDefaultInstance();
  ModelConfigList::default_instance_->InitAsDefaultInstance();
  ModelServerConfig::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto {
  StaticDescriptorInitializer_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto() {
    protobuf_AddDesc_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto();
  }
} static_descriptor_initializer_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto_;
const ::google::protobuf::EnumDescriptor* ModelType_descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ModelType_descriptor_;
}
bool ModelType_IsValid(int value) {
  switch(value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}


// ===================================================================

void ModelConfig::_slow_mutable_model_version_policy() {
  model_version_policy_ = ::google::protobuf::Arena::Create< ::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy >(
      GetArenaNoVirtual());
}
::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy* ModelConfig::_slow_release_model_version_policy() {
  if (model_version_policy_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy* temp = new ::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy;
    temp->MergeFrom(*model_version_policy_);
    model_version_policy_ = NULL;
    return temp;
  }
}
::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy* ModelConfig::unsafe_arena_release_model_version_policy() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelConfig.model_version_policy)
  
  ::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy* temp = model_version_policy_;
  model_version_policy_ = NULL;
  return temp;
}
void ModelConfig::unsafe_arena_set_allocated_model_version_policy(
    ::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy* model_version_policy) {
  if (GetArenaNoVirtual() == NULL) {
    delete model_version_policy_;
  }
  model_version_policy_ = model_version_policy;
  if (model_version_policy) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelConfig.model_version_policy)
}
void ModelConfig::_slow_mutable_logging_config() {
  logging_config_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::LoggingConfig >(
      GetArenaNoVirtual());
}
::tensorflow::serving::LoggingConfig* ModelConfig::_slow_release_logging_config() {
  if (logging_config_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::serving::LoggingConfig* temp = new ::tensorflow::serving::LoggingConfig;
    temp->MergeFrom(*logging_config_);
    logging_config_ = NULL;
    return temp;
  }
}
::tensorflow::serving::LoggingConfig* ModelConfig::unsafe_arena_release_logging_config() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelConfig.logging_config)
  
  ::tensorflow::serving::LoggingConfig* temp = logging_config_;
  logging_config_ = NULL;
  return temp;
}
void ModelConfig::_slow_set_allocated_logging_config(
    ::google::protobuf::Arena* message_arena, ::tensorflow::serving::LoggingConfig** logging_config) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*logging_config) == NULL) {
      message_arena->Own(*logging_config);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*logging_config)) {
      ::tensorflow::serving::LoggingConfig* new_logging_config = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::LoggingConfig >(
            message_arena);
      new_logging_config->CopyFrom(**logging_config);
      *logging_config = new_logging_config;
    }
}
void ModelConfig::unsafe_arena_set_allocated_logging_config(
    ::tensorflow::serving::LoggingConfig* logging_config) {
  if (GetArenaNoVirtual() == NULL) {
    delete logging_config_;
  }
  logging_config_ = logging_config;
  if (logging_config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelConfig.logging_config)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ModelConfig::kNameFieldNumber;
const int ModelConfig::kBasePathFieldNumber;
const int ModelConfig::kModelTypeFieldNumber;
const int ModelConfig::kModelPlatformFieldNumber;
const int ModelConfig::kModelVersionPolicyFieldNumber;
const int ModelConfig::kVersionLabelsFieldNumber;
const int ModelConfig::kLoggingConfigFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ModelConfig::ModelConfig()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ModelConfig)
}

ModelConfig::ModelConfig(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  version_labels_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ModelConfig)
}

void ModelConfig::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  model_version_policy_ = const_cast< ::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy*>(&::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy::default_instance());
  logging_config_ = const_cast< ::tensorflow::serving::LoggingConfig*>(&::tensorflow::serving::LoggingConfig::default_instance());
}

ModelConfig::ModelConfig(const ModelConfig& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ModelConfig)
}

void ModelConfig::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  name_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  base_path_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  model_type_ = 0;
  model_platform_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  model_version_policy_ = NULL;
  version_labels_.SetAssignDescriptorCallback(
      protobuf_AssignDescriptorsOnce);
  version_labels_.SetEntryDescriptor(
      &::tensorflow::serving::ModelConfig_VersionLabelsEntry_descriptor_);
  logging_config_ = NULL;
}

ModelConfig::~ModelConfig() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ModelConfig)
  SharedDtor();
}

void ModelConfig::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  name_.Destroy(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  base_path_.Destroy(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  model_platform_.Destroy(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  if (this != default_instance_) {
    delete model_version_policy_;
    delete logging_config_;
  }
}

void ModelConfig::ArenaDtor(void* object) {
  ModelConfig* _this = reinterpret_cast< ModelConfig* >(object);
  (void)_this;
}
void ModelConfig::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ModelConfig::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ModelConfig::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ModelConfig_descriptor_;
}

const ModelConfig& ModelConfig::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto();
  return *default_instance_;
}

ModelConfig* ModelConfig::default_instance_ = NULL;

ModelConfig* ModelConfig::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<ModelConfig>(arena);
}

void ModelConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ModelConfig)
  name_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  base_path_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  model_type_ = 0;
  model_platform_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  if (GetArenaNoVirtual() == NULL && model_version_policy_ != NULL) delete model_version_policy_;
  model_version_policy_ = NULL;
  if (GetArenaNoVirtual() == NULL && logging_config_ != NULL) delete logging_config_;
  logging_config_ = NULL;
  version_labels_.Clear();
}

bool ModelConfig::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ModelConfig)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string name = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_name()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->name().data(), this->name().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.ModelConfig.name"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_base_path;
        break;
      }

      // optional string base_path = 2;
      case 2: {
        if (tag == 18) {
         parse_base_path:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_base_path()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->base_path().data(), this->base_path().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.ModelConfig.base_path"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_model_type;
        break;
      }

      // optional .tensorflow.serving.ModelType model_type = 3 [deprecated = true];
      case 3: {
        if (tag == 24) {
         parse_model_type:
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_model_type(static_cast< ::tensorflow::serving::ModelType >(value));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_model_platform;
        break;
      }

      // optional string model_platform = 4;
      case 4: {
        if (tag == 34) {
         parse_model_platform:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_model_platform()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->model_platform().data(), this->model_platform().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.ModelConfig.model_platform"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(50)) goto parse_logging_config;
        break;
      }

      // optional .tensorflow.serving.LoggingConfig logging_config = 6;
      case 6: {
        if (tag == 50) {
         parse_logging_config:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_logging_config()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(58)) goto parse_model_version_policy;
        break;
      }

      // optional .tensorflow.serving.FileSystemStoragePathSourceConfig.ServableVersionPolicy model_version_policy = 7;
      case 7: {
        if (tag == 58) {
         parse_model_version_policy:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_model_version_policy()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(66)) goto parse_version_labels;
        break;
      }

      // map<string, int64> version_labels = 8;
      case 8: {
        if (tag == 66) {
         parse_version_labels:
          DO_(input->IncrementRecursionDepth());
         parse_loop_version_labels:
          ModelConfig_VersionLabelsEntry::Parser< ::google::protobuf::internal::MapField<
              ::std::string, ::google::protobuf::int64,
              ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
              ::google::protobuf::internal::WireFormatLite::TYPE_INT64,
              0 >,
            ::google::protobuf::Map< ::std::string, ::google::protobuf::int64 > > parser(&version_labels_);
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
              input, &parser));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            parser.key().data(), parser.key().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.ModelConfig.VersionLabelsEntry.key"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(66)) goto parse_loop_version_labels;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ModelConfig)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ModelConfig)
  return false;
#undef DO_
}

void ModelConfig::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ModelConfig)
  // optional string name = 1;
  if (this->name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.name");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->name(), output);
  }

  // optional string base_path = 2;
  if (this->base_path().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->base_path().data(), this->base_path().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.base_path");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      2, this->base_path(), output);
  }

  // optional .tensorflow.serving.ModelType model_type = 3 [deprecated = true];
  if (this->model_type() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      3, this->model_type(), output);
  }

  // optional string model_platform = 4;
  if (this->model_platform().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->model_platform().data(), this->model_platform().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.model_platform");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      4, this->model_platform(), output);
  }

  // optional .tensorflow.serving.LoggingConfig logging_config = 6;
  if (this->has_logging_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      6, *this->logging_config_, output);
  }

  // optional .tensorflow.serving.FileSystemStoragePathSourceConfig.ServableVersionPolicy model_version_policy = 7;
  if (this->has_model_version_policy()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      7, *this->model_version_policy_, output);
  }

  // map<string, int64> version_labels = 8;
  if (!this->version_labels().empty()) {
    typedef ::google::protobuf::Map< ::std::string, ::google::protobuf::int64 >::const_pointer
        ConstPtr;
    typedef ConstPtr SortItem;
    typedef ::google::protobuf::internal::CompareByDerefFirst<SortItem> Less;
    struct Utf8Check {
      static void Check(ConstPtr p) {
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          p->first.data(), p->first.length(),
          ::google::protobuf::internal::WireFormatLite::SERIALIZE,
          "tensorflow.serving.ModelConfig.VersionLabelsEntry.key");
      }
    };

    if (output->IsSerializationDeterminstic() &&
        this->version_labels().size() > 1) {
      ::google::protobuf::scoped_array<SortItem> items(
          new SortItem[this->version_labels().size()]);
      typedef ::google::protobuf::Map< ::std::string, ::google::protobuf::int64 >::size_type size_type;
      size_type n = 0;
      for (::google::protobuf::Map< ::std::string, ::google::protobuf::int64 >::const_iterator
          it = this->version_labels().begin();
          it != this->version_labels().end(); ++it, ++n) {
        items[n] = SortItem(&*it);
      }
      ::std::sort(&items[0], &items[n], Less());
      ::google::protobuf::scoped_ptr<ModelConfig_VersionLabelsEntry> entry;
      for (size_type i = 0; i < n; i++) {
        entry.reset(version_labels_.NewEntryWrapper(
            items[i]->first, items[i]->second));
        ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
            8, *entry, output);
        if (entry->GetArena() != NULL) {
          entry.release();
        }
        Utf8Check::Check(items[i]);
      }
    } else {
      ::google::protobuf::scoped_ptr<ModelConfig_VersionLabelsEntry> entry;
      for (::google::protobuf::Map< ::std::string, ::google::protobuf::int64 >::const_iterator
          it = this->version_labels().begin();
          it != this->version_labels().end(); ++it) {
        entry.reset(version_labels_.NewEntryWrapper(
            it->first, it->second));
        ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
            8, *entry, output);
        if (entry->GetArena() != NULL) {
          entry.release();
        }
        Utf8Check::Check(&*it);
      }
    }
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ModelConfig)
}

::google::protobuf::uint8* ModelConfig::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ModelConfig)
  // optional string name = 1;
  if (this->name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.name");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->name(), target);
  }

  // optional string base_path = 2;
  if (this->base_path().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->base_path().data(), this->base_path().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.base_path");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        2, this->base_path(), target);
  }

  // optional .tensorflow.serving.ModelType model_type = 3 [deprecated = true];
  if (this->model_type() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      3, this->model_type(), target);
  }

  // optional string model_platform = 4;
  if (this->model_platform().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->model_platform().data(), this->model_platform().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.model_platform");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        4, this->model_platform(), target);
  }

  // optional .tensorflow.serving.LoggingConfig logging_config = 6;
  if (this->has_logging_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        6, *this->logging_config_, false, target);
  }

  // optional .tensorflow.serving.FileSystemStoragePathSourceConfig.ServableVersionPolicy model_version_policy = 7;
  if (this->has_model_version_policy()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        7, *this->model_version_policy_, false, target);
  }

  // map<string, int64> version_labels = 8;
  if (!this->version_labels().empty()) {
    typedef ::google::protobuf::Map< ::std::string, ::google::protobuf::int64 >::const_pointer
        ConstPtr;
    typedef ConstPtr SortItem;
    typedef ::google::protobuf::internal::CompareByDerefFirst<SortItem> Less;
    struct Utf8Check {
      static void Check(ConstPtr p) {
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          p->first.data(), p->first.length(),
          ::google::protobuf::internal::WireFormatLite::SERIALIZE,
          "tensorflow.serving.ModelConfig.VersionLabelsEntry.key");
      }
    };

    if (deterministic &&
        this->version_labels().size() > 1) {
      ::google::protobuf::scoped_array<SortItem> items(
          new SortItem[this->version_labels().size()]);
      typedef ::google::protobuf::Map< ::std::string, ::google::protobuf::int64 >::size_type size_type;
      size_type n = 0;
      for (::google::protobuf::Map< ::std::string, ::google::protobuf::int64 >::const_iterator
          it = this->version_labels().begin();
          it != this->version_labels().end(); ++it, ++n) {
        items[n] = SortItem(&*it);
      }
      ::std::sort(&items[0], &items[n], Less());
      ::google::protobuf::scoped_ptr<ModelConfig_VersionLabelsEntry> entry;
      for (size_type i = 0; i < n; i++) {
        entry.reset(version_labels_.NewEntryWrapper(
            items[i]->first, items[i]->second));
        target = ::google::protobuf::internal::WireFormatLite::
                   InternalWriteMessageNoVirtualToArray(
                       8, *entry, deterministic, target);
;
        if (entry->GetArena() != NULL) {
          entry.release();
        }
        Utf8Check::Check(items[i]);
      }
    } else {
      ::google::protobuf::scoped_ptr<ModelConfig_VersionLabelsEntry> entry;
      for (::google::protobuf::Map< ::std::string, ::google::protobuf::int64 >::const_iterator
          it = this->version_labels().begin();
          it != this->version_labels().end(); ++it) {
        entry.reset(version_labels_.NewEntryWrapper(
            it->first, it->second));
        target = ::google::protobuf::internal::WireFormatLite::
                   InternalWriteMessageNoVirtualToArray(
                       8, *entry, deterministic, target);
;
        if (entry->GetArena() != NULL) {
          entry.release();
        }
        Utf8Check::Check(&*it);
      }
    }
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ModelConfig)
  return target;
}

int ModelConfig::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ModelConfig)
  int total_size = 0;

  // optional string name = 1;
  if (this->name().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->name());
  }

  // optional string base_path = 2;
  if (this->base_path().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->base_path());
  }

  // optional .tensorflow.serving.ModelType model_type = 3 [deprecated = true];
  if (this->model_type() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->model_type());
  }

  // optional string model_platform = 4;
  if (this->model_platform().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->model_platform());
  }

  // optional .tensorflow.serving.FileSystemStoragePathSourceConfig.ServableVersionPolicy model_version_policy = 7;
  if (this->has_model_version_policy()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->model_version_policy_);
  }

  // optional .tensorflow.serving.LoggingConfig logging_config = 6;
  if (this->has_logging_config()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->logging_config_);
  }

  // map<string, int64> version_labels = 8;
  total_size += 1 * this->version_labels_size();
  {
    ::google::protobuf::scoped_ptr<ModelConfig_VersionLabelsEntry> entry;
    for (::google::protobuf::Map< ::std::string, ::google::protobuf::int64 >::const_iterator
        it = this->version_labels().begin();
        it != this->version_labels().end(); ++it) {
      if (entry.get() != NULL && entry->GetArena() != NULL) {
        entry.release();
      }
      entry.reset(version_labels_.NewEntryWrapper(it->first, it->second));
      total_size += ::google::protobuf::internal::WireFormatLite::
          MessageSizeNoVirtual(*entry);
    }
    if (entry.get() != NULL && entry->GetArena() != NULL) {
      entry.release();
    }
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ModelConfig::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ModelConfig)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const ModelConfig* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ModelConfig>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ModelConfig)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ModelConfig)
    MergeFrom(*source);
  }
}

void ModelConfig::MergeFrom(const ModelConfig& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ModelConfig)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  version_labels_.MergeFrom(from.version_labels_);
  if (from.name().size() > 0) {
    set_name(from.name());
  }
  if (from.base_path().size() > 0) {
    set_base_path(from.base_path());
  }
  if (from.model_type() != 0) {
    set_model_type(from.model_type());
  }
  if (from.model_platform().size() > 0) {
    set_model_platform(from.model_platform());
  }
  if (from.has_model_version_policy()) {
    mutable_model_version_policy()->::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy::MergeFrom(from.model_version_policy());
  }
  if (from.has_logging_config()) {
    mutable_logging_config()->::tensorflow::serving::LoggingConfig::MergeFrom(from.logging_config());
  }
}

void ModelConfig::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ModelConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ModelConfig::CopyFrom(const ModelConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ModelConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelConfig::IsInitialized() const {

  return true;
}

void ModelConfig::Swap(ModelConfig* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ModelConfig temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void ModelConfig::UnsafeArenaSwap(ModelConfig* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ModelConfig::InternalSwap(ModelConfig* other) {
  name_.Swap(&other->name_);
  base_path_.Swap(&other->base_path_);
  std::swap(model_type_, other->model_type_);
  model_platform_.Swap(&other->model_platform_);
  std::swap(model_version_policy_, other->model_version_policy_);
  version_labels_.Swap(&other->version_labels_);
  std::swap(logging_config_, other->logging_config_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ModelConfig::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ModelConfig_descriptor_;
  metadata.reflection = ModelConfig_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ModelConfig

// optional string name = 1;
void ModelConfig::clear_name() {
  name_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 const ::std::string& ModelConfig::name() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.name)
  return name_.Get(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void ModelConfig::set_name(const ::std::string& value) {
  
  name_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set:tensorflow.serving.ModelConfig.name)
}
 void ModelConfig::set_name(const char* value) {
  
  name_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value),
              GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.ModelConfig.name)
}
 void ModelConfig::set_name(const char* value,
    size_t size) {
  
  name_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size), GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.ModelConfig.name)
}
 ::std::string* ModelConfig::mutable_name() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelConfig.name)
  return name_.Mutable(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 ::std::string* ModelConfig::release_name() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelConfig.name)
  
  return name_.Release(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 ::std::string* ModelConfig::unsafe_arena_release_name() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelConfig.name)
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  
  return name_.UnsafeArenaRelease(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      GetArenaNoVirtual());
}
 void ModelConfig::set_allocated_name(::std::string* name) {
  if (name != NULL) {
    
  } else {
    
  }
  name_.SetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), name,
      GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelConfig.name)
}
 void ModelConfig::unsafe_arena_set_allocated_name(
    ::std::string* name) {
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  if (name != NULL) {
    
  } else {
    
  }
  name_.UnsafeArenaSetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      name, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelConfig.name)
}

// optional string base_path = 2;
void ModelConfig::clear_base_path() {
  base_path_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 const ::std::string& ModelConfig::base_path() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.base_path)
  return base_path_.Get(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void ModelConfig::set_base_path(const ::std::string& value) {
  
  base_path_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set:tensorflow.serving.ModelConfig.base_path)
}
 void ModelConfig::set_base_path(const char* value) {
  
  base_path_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value),
              GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.ModelConfig.base_path)
}
 void ModelConfig::set_base_path(const char* value,
    size_t size) {
  
  base_path_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size), GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.ModelConfig.base_path)
}
 ::std::string* ModelConfig::mutable_base_path() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelConfig.base_path)
  return base_path_.Mutable(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 ::std::string* ModelConfig::release_base_path() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelConfig.base_path)
  
  return base_path_.Release(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 ::std::string* ModelConfig::unsafe_arena_release_base_path() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelConfig.base_path)
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  
  return base_path_.UnsafeArenaRelease(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      GetArenaNoVirtual());
}
 void ModelConfig::set_allocated_base_path(::std::string* base_path) {
  if (base_path != NULL) {
    
  } else {
    
  }
  base_path_.SetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), base_path,
      GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelConfig.base_path)
}
 void ModelConfig::unsafe_arena_set_allocated_base_path(
    ::std::string* base_path) {
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  if (base_path != NULL) {
    
  } else {
    
  }
  base_path_.UnsafeArenaSetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      base_path, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelConfig.base_path)
}

// optional .tensorflow.serving.ModelType model_type = 3 [deprecated = true];
void ModelConfig::clear_model_type() {
  model_type_ = 0;
}
 ::tensorflow::serving::ModelType ModelConfig::model_type() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.model_type)
  return static_cast< ::tensorflow::serving::ModelType >(model_type_);
}
 void ModelConfig::set_model_type(::tensorflow::serving::ModelType value) {
  
  model_type_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.serving.ModelConfig.model_type)
}

// optional string model_platform = 4;
void ModelConfig::clear_model_platform() {
  model_platform_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 const ::std::string& ModelConfig::model_platform() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.model_platform)
  return model_platform_.Get(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void ModelConfig::set_model_platform(const ::std::string& value) {
  
  model_platform_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set:tensorflow.serving.ModelConfig.model_platform)
}
 void ModelConfig::set_model_platform(const char* value) {
  
  model_platform_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value),
              GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.ModelConfig.model_platform)
}
 void ModelConfig::set_model_platform(const char* value,
    size_t size) {
  
  model_platform_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size), GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.ModelConfig.model_platform)
}
 ::std::string* ModelConfig::mutable_model_platform() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelConfig.model_platform)
  return model_platform_.Mutable(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 ::std::string* ModelConfig::release_model_platform() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelConfig.model_platform)
  
  return model_platform_.Release(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 ::std::string* ModelConfig::unsafe_arena_release_model_platform() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelConfig.model_platform)
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  
  return model_platform_.UnsafeArenaRelease(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      GetArenaNoVirtual());
}
 void ModelConfig::set_allocated_model_platform(::std::string* model_platform) {
  if (model_platform != NULL) {
    
  } else {
    
  }
  model_platform_.SetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), model_platform,
      GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelConfig.model_platform)
}
 void ModelConfig::unsafe_arena_set_allocated_model_platform(
    ::std::string* model_platform) {
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  if (model_platform != NULL) {
    
  } else {
    
  }
  model_platform_.UnsafeArenaSetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      model_platform, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelConfig.model_platform)
}

// optional .tensorflow.serving.FileSystemStoragePathSourceConfig.ServableVersionPolicy model_version_policy = 7;
bool ModelConfig::has_model_version_policy() const {
  return !_is_default_instance_ && model_version_policy_ != NULL;
}
void ModelConfig::clear_model_version_policy() {
  if (GetArenaNoVirtual() == NULL && model_version_policy_ != NULL) delete model_version_policy_;
  model_version_policy_ = NULL;
}
const ::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy& ModelConfig::model_version_policy() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.model_version_policy)
  return model_version_policy_ != NULL ? *model_version_policy_ : *default_instance_->model_version_policy_;
}
::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy* ModelConfig::mutable_model_version_policy() {
  
  if (model_version_policy_ == NULL) {
    _slow_mutable_model_version_policy();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelConfig.model_version_policy)
  return model_version_policy_;
}
::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy* ModelConfig::release_model_version_policy() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelConfig.model_version_policy)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_model_version_policy();
  } else {
    ::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy* temp = model_version_policy_;
    model_version_policy_ = NULL;
    return temp;
  }
}
 void ModelConfig::set_allocated_model_version_policy(::tensorflow::serving::FileSystemStoragePathSourceConfig_ServableVersionPolicy* model_version_policy) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete model_version_policy_;
  }
  if (model_version_policy != NULL) {
    if (message_arena != NULL) {
      message_arena->Own(model_version_policy);
    }
  }
  model_version_policy_ = model_version_policy;
  if (model_version_policy) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelConfig.model_version_policy)
}

// map<string, int64> version_labels = 8;
int ModelConfig::version_labels_size() const {
  return version_labels_.size();
}
void ModelConfig::clear_version_labels() {
  version_labels_.Clear();
}
 const ::google::protobuf::Map< ::std::string, ::google::protobuf::int64 >&
ModelConfig::version_labels() const {
  // @@protoc_insertion_point(field_map:tensorflow.serving.ModelConfig.version_labels)
  return version_labels_.GetMap();
}
 ::google::protobuf::Map< ::std::string, ::google::protobuf::int64 >*
ModelConfig::mutable_version_labels() {
  // @@protoc_insertion_point(field_mutable_map:tensorflow.serving.ModelConfig.version_labels)
  return version_labels_.MutableMap();
}

// optional .tensorflow.serving.LoggingConfig logging_config = 6;
bool ModelConfig::has_logging_config() const {
  return !_is_default_instance_ && logging_config_ != NULL;
}
void ModelConfig::clear_logging_config() {
  if (GetArenaNoVirtual() == NULL && logging_config_ != NULL) delete logging_config_;
  logging_config_ = NULL;
}
const ::tensorflow::serving::LoggingConfig& ModelConfig::logging_config() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.logging_config)
  return logging_config_ != NULL ? *logging_config_ : *default_instance_->logging_config_;
}
::tensorflow::serving::LoggingConfig* ModelConfig::mutable_logging_config() {
  
  if (logging_config_ == NULL) {
    _slow_mutable_logging_config();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelConfig.logging_config)
  return logging_config_;
}
::tensorflow::serving::LoggingConfig* ModelConfig::release_logging_config() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelConfig.logging_config)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_logging_config();
  } else {
    ::tensorflow::serving::LoggingConfig* temp = logging_config_;
    logging_config_ = NULL;
    return temp;
  }
}
 void ModelConfig::set_allocated_logging_config(::tensorflow::serving::LoggingConfig* logging_config) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete logging_config_;
  }
  if (logging_config != NULL) {
    _slow_set_allocated_logging_config(message_arena, &logging_config);
  }
  logging_config_ = logging_config;
  if (logging_config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelConfig.logging_config)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ModelConfigList::kConfigFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ModelConfigList::ModelConfigList()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ModelConfigList)
}

ModelConfigList::ModelConfigList(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  config_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ModelConfigList)
}

void ModelConfigList::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

ModelConfigList::ModelConfigList(const ModelConfigList& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ModelConfigList)
}

void ModelConfigList::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

ModelConfigList::~ModelConfigList() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ModelConfigList)
  SharedDtor();
}

void ModelConfigList::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
  }
}

void ModelConfigList::ArenaDtor(void* object) {
  ModelConfigList* _this = reinterpret_cast< ModelConfigList* >(object);
  (void)_this;
}
void ModelConfigList::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ModelConfigList::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ModelConfigList::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ModelConfigList_descriptor_;
}

const ModelConfigList& ModelConfigList::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto();
  return *default_instance_;
}

ModelConfigList* ModelConfigList::default_instance_ = NULL;

ModelConfigList* ModelConfigList::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<ModelConfigList>(arena);
}

void ModelConfigList::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ModelConfigList)
  config_.Clear();
}

bool ModelConfigList::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ModelConfigList)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.serving.ModelConfig config = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_config:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_config()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_config;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ModelConfigList)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ModelConfigList)
  return false;
#undef DO_
}

void ModelConfigList::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ModelConfigList)
  // repeated .tensorflow.serving.ModelConfig config = 1;
  for (unsigned int i = 0, n = this->config_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->config(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ModelConfigList)
}

::google::protobuf::uint8* ModelConfigList::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ModelConfigList)
  // repeated .tensorflow.serving.ModelConfig config = 1;
  for (unsigned int i = 0, n = this->config_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, this->config(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ModelConfigList)
  return target;
}

int ModelConfigList::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ModelConfigList)
  int total_size = 0;

  // repeated .tensorflow.serving.ModelConfig config = 1;
  total_size += 1 * this->config_size();
  for (int i = 0; i < this->config_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->config(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ModelConfigList::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ModelConfigList)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const ModelConfigList* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ModelConfigList>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ModelConfigList)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ModelConfigList)
    MergeFrom(*source);
  }
}

void ModelConfigList::MergeFrom(const ModelConfigList& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ModelConfigList)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  config_.MergeFrom(from.config_);
}

void ModelConfigList::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ModelConfigList)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ModelConfigList::CopyFrom(const ModelConfigList& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ModelConfigList)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelConfigList::IsInitialized() const {

  return true;
}

void ModelConfigList::Swap(ModelConfigList* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ModelConfigList temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void ModelConfigList::UnsafeArenaSwap(ModelConfigList* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ModelConfigList::InternalSwap(ModelConfigList* other) {
  config_.UnsafeArenaSwap(&other->config_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ModelConfigList::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ModelConfigList_descriptor_;
  metadata.reflection = ModelConfigList_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ModelConfigList

// repeated .tensorflow.serving.ModelConfig config = 1;
int ModelConfigList::config_size() const {
  return config_.size();
}
void ModelConfigList::clear_config() {
  config_.Clear();
}
const ::tensorflow::serving::ModelConfig& ModelConfigList::config(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfigList.config)
  return config_.Get(index);
}
::tensorflow::serving::ModelConfig* ModelConfigList::mutable_config(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelConfigList.config)
  return config_.Mutable(index);
}
::tensorflow::serving::ModelConfig* ModelConfigList::add_config() {
  // @@protoc_insertion_point(field_add:tensorflow.serving.ModelConfigList.config)
  return config_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::serving::ModelConfig >*
ModelConfigList::mutable_config() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.ModelConfigList.config)
  return &config_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::serving::ModelConfig >&
ModelConfigList::config() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.ModelConfigList.config)
  return config_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ModelServerConfig::kModelConfigListFieldNumber;
const int ModelServerConfig::kCustomModelConfigFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ModelServerConfig::ModelServerConfig()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ModelServerConfig)
}

ModelServerConfig::ModelServerConfig(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ModelServerConfig)
}

void ModelServerConfig::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  ModelServerConfig_default_oneof_instance_->model_config_list_ = const_cast< ::tensorflow::serving::ModelConfigList*>(&::tensorflow::serving::ModelConfigList::default_instance());
  ModelServerConfig_default_oneof_instance_->custom_model_config_ = const_cast< ::google::protobuf::Any*>(&::google::protobuf::Any::default_instance());
}

ModelServerConfig::ModelServerConfig(const ModelServerConfig& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ModelServerConfig)
}

void ModelServerConfig::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  clear_has_config();
}

ModelServerConfig::~ModelServerConfig() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ModelServerConfig)
  SharedDtor();
}

void ModelServerConfig::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (has_config()) {
    clear_config();
  }
  if (this != default_instance_) {
  }
}

void ModelServerConfig::ArenaDtor(void* object) {
  ModelServerConfig* _this = reinterpret_cast< ModelServerConfig* >(object);
  (void)_this;
}
void ModelServerConfig::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ModelServerConfig::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ModelServerConfig::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ModelServerConfig_descriptor_;
}

const ModelServerConfig& ModelServerConfig::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto();
  return *default_instance_;
}

ModelServerConfig* ModelServerConfig::default_instance_ = NULL;

ModelServerConfig* ModelServerConfig::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<ModelServerConfig>(arena);
}

void ModelServerConfig::clear_config() {
// @@protoc_insertion_point(one_of_clear_start:tensorflow.serving.ModelServerConfig)
  switch(config_case()) {
    case kModelConfigList: {
      if (GetArenaNoVirtual() == NULL) {
        delete config_.model_config_list_;
      }
      break;
    }
    case kCustomModelConfig: {
      if (GetArenaNoVirtual() == NULL) {
        delete config_.custom_model_config_;
      }
      break;
    }
    case CONFIG_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = CONFIG_NOT_SET;
}


void ModelServerConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ModelServerConfig)
  clear_config();
}

bool ModelServerConfig::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ModelServerConfig)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.serving.ModelConfigList model_config_list = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_model_config_list()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_custom_model_config;
        break;
      }

      // optional .google.protobuf.Any custom_model_config = 2;
      case 2: {
        if (tag == 18) {
         parse_custom_model_config:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_custom_model_config()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ModelServerConfig)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ModelServerConfig)
  return false;
#undef DO_
}

void ModelServerConfig::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ModelServerConfig)
  // optional .tensorflow.serving.ModelConfigList model_config_list = 1;
  if (has_model_config_list()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *config_.model_config_list_, output);
  }

  // optional .google.protobuf.Any custom_model_config = 2;
  if (has_custom_model_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *config_.custom_model_config_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ModelServerConfig)
}

::google::protobuf::uint8* ModelServerConfig::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ModelServerConfig)
  // optional .tensorflow.serving.ModelConfigList model_config_list = 1;
  if (has_model_config_list()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *config_.model_config_list_, false, target);
  }

  // optional .google.protobuf.Any custom_model_config = 2;
  if (has_custom_model_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *config_.custom_model_config_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ModelServerConfig)
  return target;
}

int ModelServerConfig::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ModelServerConfig)
  int total_size = 0;

  switch (config_case()) {
    // optional .tensorflow.serving.ModelConfigList model_config_list = 1;
    case kModelConfigList: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *config_.model_config_list_);
      break;
    }
    // optional .google.protobuf.Any custom_model_config = 2;
    case kCustomModelConfig: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *config_.custom_model_config_);
      break;
    }
    case CONFIG_NOT_SET: {
      break;
    }
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ModelServerConfig::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ModelServerConfig)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const ModelServerConfig* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ModelServerConfig>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ModelServerConfig)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ModelServerConfig)
    MergeFrom(*source);
  }
}

void ModelServerConfig::MergeFrom(const ModelServerConfig& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ModelServerConfig)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  switch (from.config_case()) {
    case kModelConfigList: {
      mutable_model_config_list()->::tensorflow::serving::ModelConfigList::MergeFrom(from.model_config_list());
      break;
    }
    case kCustomModelConfig: {
      mutable_custom_model_config()->::google::protobuf::Any::MergeFrom(from.custom_model_config());
      break;
    }
    case CONFIG_NOT_SET: {
      break;
    }
  }
}

void ModelServerConfig::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ModelServerConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ModelServerConfig::CopyFrom(const ModelServerConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ModelServerConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelServerConfig::IsInitialized() const {

  return true;
}

void ModelServerConfig::Swap(ModelServerConfig* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ModelServerConfig temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void ModelServerConfig::UnsafeArenaSwap(ModelServerConfig* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ModelServerConfig::InternalSwap(ModelServerConfig* other) {
  std::swap(config_, other->config_);
  std::swap(_oneof_case_[0], other->_oneof_case_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ModelServerConfig::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ModelServerConfig_descriptor_;
  metadata.reflection = ModelServerConfig_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ModelServerConfig

// optional .tensorflow.serving.ModelConfigList model_config_list = 1;
bool ModelServerConfig::has_model_config_list() const {
  return config_case() == kModelConfigList;
}
void ModelServerConfig::set_has_model_config_list() {
  _oneof_case_[0] = kModelConfigList;
}
void ModelServerConfig::clear_model_config_list() {
  if (has_model_config_list()) {
    if (GetArenaNoVirtual() == NULL) {
      delete config_.model_config_list_;
    }
    clear_has_config();
  }
}
 const ::tensorflow::serving::ModelConfigList& ModelServerConfig::model_config_list() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelServerConfig.model_config_list)
  return has_model_config_list()
      ? *config_.model_config_list_
      : ::tensorflow::serving::ModelConfigList::default_instance();
}
::tensorflow::serving::ModelConfigList* ModelServerConfig::mutable_model_config_list() {
  if (!has_model_config_list()) {
    clear_config();
    set_has_model_config_list();
    config_.model_config_list_ = 
      ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelConfigList >(
      GetArenaNoVirtual());
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelServerConfig.model_config_list)
  return config_.model_config_list_;
}
::tensorflow::serving::ModelConfigList* ModelServerConfig::release_model_config_list() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelServerConfig.model_config_list)
  if (has_model_config_list()) {
    clear_has_config();
    if (GetArenaNoVirtual() != NULL) {
      ::tensorflow::serving::ModelConfigList* temp = new ::tensorflow::serving::ModelConfigList;
      temp->MergeFrom(*config_.model_config_list_);
      config_.model_config_list_ = NULL;
      return temp;
    } else {
      ::tensorflow::serving::ModelConfigList* temp = config_.model_config_list_;
      config_.model_config_list_ = NULL;
      return temp;
    }
  } else {
    return NULL;
  }
}
void ModelServerConfig::set_allocated_model_config_list(::tensorflow::serving::ModelConfigList* model_config_list) {
  clear_config();
  if (model_config_list) {
    if (GetArenaNoVirtual() != NULL &&
        ::google::protobuf::Arena::GetArena(model_config_list) == NULL) {
      GetArenaNoVirtual()->Own(model_config_list);
    } else if (GetArenaNoVirtual() !=
               ::google::protobuf::Arena::GetArena(model_config_list)) {
      ::tensorflow::serving::ModelConfigList* new_model_config_list = 
          ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelConfigList >(
          GetArenaNoVirtual());
      new_model_config_list->CopyFrom(*model_config_list);
      model_config_list = new_model_config_list;
    }
    set_has_model_config_list();
    config_.model_config_list_ = model_config_list;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelServerConfig.model_config_list)
}
 ::tensorflow::serving::ModelConfigList* ModelServerConfig::unsafe_arena_release_model_config_list() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelServerConfig.model_config_list)
  if (has_model_config_list()) {
    clear_has_config();
    ::tensorflow::serving::ModelConfigList* temp = config_.model_config_list_;
    config_.model_config_list_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
 void ModelServerConfig::unsafe_arena_set_allocated_model_config_list(::tensorflow::serving::ModelConfigList* model_config_list) {
  clear_config();
  if (model_config_list) {
    set_has_model_config_list();
    config_.model_config_list_ = model_config_list;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelServerConfig.model_config_list)
}

// optional .google.protobuf.Any custom_model_config = 2;
bool ModelServerConfig::has_custom_model_config() const {
  return config_case() == kCustomModelConfig;
}
void ModelServerConfig::set_has_custom_model_config() {
  _oneof_case_[0] = kCustomModelConfig;
}
void ModelServerConfig::clear_custom_model_config() {
  if (has_custom_model_config()) {
    if (GetArenaNoVirtual() == NULL) {
      delete config_.custom_model_config_;
    }
    clear_has_config();
  }
}
 const ::google::protobuf::Any& ModelServerConfig::custom_model_config() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelServerConfig.custom_model_config)
  return has_custom_model_config()
      ? *config_.custom_model_config_
      : ::google::protobuf::Any::default_instance();
}
::google::protobuf::Any* ModelServerConfig::mutable_custom_model_config() {
  if (!has_custom_model_config()) {
    clear_config();
    set_has_custom_model_config();
    config_.custom_model_config_ = 
      ::google::protobuf::Arena::Create< ::google::protobuf::Any >(
      GetArenaNoVirtual());
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelServerConfig.custom_model_config)
  return config_.custom_model_config_;
}
::google::protobuf::Any* ModelServerConfig::release_custom_model_config() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelServerConfig.custom_model_config)
  if (has_custom_model_config()) {
    clear_has_config();
    if (GetArenaNoVirtual() != NULL) {
      ::google::protobuf::Any* temp = new ::google::protobuf::Any;
      temp->MergeFrom(*config_.custom_model_config_);
      config_.custom_model_config_ = NULL;
      return temp;
    } else {
      ::google::protobuf::Any* temp = config_.custom_model_config_;
      config_.custom_model_config_ = NULL;
      return temp;
    }
  } else {
    return NULL;
  }
}
void ModelServerConfig::set_allocated_custom_model_config(::google::protobuf::Any* custom_model_config) {
  clear_config();
  if (custom_model_config) {
    if (GetArenaNoVirtual() != NULL) {
      GetArenaNoVirtual()->Own(custom_model_config);
    }
    set_has_custom_model_config();
    config_.custom_model_config_ = custom_model_config;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelServerConfig.custom_model_config)
}
 ::google::protobuf::Any* ModelServerConfig::unsafe_arena_release_custom_model_config() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelServerConfig.custom_model_config)
  if (has_custom_model_config()) {
    clear_has_config();
    ::google::protobuf::Any* temp = config_.custom_model_config_;
    config_.custom_model_config_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
 void ModelServerConfig::unsafe_arena_set_allocated_custom_model_config(::google::protobuf::Any* custom_model_config) {
  clear_config();
  if (custom_model_config) {
    set_has_custom_model_config();
    config_.custom_model_config_ = custom_model_config;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelServerConfig.custom_model_config)
}

bool ModelServerConfig::has_config() const {
  return config_case() != CONFIG_NOT_SET;
}
void ModelServerConfig::clear_has_config() {
  _oneof_case_[0] = CONFIG_NOT_SET;
}
ModelServerConfig::ConfigCase ModelServerConfig::config_case() const {
  return ModelServerConfig::ConfigCase(_oneof_case_[0]);
}
#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace serving
}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
