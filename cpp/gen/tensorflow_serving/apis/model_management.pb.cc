// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/model_management.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow_serving/apis/model_management.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {
namespace serving {

namespace {

const ::google::protobuf::Descriptor* ReloadConfigRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ReloadConfigRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* ReloadConfigResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ReloadConfigResponse_reflection_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AssignDesc_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto() {
  protobuf_AddDesc_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow_serving/apis/model_management.proto");
  GOOGLE_CHECK(file != NULL);
  ReloadConfigRequest_descriptor_ = file->message_type(0);
  static const int ReloadConfigRequest_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ReloadConfigRequest, config_),
  };
  ReloadConfigRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ReloadConfigRequest_descriptor_,
      ReloadConfigRequest::default_instance_,
      ReloadConfigRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(ReloadConfigRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ReloadConfigRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ReloadConfigRequest, _is_default_instance_));
  ReloadConfigResponse_descriptor_ = file->message_type(1);
  static const int ReloadConfigResponse_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ReloadConfigResponse, status_),
  };
  ReloadConfigResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ReloadConfigResponse_descriptor_,
      ReloadConfigResponse::default_instance_,
      ReloadConfigResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(ReloadConfigResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ReloadConfigResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ReloadConfigResponse, _is_default_instance_));
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ReloadConfigRequest_descriptor_, &ReloadConfigRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ReloadConfigResponse_descriptor_, &ReloadConfigResponse::default_instance());
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto() {
  delete ReloadConfigRequest::default_instance_;
  delete ReloadConfigRequest_reflection_;
  delete ReloadConfigResponse::default_instance_;
  delete ReloadConfigResponse_reflection_;
}

void protobuf_AddDesc_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AddDesc_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::tensorflow::serving::protobuf_AddDesc_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto();
  ::tensorflow::serving::protobuf_AddDesc_tensorflow_5fserving_2futil_2fstatus_2eproto();
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n.tensorflow_serving/apis/model_manageme"
    "nt.proto\022\022tensorflow.serving\0323tensorflow"
    "_serving/config/model_server_config.prot"
    "o\032$tensorflow_serving/util/status.proto\""
    "L\n\023ReloadConfigRequest\0225\n\006config\030\001 \001(\0132%"
    ".tensorflow.serving.ModelServerConfig\"G\n"
    "\024ReloadConfigResponse\022/\n\006status\030\001 \001(\0132\037."
    "tensorflow.serving.StatusProtoB\003\370\001\001b\006pro"
    "to3", 323);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/apis/model_management.proto", &protobuf_RegisterTypes);
  ReloadConfigRequest::default_instance_ = new ReloadConfigRequest();
  ReloadConfigResponse::default_instance_ = new ReloadConfigResponse();
  ReloadConfigRequest::default_instance_->InitAsDefaultInstance();
  ReloadConfigResponse::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto {
  StaticDescriptorInitializer_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto() {
    protobuf_AddDesc_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto();
  }
} static_descriptor_initializer_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto_;

// ===================================================================

void ReloadConfigRequest::_slow_mutable_config() {
  config_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelServerConfig >(
      GetArenaNoVirtual());
}
::tensorflow::serving::ModelServerConfig* ReloadConfigRequest::_slow_release_config() {
  if (config_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::serving::ModelServerConfig* temp = new ::tensorflow::serving::ModelServerConfig;
    temp->MergeFrom(*config_);
    config_ = NULL;
    return temp;
  }
}
::tensorflow::serving::ModelServerConfig* ReloadConfigRequest::unsafe_arena_release_config() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ReloadConfigRequest.config)
  
  ::tensorflow::serving::ModelServerConfig* temp = config_;
  config_ = NULL;
  return temp;
}
void ReloadConfigRequest::_slow_set_allocated_config(
    ::google::protobuf::Arena* message_arena, ::tensorflow::serving::ModelServerConfig** config) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*config) == NULL) {
      message_arena->Own(*config);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*config)) {
      ::tensorflow::serving::ModelServerConfig* new_config = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelServerConfig >(
            message_arena);
      new_config->CopyFrom(**config);
      *config = new_config;
    }
}
void ReloadConfigRequest::unsafe_arena_set_allocated_config(
    ::tensorflow::serving::ModelServerConfig* config) {
  if (GetArenaNoVirtual() == NULL) {
    delete config_;
  }
  config_ = config;
  if (config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ReloadConfigRequest.config)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ReloadConfigRequest::kConfigFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ReloadConfigRequest::ReloadConfigRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ReloadConfigRequest)
}

ReloadConfigRequest::ReloadConfigRequest(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ReloadConfigRequest)
}

void ReloadConfigRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  config_ = const_cast< ::tensorflow::serving::ModelServerConfig*>(&::tensorflow::serving::ModelServerConfig::default_instance());
}

ReloadConfigRequest::ReloadConfigRequest(const ReloadConfigRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ReloadConfigRequest)
}

void ReloadConfigRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  config_ = NULL;
}

ReloadConfigRequest::~ReloadConfigRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ReloadConfigRequest)
  SharedDtor();
}

void ReloadConfigRequest::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
    delete config_;
  }
}

void ReloadConfigRequest::ArenaDtor(void* object) {
  ReloadConfigRequest* _this = reinterpret_cast< ReloadConfigRequest* >(object);
  (void)_this;
}
void ReloadConfigRequest::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ReloadConfigRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ReloadConfigRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ReloadConfigRequest_descriptor_;
}

const ReloadConfigRequest& ReloadConfigRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto();
  return *default_instance_;
}

ReloadConfigRequest* ReloadConfigRequest::default_instance_ = NULL;

ReloadConfigRequest* ReloadConfigRequest::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<ReloadConfigRequest>(arena);
}

void ReloadConfigRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ReloadConfigRequest)
  if (GetArenaNoVirtual() == NULL && config_ != NULL) delete config_;
  config_ = NULL;
}

bool ReloadConfigRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ReloadConfigRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.serving.ModelServerConfig config = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_config()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ReloadConfigRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ReloadConfigRequest)
  return false;
#undef DO_
}

void ReloadConfigRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ReloadConfigRequest)
  // optional .tensorflow.serving.ModelServerConfig config = 1;
  if (this->has_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->config_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ReloadConfigRequest)
}

::google::protobuf::uint8* ReloadConfigRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ReloadConfigRequest)
  // optional .tensorflow.serving.ModelServerConfig config = 1;
  if (this->has_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->config_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ReloadConfigRequest)
  return target;
}

int ReloadConfigRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ReloadConfigRequest)
  int total_size = 0;

  // optional .tensorflow.serving.ModelServerConfig config = 1;
  if (this->has_config()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->config_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ReloadConfigRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ReloadConfigRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const ReloadConfigRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ReloadConfigRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ReloadConfigRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ReloadConfigRequest)
    MergeFrom(*source);
  }
}

void ReloadConfigRequest::MergeFrom(const ReloadConfigRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ReloadConfigRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  if (from.has_config()) {
    mutable_config()->::tensorflow::serving::ModelServerConfig::MergeFrom(from.config());
  }
}

void ReloadConfigRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ReloadConfigRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ReloadConfigRequest::CopyFrom(const ReloadConfigRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ReloadConfigRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ReloadConfigRequest::IsInitialized() const {

  return true;
}

void ReloadConfigRequest::Swap(ReloadConfigRequest* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ReloadConfigRequest temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void ReloadConfigRequest::UnsafeArenaSwap(ReloadConfigRequest* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ReloadConfigRequest::InternalSwap(ReloadConfigRequest* other) {
  std::swap(config_, other->config_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ReloadConfigRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ReloadConfigRequest_descriptor_;
  metadata.reflection = ReloadConfigRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ReloadConfigRequest

// optional .tensorflow.serving.ModelServerConfig config = 1;
bool ReloadConfigRequest::has_config() const {
  return !_is_default_instance_ && config_ != NULL;
}
void ReloadConfigRequest::clear_config() {
  if (GetArenaNoVirtual() == NULL && config_ != NULL) delete config_;
  config_ = NULL;
}
const ::tensorflow::serving::ModelServerConfig& ReloadConfigRequest::config() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ReloadConfigRequest.config)
  return config_ != NULL ? *config_ : *default_instance_->config_;
}
::tensorflow::serving::ModelServerConfig* ReloadConfigRequest::mutable_config() {
  
  if (config_ == NULL) {
    _slow_mutable_config();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ReloadConfigRequest.config)
  return config_;
}
::tensorflow::serving::ModelServerConfig* ReloadConfigRequest::release_config() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ReloadConfigRequest.config)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_config();
  } else {
    ::tensorflow::serving::ModelServerConfig* temp = config_;
    config_ = NULL;
    return temp;
  }
}
 void ReloadConfigRequest::set_allocated_config(::tensorflow::serving::ModelServerConfig* config) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete config_;
  }
  if (config != NULL) {
    _slow_set_allocated_config(message_arena, &config);
  }
  config_ = config;
  if (config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ReloadConfigRequest.config)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

void ReloadConfigResponse::_slow_mutable_status() {
  status_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::StatusProto >(
      GetArenaNoVirtual());
}
::tensorflow::serving::StatusProto* ReloadConfigResponse::_slow_release_status() {
  if (status_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::serving::StatusProto* temp = new ::tensorflow::serving::StatusProto;
    temp->MergeFrom(*status_);
    status_ = NULL;
    return temp;
  }
}
::tensorflow::serving::StatusProto* ReloadConfigResponse::unsafe_arena_release_status() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ReloadConfigResponse.status)
  
  ::tensorflow::serving::StatusProto* temp = status_;
  status_ = NULL;
  return temp;
}
void ReloadConfigResponse::_slow_set_allocated_status(
    ::google::protobuf::Arena* message_arena, ::tensorflow::serving::StatusProto** status) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*status) == NULL) {
      message_arena->Own(*status);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*status)) {
      ::tensorflow::serving::StatusProto* new_status = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::StatusProto >(
            message_arena);
      new_status->CopyFrom(**status);
      *status = new_status;
    }
}
void ReloadConfigResponse::unsafe_arena_set_allocated_status(
    ::tensorflow::serving::StatusProto* status) {
  if (GetArenaNoVirtual() == NULL) {
    delete status_;
  }
  status_ = status;
  if (status) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ReloadConfigResponse.status)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ReloadConfigResponse::kStatusFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ReloadConfigResponse::ReloadConfigResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ReloadConfigResponse)
}

ReloadConfigResponse::ReloadConfigResponse(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ReloadConfigResponse)
}

void ReloadConfigResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  status_ = const_cast< ::tensorflow::serving::StatusProto*>(&::tensorflow::serving::StatusProto::default_instance());
}

ReloadConfigResponse::ReloadConfigResponse(const ReloadConfigResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ReloadConfigResponse)
}

void ReloadConfigResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  status_ = NULL;
}

ReloadConfigResponse::~ReloadConfigResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ReloadConfigResponse)
  SharedDtor();
}

void ReloadConfigResponse::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
    delete status_;
  }
}

void ReloadConfigResponse::ArenaDtor(void* object) {
  ReloadConfigResponse* _this = reinterpret_cast< ReloadConfigResponse* >(object);
  (void)_this;
}
void ReloadConfigResponse::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ReloadConfigResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ReloadConfigResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ReloadConfigResponse_descriptor_;
}

const ReloadConfigResponse& ReloadConfigResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_5fserving_2fapis_2fmodel_5fmanagement_2eproto();
  return *default_instance_;
}

ReloadConfigResponse* ReloadConfigResponse::default_instance_ = NULL;

ReloadConfigResponse* ReloadConfigResponse::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<ReloadConfigResponse>(arena);
}

void ReloadConfigResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ReloadConfigResponse)
  if (GetArenaNoVirtual() == NULL && status_ != NULL) delete status_;
  status_ = NULL;
}

bool ReloadConfigResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ReloadConfigResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.serving.StatusProto status = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_status()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ReloadConfigResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ReloadConfigResponse)
  return false;
#undef DO_
}

void ReloadConfigResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ReloadConfigResponse)
  // optional .tensorflow.serving.StatusProto status = 1;
  if (this->has_status()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->status_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ReloadConfigResponse)
}

::google::protobuf::uint8* ReloadConfigResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ReloadConfigResponse)
  // optional .tensorflow.serving.StatusProto status = 1;
  if (this->has_status()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->status_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ReloadConfigResponse)
  return target;
}

int ReloadConfigResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ReloadConfigResponse)
  int total_size = 0;

  // optional .tensorflow.serving.StatusProto status = 1;
  if (this->has_status()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->status_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ReloadConfigResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ReloadConfigResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const ReloadConfigResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ReloadConfigResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ReloadConfigResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ReloadConfigResponse)
    MergeFrom(*source);
  }
}

void ReloadConfigResponse::MergeFrom(const ReloadConfigResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ReloadConfigResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  if (from.has_status()) {
    mutable_status()->::tensorflow::serving::StatusProto::MergeFrom(from.status());
  }
}

void ReloadConfigResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ReloadConfigResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ReloadConfigResponse::CopyFrom(const ReloadConfigResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ReloadConfigResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ReloadConfigResponse::IsInitialized() const {

  return true;
}

void ReloadConfigResponse::Swap(ReloadConfigResponse* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ReloadConfigResponse temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void ReloadConfigResponse::UnsafeArenaSwap(ReloadConfigResponse* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ReloadConfigResponse::InternalSwap(ReloadConfigResponse* other) {
  std::swap(status_, other->status_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ReloadConfigResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ReloadConfigResponse_descriptor_;
  metadata.reflection = ReloadConfigResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ReloadConfigResponse

// optional .tensorflow.serving.StatusProto status = 1;
bool ReloadConfigResponse::has_status() const {
  return !_is_default_instance_ && status_ != NULL;
}
void ReloadConfigResponse::clear_status() {
  if (GetArenaNoVirtual() == NULL && status_ != NULL) delete status_;
  status_ = NULL;
}
const ::tensorflow::serving::StatusProto& ReloadConfigResponse::status() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ReloadConfigResponse.status)
  return status_ != NULL ? *status_ : *default_instance_->status_;
}
::tensorflow::serving::StatusProto* ReloadConfigResponse::mutable_status() {
  
  if (status_ == NULL) {
    _slow_mutable_status();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ReloadConfigResponse.status)
  return status_;
}
::tensorflow::serving::StatusProto* ReloadConfigResponse::release_status() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ReloadConfigResponse.status)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_status();
  } else {
    ::tensorflow::serving::StatusProto* temp = status_;
    status_ = NULL;
    return temp;
  }
}
 void ReloadConfigResponse::set_allocated_status(::tensorflow::serving::StatusProto* status) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete status_;
  }
  if (status != NULL) {
    _slow_set_allocated_status(message_arena, &status);
  }
  status_ = status;
  if (status) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ReloadConfigResponse.status)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace serving
}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
