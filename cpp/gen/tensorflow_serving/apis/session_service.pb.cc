// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/session_service.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow_serving/apis/session_service.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {
namespace serving {

namespace {

const ::google::protobuf::Descriptor* SessionRunRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  SessionRunRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* SessionRunResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  SessionRunResponse_reflection_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AssignDesc_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto() {
  protobuf_AddDesc_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow_serving/apis/session_service.proto");
  GOOGLE_CHECK(file != NULL);
  SessionRunRequest_descriptor_ = file->message_type(0);
  static const int SessionRunRequest_offsets_[5] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunRequest, model_spec_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunRequest, feed_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunRequest, fetch_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunRequest, target_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunRequest, options_),
  };
  SessionRunRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      SessionRunRequest_descriptor_,
      SessionRunRequest::default_instance_,
      SessionRunRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(SessionRunRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunRequest, _is_default_instance_));
  SessionRunResponse_descriptor_ = file->message_type(1);
  static const int SessionRunResponse_offsets_[3] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunResponse, model_spec_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunResponse, tensor_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunResponse, metadata_),
  };
  SessionRunResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      SessionRunResponse_descriptor_,
      SessionRunResponse::default_instance_,
      SessionRunResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(SessionRunResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionRunResponse, _is_default_instance_));
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      SessionRunRequest_descriptor_, &SessionRunRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      SessionRunResponse_descriptor_, &SessionRunResponse::default_instance());
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto() {
  delete SessionRunRequest::default_instance_;
  delete SessionRunRequest_reflection_;
  delete SessionRunResponse::default_instance_;
  delete SessionRunResponse_reflection_;
}

void protobuf_AddDesc_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AddDesc_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::tensorflow::serving::protobuf_AddDesc_tensorflow_5fserving_2fapis_2fmodel_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto();
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n-tensorflow_serving/apis/session_servic"
    "e.proto\022\022tensorflow.serving\032#tensorflow_"
    "serving/apis/model.proto\032%tensorflow/cor"
    "e/protobuf/config.proto\032+tensorflow/core"
    "/protobuf/named_tensor.proto\"\272\001\n\021Session"
    "RunRequest\0221\n\nmodel_spec\030\001 \001(\0132\035.tensorf"
    "low.serving.ModelSpec\022*\n\004feed\030\002 \003(\0132\034.te"
    "nsorflow.NamedTensorProto\022\r\n\005fetch\030\003 \003(\t"
    "\022\016\n\006target\030\004 \003(\t\022\'\n\007options\030\005 \001(\0132\026.tens"
    "orflow.RunOptions\"\240\001\n\022SessionRunResponse"
    "\0221\n\nmodel_spec\030\003 \001(\0132\035.tensorflow.servin"
    "g.ModelSpec\022,\n\006tensor\030\001 \003(\0132\034.tensorflow"
    ".NamedTensorProto\022)\n\010metadata\030\002 \001(\0132\027.te"
    "nsorflow.RunMetadata2m\n\016SessionService\022["
    "\n\nSessionRun\022%.tensorflow.serving.Sessio"
    "nRunRequest\032&.tensorflow.serving.Session"
    "RunResponseB\003\370\001\001b\006proto3", 664);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/apis/session_service.proto", &protobuf_RegisterTypes);
  SessionRunRequest::default_instance_ = new SessionRunRequest();
  SessionRunResponse::default_instance_ = new SessionRunResponse();
  SessionRunRequest::default_instance_->InitAsDefaultInstance();
  SessionRunResponse::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto {
  StaticDescriptorInitializer_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto() {
    protobuf_AddDesc_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto();
  }
} static_descriptor_initializer_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto_;

// ===================================================================

void SessionRunRequest::_slow_mutable_model_spec() {
  model_spec_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelSpec >(
      GetArenaNoVirtual());
}
::tensorflow::serving::ModelSpec* SessionRunRequest::_slow_release_model_spec() {
  if (model_spec_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::serving::ModelSpec* temp = new ::tensorflow::serving::ModelSpec;
    temp->MergeFrom(*model_spec_);
    model_spec_ = NULL;
    return temp;
  }
}
::tensorflow::serving::ModelSpec* SessionRunRequest::unsafe_arena_release_model_spec() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.SessionRunRequest.model_spec)
  
  ::tensorflow::serving::ModelSpec* temp = model_spec_;
  model_spec_ = NULL;
  return temp;
}
void SessionRunRequest::_slow_set_allocated_model_spec(
    ::google::protobuf::Arena* message_arena, ::tensorflow::serving::ModelSpec** model_spec) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*model_spec) == NULL) {
      message_arena->Own(*model_spec);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*model_spec)) {
      ::tensorflow::serving::ModelSpec* new_model_spec = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelSpec >(
            message_arena);
      new_model_spec->CopyFrom(**model_spec);
      *model_spec = new_model_spec;
    }
}
void SessionRunRequest::unsafe_arena_set_allocated_model_spec(
    ::tensorflow::serving::ModelSpec* model_spec) {
  if (GetArenaNoVirtual() == NULL) {
    delete model_spec_;
  }
  model_spec_ = model_spec;
  if (model_spec) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunRequest.model_spec)
}
void SessionRunRequest::_slow_mutable_options() {
  options_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::RunOptions >(
      GetArenaNoVirtual());
}
::tensorflow::RunOptions* SessionRunRequest::_slow_release_options() {
  if (options_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::RunOptions* temp = new ::tensorflow::RunOptions;
    temp->MergeFrom(*options_);
    options_ = NULL;
    return temp;
  }
}
::tensorflow::RunOptions* SessionRunRequest::unsafe_arena_release_options() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.SessionRunRequest.options)
  
  ::tensorflow::RunOptions* temp = options_;
  options_ = NULL;
  return temp;
}
void SessionRunRequest::_slow_set_allocated_options(
    ::google::protobuf::Arena* message_arena, ::tensorflow::RunOptions** options) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*options) == NULL) {
      message_arena->Own(*options);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*options)) {
      ::tensorflow::RunOptions* new_options = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::RunOptions >(
            message_arena);
      new_options->CopyFrom(**options);
      *options = new_options;
    }
}
void SessionRunRequest::unsafe_arena_set_allocated_options(
    ::tensorflow::RunOptions* options) {
  if (GetArenaNoVirtual() == NULL) {
    delete options_;
  }
  options_ = options;
  if (options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunRequest.options)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SessionRunRequest::kModelSpecFieldNumber;
const int SessionRunRequest::kFeedFieldNumber;
const int SessionRunRequest::kFetchFieldNumber;
const int SessionRunRequest::kTargetFieldNumber;
const int SessionRunRequest::kOptionsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SessionRunRequest::SessionRunRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.SessionRunRequest)
}

SessionRunRequest::SessionRunRequest(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  feed_(arena),
  fetch_(arena),
  target_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.SessionRunRequest)
}

void SessionRunRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  model_spec_ = const_cast< ::tensorflow::serving::ModelSpec*>(&::tensorflow::serving::ModelSpec::default_instance());
  options_ = const_cast< ::tensorflow::RunOptions*>(&::tensorflow::RunOptions::default_instance());
}

SessionRunRequest::SessionRunRequest(const SessionRunRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.SessionRunRequest)
}

void SessionRunRequest::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  model_spec_ = NULL;
  options_ = NULL;
}

SessionRunRequest::~SessionRunRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.SessionRunRequest)
  SharedDtor();
}

void SessionRunRequest::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
    delete model_spec_;
    delete options_;
  }
}

void SessionRunRequest::ArenaDtor(void* object) {
  SessionRunRequest* _this = reinterpret_cast< SessionRunRequest* >(object);
  (void)_this;
}
void SessionRunRequest::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void SessionRunRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SessionRunRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return SessionRunRequest_descriptor_;
}

const SessionRunRequest& SessionRunRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto();
  return *default_instance_;
}

SessionRunRequest* SessionRunRequest::default_instance_ = NULL;

SessionRunRequest* SessionRunRequest::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<SessionRunRequest>(arena);
}

void SessionRunRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.SessionRunRequest)
  if (GetArenaNoVirtual() == NULL && model_spec_ != NULL) delete model_spec_;
  model_spec_ = NULL;
  if (GetArenaNoVirtual() == NULL && options_ != NULL) delete options_;
  options_ = NULL;
  feed_.Clear();
  fetch_.Clear();
  target_.Clear();
}

bool SessionRunRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.SessionRunRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.serving.ModelSpec model_spec = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_model_spec()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_feed;
        break;
      }

      // repeated .tensorflow.NamedTensorProto feed = 2;
      case 2: {
        if (tag == 18) {
         parse_feed:
          DO_(input->IncrementRecursionDepth());
         parse_loop_feed:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_feed()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_loop_feed;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(26)) goto parse_fetch;
        break;
      }

      // repeated string fetch = 3;
      case 3: {
        if (tag == 26) {
         parse_fetch:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_fetch()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->fetch(this->fetch_size() - 1).data(),
            this->fetch(this->fetch_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.SessionRunRequest.fetch"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_fetch;
        if (input->ExpectTag(34)) goto parse_target;
        break;
      }

      // repeated string target = 4;
      case 4: {
        if (tag == 34) {
         parse_target:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_target()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->target(this->target_size() - 1).data(),
            this->target(this->target_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.SessionRunRequest.target"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_target;
        if (input->ExpectTag(42)) goto parse_options;
        break;
      }

      // optional .tensorflow.RunOptions options = 5;
      case 5: {
        if (tag == 42) {
         parse_options:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.SessionRunRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.SessionRunRequest)
  return false;
#undef DO_
}

void SessionRunRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.SessionRunRequest)
  // optional .tensorflow.serving.ModelSpec model_spec = 1;
  if (this->has_model_spec()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->model_spec_, output);
  }

  // repeated .tensorflow.NamedTensorProto feed = 2;
  for (unsigned int i = 0, n = this->feed_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->feed(i), output);
  }

  // repeated string fetch = 3;
  for (int i = 0; i < this->fetch_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->fetch(i).data(), this->fetch(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionRunRequest.fetch");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      3, this->fetch(i), output);
  }

  // repeated string target = 4;
  for (int i = 0; i < this->target_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->target(i).data(), this->target(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionRunRequest.target");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      4, this->target(i), output);
  }

  // optional .tensorflow.RunOptions options = 5;
  if (this->has_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      5, *this->options_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.SessionRunRequest)
}

::google::protobuf::uint8* SessionRunRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.SessionRunRequest)
  // optional .tensorflow.serving.ModelSpec model_spec = 1;
  if (this->has_model_spec()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->model_spec_, false, target);
  }

  // repeated .tensorflow.NamedTensorProto feed = 2;
  for (unsigned int i = 0, n = this->feed_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, this->feed(i), false, target);
  }

  // repeated string fetch = 3;
  for (int i = 0; i < this->fetch_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->fetch(i).data(), this->fetch(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionRunRequest.fetch");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(3, this->fetch(i), target);
  }

  // repeated string target = 4;
  for (int i = 0; i < this->target_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->target(i).data(), this->target(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionRunRequest.target");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(4, this->target(i), target);
  }

  // optional .tensorflow.RunOptions options = 5;
  if (this->has_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        5, *this->options_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.SessionRunRequest)
  return target;
}

int SessionRunRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.SessionRunRequest)
  int total_size = 0;

  // optional .tensorflow.serving.ModelSpec model_spec = 1;
  if (this->has_model_spec()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->model_spec_);
  }

  // optional .tensorflow.RunOptions options = 5;
  if (this->has_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->options_);
  }

  // repeated .tensorflow.NamedTensorProto feed = 2;
  total_size += 1 * this->feed_size();
  for (int i = 0; i < this->feed_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->feed(i));
  }

  // repeated string fetch = 3;
  total_size += 1 * this->fetch_size();
  for (int i = 0; i < this->fetch_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->fetch(i));
  }

  // repeated string target = 4;
  total_size += 1 * this->target_size();
  for (int i = 0; i < this->target_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->target(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SessionRunRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.SessionRunRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const SessionRunRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const SessionRunRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.SessionRunRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.SessionRunRequest)
    MergeFrom(*source);
  }
}

void SessionRunRequest::MergeFrom(const SessionRunRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.SessionRunRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  feed_.MergeFrom(from.feed_);
  fetch_.MergeFrom(from.fetch_);
  target_.MergeFrom(from.target_);
  if (from.has_model_spec()) {
    mutable_model_spec()->::tensorflow::serving::ModelSpec::MergeFrom(from.model_spec());
  }
  if (from.has_options()) {
    mutable_options()->::tensorflow::RunOptions::MergeFrom(from.options());
  }
}

void SessionRunRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.SessionRunRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SessionRunRequest::CopyFrom(const SessionRunRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.SessionRunRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SessionRunRequest::IsInitialized() const {

  return true;
}

void SessionRunRequest::Swap(SessionRunRequest* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    SessionRunRequest temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void SessionRunRequest::UnsafeArenaSwap(SessionRunRequest* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void SessionRunRequest::InternalSwap(SessionRunRequest* other) {
  std::swap(model_spec_, other->model_spec_);
  feed_.UnsafeArenaSwap(&other->feed_);
  fetch_.UnsafeArenaSwap(&other->fetch_);
  target_.UnsafeArenaSwap(&other->target_);
  std::swap(options_, other->options_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SessionRunRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = SessionRunRequest_descriptor_;
  metadata.reflection = SessionRunRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SessionRunRequest

// optional .tensorflow.serving.ModelSpec model_spec = 1;
bool SessionRunRequest::has_model_spec() const {
  return !_is_default_instance_ && model_spec_ != NULL;
}
void SessionRunRequest::clear_model_spec() {
  if (GetArenaNoVirtual() == NULL && model_spec_ != NULL) delete model_spec_;
  model_spec_ = NULL;
}
const ::tensorflow::serving::ModelSpec& SessionRunRequest::model_spec() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunRequest.model_spec)
  return model_spec_ != NULL ? *model_spec_ : *default_instance_->model_spec_;
}
::tensorflow::serving::ModelSpec* SessionRunRequest::mutable_model_spec() {
  
  if (model_spec_ == NULL) {
    _slow_mutable_model_spec();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunRequest.model_spec)
  return model_spec_;
}
::tensorflow::serving::ModelSpec* SessionRunRequest::release_model_spec() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionRunRequest.model_spec)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_model_spec();
  } else {
    ::tensorflow::serving::ModelSpec* temp = model_spec_;
    model_spec_ = NULL;
    return temp;
  }
}
 void SessionRunRequest::set_allocated_model_spec(::tensorflow::serving::ModelSpec* model_spec) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete model_spec_;
  }
  if (model_spec != NULL) {
    _slow_set_allocated_model_spec(message_arena, &model_spec);
  }
  model_spec_ = model_spec;
  if (model_spec) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionRunRequest.model_spec)
}

// repeated .tensorflow.NamedTensorProto feed = 2;
int SessionRunRequest::feed_size() const {
  return feed_.size();
}
void SessionRunRequest::clear_feed() {
  feed_.Clear();
}
const ::tensorflow::NamedTensorProto& SessionRunRequest::feed(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunRequest.feed)
  return feed_.Get(index);
}
::tensorflow::NamedTensorProto* SessionRunRequest::mutable_feed(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunRequest.feed)
  return feed_.Mutable(index);
}
::tensorflow::NamedTensorProto* SessionRunRequest::add_feed() {
  // @@protoc_insertion_point(field_add:tensorflow.serving.SessionRunRequest.feed)
  return feed_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensorProto >*
SessionRunRequest::mutable_feed() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.SessionRunRequest.feed)
  return &feed_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensorProto >&
SessionRunRequest::feed() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.SessionRunRequest.feed)
  return feed_;
}

// repeated string fetch = 3;
int SessionRunRequest::fetch_size() const {
  return fetch_.size();
}
void SessionRunRequest::clear_fetch() {
  fetch_.Clear();
}
 const ::std::string& SessionRunRequest::fetch(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunRequest.fetch)
  return fetch_.Get(index);
}
 ::std::string* SessionRunRequest::mutable_fetch(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunRequest.fetch)
  return fetch_.Mutable(index);
}
 void SessionRunRequest::set_fetch(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.serving.SessionRunRequest.fetch)
  fetch_.Mutable(index)->assign(value);
}
 void SessionRunRequest::set_fetch(int index, const char* value) {
  fetch_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.SessionRunRequest.fetch)
}
 void SessionRunRequest::set_fetch(int index, const char* value, size_t size) {
  fetch_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.SessionRunRequest.fetch)
}
 ::std::string* SessionRunRequest::add_fetch() {
  // @@protoc_insertion_point(field_add_mutable:tensorflow.serving.SessionRunRequest.fetch)
  return fetch_.Add();
}
 void SessionRunRequest::add_fetch(const ::std::string& value) {
  fetch_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.serving.SessionRunRequest.fetch)
}
 void SessionRunRequest::add_fetch(const char* value) {
  fetch_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.serving.SessionRunRequest.fetch)
}
 void SessionRunRequest::add_fetch(const char* value, size_t size) {
  fetch_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.serving.SessionRunRequest.fetch)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
SessionRunRequest::fetch() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.SessionRunRequest.fetch)
  return fetch_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
SessionRunRequest::mutable_fetch() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.SessionRunRequest.fetch)
  return &fetch_;
}

// repeated string target = 4;
int SessionRunRequest::target_size() const {
  return target_.size();
}
void SessionRunRequest::clear_target() {
  target_.Clear();
}
 const ::std::string& SessionRunRequest::target(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunRequest.target)
  return target_.Get(index);
}
 ::std::string* SessionRunRequest::mutable_target(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunRequest.target)
  return target_.Mutable(index);
}
 void SessionRunRequest::set_target(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.serving.SessionRunRequest.target)
  target_.Mutable(index)->assign(value);
}
 void SessionRunRequest::set_target(int index, const char* value) {
  target_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.SessionRunRequest.target)
}
 void SessionRunRequest::set_target(int index, const char* value, size_t size) {
  target_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.SessionRunRequest.target)
}
 ::std::string* SessionRunRequest::add_target() {
  // @@protoc_insertion_point(field_add_mutable:tensorflow.serving.SessionRunRequest.target)
  return target_.Add();
}
 void SessionRunRequest::add_target(const ::std::string& value) {
  target_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.serving.SessionRunRequest.target)
}
 void SessionRunRequest::add_target(const char* value) {
  target_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.serving.SessionRunRequest.target)
}
 void SessionRunRequest::add_target(const char* value, size_t size) {
  target_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.serving.SessionRunRequest.target)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
SessionRunRequest::target() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.SessionRunRequest.target)
  return target_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
SessionRunRequest::mutable_target() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.SessionRunRequest.target)
  return &target_;
}

// optional .tensorflow.RunOptions options = 5;
bool SessionRunRequest::has_options() const {
  return !_is_default_instance_ && options_ != NULL;
}
void SessionRunRequest::clear_options() {
  if (GetArenaNoVirtual() == NULL && options_ != NULL) delete options_;
  options_ = NULL;
}
const ::tensorflow::RunOptions& SessionRunRequest::options() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunRequest.options)
  return options_ != NULL ? *options_ : *default_instance_->options_;
}
::tensorflow::RunOptions* SessionRunRequest::mutable_options() {
  
  if (options_ == NULL) {
    _slow_mutable_options();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunRequest.options)
  return options_;
}
::tensorflow::RunOptions* SessionRunRequest::release_options() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionRunRequest.options)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_options();
  } else {
    ::tensorflow::RunOptions* temp = options_;
    options_ = NULL;
    return temp;
  }
}
 void SessionRunRequest::set_allocated_options(::tensorflow::RunOptions* options) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete options_;
  }
  if (options != NULL) {
    _slow_set_allocated_options(message_arena, &options);
  }
  options_ = options;
  if (options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionRunRequest.options)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

void SessionRunResponse::_slow_mutable_model_spec() {
  model_spec_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelSpec >(
      GetArenaNoVirtual());
}
::tensorflow::serving::ModelSpec* SessionRunResponse::_slow_release_model_spec() {
  if (model_spec_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::serving::ModelSpec* temp = new ::tensorflow::serving::ModelSpec;
    temp->MergeFrom(*model_spec_);
    model_spec_ = NULL;
    return temp;
  }
}
::tensorflow::serving::ModelSpec* SessionRunResponse::unsafe_arena_release_model_spec() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.SessionRunResponse.model_spec)
  
  ::tensorflow::serving::ModelSpec* temp = model_spec_;
  model_spec_ = NULL;
  return temp;
}
void SessionRunResponse::_slow_set_allocated_model_spec(
    ::google::protobuf::Arena* message_arena, ::tensorflow::serving::ModelSpec** model_spec) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*model_spec) == NULL) {
      message_arena->Own(*model_spec);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*model_spec)) {
      ::tensorflow::serving::ModelSpec* new_model_spec = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelSpec >(
            message_arena);
      new_model_spec->CopyFrom(**model_spec);
      *model_spec = new_model_spec;
    }
}
void SessionRunResponse::unsafe_arena_set_allocated_model_spec(
    ::tensorflow::serving::ModelSpec* model_spec) {
  if (GetArenaNoVirtual() == NULL) {
    delete model_spec_;
  }
  model_spec_ = model_spec;
  if (model_spec) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunResponse.model_spec)
}
void SessionRunResponse::_slow_mutable_metadata() {
  metadata_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::RunMetadata >(
      GetArenaNoVirtual());
}
::tensorflow::RunMetadata* SessionRunResponse::_slow_release_metadata() {
  if (metadata_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::RunMetadata* temp = new ::tensorflow::RunMetadata;
    temp->MergeFrom(*metadata_);
    metadata_ = NULL;
    return temp;
  }
}
::tensorflow::RunMetadata* SessionRunResponse::unsafe_arena_release_metadata() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.SessionRunResponse.metadata)
  
  ::tensorflow::RunMetadata* temp = metadata_;
  metadata_ = NULL;
  return temp;
}
void SessionRunResponse::_slow_set_allocated_metadata(
    ::google::protobuf::Arena* message_arena, ::tensorflow::RunMetadata** metadata) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*metadata) == NULL) {
      message_arena->Own(*metadata);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*metadata)) {
      ::tensorflow::RunMetadata* new_metadata = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::RunMetadata >(
            message_arena);
      new_metadata->CopyFrom(**metadata);
      *metadata = new_metadata;
    }
}
void SessionRunResponse::unsafe_arena_set_allocated_metadata(
    ::tensorflow::RunMetadata* metadata) {
  if (GetArenaNoVirtual() == NULL) {
    delete metadata_;
  }
  metadata_ = metadata;
  if (metadata) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunResponse.metadata)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SessionRunResponse::kModelSpecFieldNumber;
const int SessionRunResponse::kTensorFieldNumber;
const int SessionRunResponse::kMetadataFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SessionRunResponse::SessionRunResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.SessionRunResponse)
}

SessionRunResponse::SessionRunResponse(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  tensor_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.SessionRunResponse)
}

void SessionRunResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  model_spec_ = const_cast< ::tensorflow::serving::ModelSpec*>(&::tensorflow::serving::ModelSpec::default_instance());
  metadata_ = const_cast< ::tensorflow::RunMetadata*>(&::tensorflow::RunMetadata::default_instance());
}

SessionRunResponse::SessionRunResponse(const SessionRunResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.SessionRunResponse)
}

void SessionRunResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  model_spec_ = NULL;
  metadata_ = NULL;
}

SessionRunResponse::~SessionRunResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.SessionRunResponse)
  SharedDtor();
}

void SessionRunResponse::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
    delete model_spec_;
    delete metadata_;
  }
}

void SessionRunResponse::ArenaDtor(void* object) {
  SessionRunResponse* _this = reinterpret_cast< SessionRunResponse* >(object);
  (void)_this;
}
void SessionRunResponse::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void SessionRunResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SessionRunResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return SessionRunResponse_descriptor_;
}

const SessionRunResponse& SessionRunResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto();
  return *default_instance_;
}

SessionRunResponse* SessionRunResponse::default_instance_ = NULL;

SessionRunResponse* SessionRunResponse::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<SessionRunResponse>(arena);
}

void SessionRunResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.SessionRunResponse)
  if (GetArenaNoVirtual() == NULL && model_spec_ != NULL) delete model_spec_;
  model_spec_ = NULL;
  if (GetArenaNoVirtual() == NULL && metadata_ != NULL) delete metadata_;
  metadata_ = NULL;
  tensor_.Clear();
}

bool SessionRunResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.SessionRunResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.NamedTensorProto tensor = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_tensor:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_tensor()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_tensor;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(18)) goto parse_metadata;
        break;
      }

      // optional .tensorflow.RunMetadata metadata = 2;
      case 2: {
        if (tag == 18) {
         parse_metadata:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_metadata()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_model_spec;
        break;
      }

      // optional .tensorflow.serving.ModelSpec model_spec = 3;
      case 3: {
        if (tag == 26) {
         parse_model_spec:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_model_spec()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.SessionRunResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.SessionRunResponse)
  return false;
#undef DO_
}

void SessionRunResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.SessionRunResponse)
  // repeated .tensorflow.NamedTensorProto tensor = 1;
  for (unsigned int i = 0, n = this->tensor_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->tensor(i), output);
  }

  // optional .tensorflow.RunMetadata metadata = 2;
  if (this->has_metadata()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->metadata_, output);
  }

  // optional .tensorflow.serving.ModelSpec model_spec = 3;
  if (this->has_model_spec()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, *this->model_spec_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.SessionRunResponse)
}

::google::protobuf::uint8* SessionRunResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.SessionRunResponse)
  // repeated .tensorflow.NamedTensorProto tensor = 1;
  for (unsigned int i = 0, n = this->tensor_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, this->tensor(i), false, target);
  }

  // optional .tensorflow.RunMetadata metadata = 2;
  if (this->has_metadata()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *this->metadata_, false, target);
  }

  // optional .tensorflow.serving.ModelSpec model_spec = 3;
  if (this->has_model_spec()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        3, *this->model_spec_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.SessionRunResponse)
  return target;
}

int SessionRunResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.SessionRunResponse)
  int total_size = 0;

  // optional .tensorflow.serving.ModelSpec model_spec = 3;
  if (this->has_model_spec()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->model_spec_);
  }

  // optional .tensorflow.RunMetadata metadata = 2;
  if (this->has_metadata()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->metadata_);
  }

  // repeated .tensorflow.NamedTensorProto tensor = 1;
  total_size += 1 * this->tensor_size();
  for (int i = 0; i < this->tensor_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->tensor(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SessionRunResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.SessionRunResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const SessionRunResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const SessionRunResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.SessionRunResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.SessionRunResponse)
    MergeFrom(*source);
  }
}

void SessionRunResponse::MergeFrom(const SessionRunResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.SessionRunResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  tensor_.MergeFrom(from.tensor_);
  if (from.has_model_spec()) {
    mutable_model_spec()->::tensorflow::serving::ModelSpec::MergeFrom(from.model_spec());
  }
  if (from.has_metadata()) {
    mutable_metadata()->::tensorflow::RunMetadata::MergeFrom(from.metadata());
  }
}

void SessionRunResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.SessionRunResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SessionRunResponse::CopyFrom(const SessionRunResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.SessionRunResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SessionRunResponse::IsInitialized() const {

  return true;
}

void SessionRunResponse::Swap(SessionRunResponse* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    SessionRunResponse temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void SessionRunResponse::UnsafeArenaSwap(SessionRunResponse* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void SessionRunResponse::InternalSwap(SessionRunResponse* other) {
  std::swap(model_spec_, other->model_spec_);
  tensor_.UnsafeArenaSwap(&other->tensor_);
  std::swap(metadata_, other->metadata_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SessionRunResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = SessionRunResponse_descriptor_;
  metadata.reflection = SessionRunResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SessionRunResponse

// optional .tensorflow.serving.ModelSpec model_spec = 3;
bool SessionRunResponse::has_model_spec() const {
  return !_is_default_instance_ && model_spec_ != NULL;
}
void SessionRunResponse::clear_model_spec() {
  if (GetArenaNoVirtual() == NULL && model_spec_ != NULL) delete model_spec_;
  model_spec_ = NULL;
}
const ::tensorflow::serving::ModelSpec& SessionRunResponse::model_spec() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunResponse.model_spec)
  return model_spec_ != NULL ? *model_spec_ : *default_instance_->model_spec_;
}
::tensorflow::serving::ModelSpec* SessionRunResponse::mutable_model_spec() {
  
  if (model_spec_ == NULL) {
    _slow_mutable_model_spec();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunResponse.model_spec)
  return model_spec_;
}
::tensorflow::serving::ModelSpec* SessionRunResponse::release_model_spec() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionRunResponse.model_spec)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_model_spec();
  } else {
    ::tensorflow::serving::ModelSpec* temp = model_spec_;
    model_spec_ = NULL;
    return temp;
  }
}
 void SessionRunResponse::set_allocated_model_spec(::tensorflow::serving::ModelSpec* model_spec) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete model_spec_;
  }
  if (model_spec != NULL) {
    _slow_set_allocated_model_spec(message_arena, &model_spec);
  }
  model_spec_ = model_spec;
  if (model_spec) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionRunResponse.model_spec)
}

// repeated .tensorflow.NamedTensorProto tensor = 1;
int SessionRunResponse::tensor_size() const {
  return tensor_.size();
}
void SessionRunResponse::clear_tensor() {
  tensor_.Clear();
}
const ::tensorflow::NamedTensorProto& SessionRunResponse::tensor(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunResponse.tensor)
  return tensor_.Get(index);
}
::tensorflow::NamedTensorProto* SessionRunResponse::mutable_tensor(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunResponse.tensor)
  return tensor_.Mutable(index);
}
::tensorflow::NamedTensorProto* SessionRunResponse::add_tensor() {
  // @@protoc_insertion_point(field_add:tensorflow.serving.SessionRunResponse.tensor)
  return tensor_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensorProto >*
SessionRunResponse::mutable_tensor() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.SessionRunResponse.tensor)
  return &tensor_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensorProto >&
SessionRunResponse::tensor() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.SessionRunResponse.tensor)
  return tensor_;
}

// optional .tensorflow.RunMetadata metadata = 2;
bool SessionRunResponse::has_metadata() const {
  return !_is_default_instance_ && metadata_ != NULL;
}
void SessionRunResponse::clear_metadata() {
  if (GetArenaNoVirtual() == NULL && metadata_ != NULL) delete metadata_;
  metadata_ = NULL;
}
const ::tensorflow::RunMetadata& SessionRunResponse::metadata() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunResponse.metadata)
  return metadata_ != NULL ? *metadata_ : *default_instance_->metadata_;
}
::tensorflow::RunMetadata* SessionRunResponse::mutable_metadata() {
  
  if (metadata_ == NULL) {
    _slow_mutable_metadata();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunResponse.metadata)
  return metadata_;
}
::tensorflow::RunMetadata* SessionRunResponse::release_metadata() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionRunResponse.metadata)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_metadata();
  } else {
    ::tensorflow::RunMetadata* temp = metadata_;
    metadata_ = NULL;
    return temp;
  }
}
 void SessionRunResponse::set_allocated_metadata(::tensorflow::RunMetadata* metadata) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete metadata_;
  }
  if (metadata != NULL) {
    _slow_set_allocated_metadata(message_arena, &metadata);
  }
  metadata_ = metadata;
  if (metadata) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionRunResponse.metadata)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace serving
}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
