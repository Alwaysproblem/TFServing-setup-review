// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/get_model_status.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow_serving/apis/get_model_status.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {
namespace serving {

namespace {

const ::google::protobuf::Descriptor* GetModelStatusRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  GetModelStatusRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* ModelVersionStatus_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ModelVersionStatus_reflection_ = NULL;
const ::google::protobuf::EnumDescriptor* ModelVersionStatus_State_descriptor_ = NULL;
const ::google::protobuf::Descriptor* GetModelStatusResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  GetModelStatusResponse_reflection_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AssignDesc_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto() {
  protobuf_AddDesc_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow_serving/apis/get_model_status.proto");
  GOOGLE_CHECK(file != NULL);
  GetModelStatusRequest_descriptor_ = file->message_type(0);
  static const int GetModelStatusRequest_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GetModelStatusRequest, model_spec_),
  };
  GetModelStatusRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      GetModelStatusRequest_descriptor_,
      GetModelStatusRequest::default_instance_,
      GetModelStatusRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(GetModelStatusRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GetModelStatusRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GetModelStatusRequest, _is_default_instance_));
  ModelVersionStatus_descriptor_ = file->message_type(1);
  static const int ModelVersionStatus_offsets_[3] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelVersionStatus, version_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelVersionStatus, state_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelVersionStatus, status_),
  };
  ModelVersionStatus_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ModelVersionStatus_descriptor_,
      ModelVersionStatus::default_instance_,
      ModelVersionStatus_offsets_,
      -1,
      -1,
      -1,
      sizeof(ModelVersionStatus),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelVersionStatus, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelVersionStatus, _is_default_instance_));
  ModelVersionStatus_State_descriptor_ = ModelVersionStatus_descriptor_->enum_type(0);
  GetModelStatusResponse_descriptor_ = file->message_type(2);
  static const int GetModelStatusResponse_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GetModelStatusResponse, model_version_status_),
  };
  GetModelStatusResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      GetModelStatusResponse_descriptor_,
      GetModelStatusResponse::default_instance_,
      GetModelStatusResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(GetModelStatusResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GetModelStatusResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GetModelStatusResponse, _is_default_instance_));
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      GetModelStatusRequest_descriptor_, &GetModelStatusRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ModelVersionStatus_descriptor_, &ModelVersionStatus::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      GetModelStatusResponse_descriptor_, &GetModelStatusResponse::default_instance());
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto() {
  delete GetModelStatusRequest::default_instance_;
  delete GetModelStatusRequest_reflection_;
  delete ModelVersionStatus::default_instance_;
  delete ModelVersionStatus_reflection_;
  delete GetModelStatusResponse::default_instance_;
  delete GetModelStatusResponse_reflection_;
}

void protobuf_AddDesc_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AddDesc_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::tensorflow::serving::protobuf_AddDesc_tensorflow_5fserving_2fapis_2fmodel_2eproto();
  ::tensorflow::serving::protobuf_AddDesc_tensorflow_5fserving_2futil_2fstatus_2eproto();
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n.tensorflow_serving/apis/get_model_stat"
    "us.proto\022\022tensorflow.serving\032#tensorflow"
    "_serving/apis/model.proto\032$tensorflow_se"
    "rving/util/status.proto\"J\n\025GetModelStatu"
    "sRequest\0221\n\nmodel_spec\030\001 \001(\0132\035.tensorflo"
    "w.serving.ModelSpec\"\350\001\n\022ModelVersionStat"
    "us\022\017\n\007version\030\001 \001(\003\022;\n\005state\030\002 \001(\0162,.ten"
    "sorflow.serving.ModelVersionStatus.State"
    "\022/\n\006status\030\003 \001(\0132\037.tensorflow.serving.St"
    "atusProto\"S\n\005State\022\013\n\007UNKNOWN\020\000\022\t\n\005START"
    "\020\n\022\013\n\007LOADING\020\024\022\r\n\tAVAILABLE\020\036\022\r\n\tUNLOAD"
    "ING\020(\022\007\n\003END\0202\"t\n\026GetModelStatusResponse"
    "\022Z\n\024model_version_status\030\001 \003(\0132&.tensorf"
    "low.serving.ModelVersionStatusR\024model_ve"
    "rsion_statusB\003\370\001\001b\006proto3", 585);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/apis/get_model_status.proto", &protobuf_RegisterTypes);
  GetModelStatusRequest::default_instance_ = new GetModelStatusRequest();
  ModelVersionStatus::default_instance_ = new ModelVersionStatus();
  GetModelStatusResponse::default_instance_ = new GetModelStatusResponse();
  GetModelStatusRequest::default_instance_->InitAsDefaultInstance();
  ModelVersionStatus::default_instance_->InitAsDefaultInstance();
  GetModelStatusResponse::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto {
  StaticDescriptorInitializer_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto() {
    protobuf_AddDesc_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto();
  }
} static_descriptor_initializer_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto_;

// ===================================================================

void GetModelStatusRequest::_slow_mutable_model_spec() {
  model_spec_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelSpec >(
      GetArenaNoVirtual());
}
::tensorflow::serving::ModelSpec* GetModelStatusRequest::_slow_release_model_spec() {
  if (model_spec_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::serving::ModelSpec* temp = new ::tensorflow::serving::ModelSpec;
    temp->MergeFrom(*model_spec_);
    model_spec_ = NULL;
    return temp;
  }
}
::tensorflow::serving::ModelSpec* GetModelStatusRequest::unsafe_arena_release_model_spec() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.GetModelStatusRequest.model_spec)
  
  ::tensorflow::serving::ModelSpec* temp = model_spec_;
  model_spec_ = NULL;
  return temp;
}
void GetModelStatusRequest::_slow_set_allocated_model_spec(
    ::google::protobuf::Arena* message_arena, ::tensorflow::serving::ModelSpec** model_spec) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*model_spec) == NULL) {
      message_arena->Own(*model_spec);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*model_spec)) {
      ::tensorflow::serving::ModelSpec* new_model_spec = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelSpec >(
            message_arena);
      new_model_spec->CopyFrom(**model_spec);
      *model_spec = new_model_spec;
    }
}
void GetModelStatusRequest::unsafe_arena_set_allocated_model_spec(
    ::tensorflow::serving::ModelSpec* model_spec) {
  if (GetArenaNoVirtual() == NULL) {
    delete model_spec_;
  }
  model_spec_ = model_spec;
  if (model_spec) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.GetModelStatusRequest.model_spec)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int GetModelStatusRequest::kModelSpecFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

GetModelStatusRequest::GetModelStatusRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.GetModelStatusRequest)
}

GetModelStatusRequest::GetModelStatusRequest(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.GetModelStatusRequest)
}

void GetModelStatusRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  model_spec_ = const_cast< ::tensorflow::serving::ModelSpec*>(&::tensorflow::serving::ModelSpec::default_instance());
}

GetModelStatusRequest::GetModelStatusRequest(const GetModelStatusRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.GetModelStatusRequest)
}

void GetModelStatusRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  model_spec_ = NULL;
}

GetModelStatusRequest::~GetModelStatusRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.GetModelStatusRequest)
  SharedDtor();
}

void GetModelStatusRequest::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
    delete model_spec_;
  }
}

void GetModelStatusRequest::ArenaDtor(void* object) {
  GetModelStatusRequest* _this = reinterpret_cast< GetModelStatusRequest* >(object);
  (void)_this;
}
void GetModelStatusRequest::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void GetModelStatusRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* GetModelStatusRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return GetModelStatusRequest_descriptor_;
}

const GetModelStatusRequest& GetModelStatusRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto();
  return *default_instance_;
}

GetModelStatusRequest* GetModelStatusRequest::default_instance_ = NULL;

GetModelStatusRequest* GetModelStatusRequest::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<GetModelStatusRequest>(arena);
}

void GetModelStatusRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.GetModelStatusRequest)
  if (GetArenaNoVirtual() == NULL && model_spec_ != NULL) delete model_spec_;
  model_spec_ = NULL;
}

bool GetModelStatusRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.GetModelStatusRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.serving.ModelSpec model_spec = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_model_spec()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.GetModelStatusRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.GetModelStatusRequest)
  return false;
#undef DO_
}

void GetModelStatusRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.GetModelStatusRequest)
  // optional .tensorflow.serving.ModelSpec model_spec = 1;
  if (this->has_model_spec()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->model_spec_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.GetModelStatusRequest)
}

::google::protobuf::uint8* GetModelStatusRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.GetModelStatusRequest)
  // optional .tensorflow.serving.ModelSpec model_spec = 1;
  if (this->has_model_spec()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->model_spec_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.GetModelStatusRequest)
  return target;
}

int GetModelStatusRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.GetModelStatusRequest)
  int total_size = 0;

  // optional .tensorflow.serving.ModelSpec model_spec = 1;
  if (this->has_model_spec()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->model_spec_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void GetModelStatusRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.GetModelStatusRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const GetModelStatusRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const GetModelStatusRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.GetModelStatusRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.GetModelStatusRequest)
    MergeFrom(*source);
  }
}

void GetModelStatusRequest::MergeFrom(const GetModelStatusRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.GetModelStatusRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  if (from.has_model_spec()) {
    mutable_model_spec()->::tensorflow::serving::ModelSpec::MergeFrom(from.model_spec());
  }
}

void GetModelStatusRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.GetModelStatusRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void GetModelStatusRequest::CopyFrom(const GetModelStatusRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.GetModelStatusRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool GetModelStatusRequest::IsInitialized() const {

  return true;
}

void GetModelStatusRequest::Swap(GetModelStatusRequest* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    GetModelStatusRequest temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void GetModelStatusRequest::UnsafeArenaSwap(GetModelStatusRequest* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void GetModelStatusRequest::InternalSwap(GetModelStatusRequest* other) {
  std::swap(model_spec_, other->model_spec_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata GetModelStatusRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = GetModelStatusRequest_descriptor_;
  metadata.reflection = GetModelStatusRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// GetModelStatusRequest

// optional .tensorflow.serving.ModelSpec model_spec = 1;
bool GetModelStatusRequest::has_model_spec() const {
  return !_is_default_instance_ && model_spec_ != NULL;
}
void GetModelStatusRequest::clear_model_spec() {
  if (GetArenaNoVirtual() == NULL && model_spec_ != NULL) delete model_spec_;
  model_spec_ = NULL;
}
const ::tensorflow::serving::ModelSpec& GetModelStatusRequest::model_spec() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.GetModelStatusRequest.model_spec)
  return model_spec_ != NULL ? *model_spec_ : *default_instance_->model_spec_;
}
::tensorflow::serving::ModelSpec* GetModelStatusRequest::mutable_model_spec() {
  
  if (model_spec_ == NULL) {
    _slow_mutable_model_spec();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.GetModelStatusRequest.model_spec)
  return model_spec_;
}
::tensorflow::serving::ModelSpec* GetModelStatusRequest::release_model_spec() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.GetModelStatusRequest.model_spec)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_model_spec();
  } else {
    ::tensorflow::serving::ModelSpec* temp = model_spec_;
    model_spec_ = NULL;
    return temp;
  }
}
 void GetModelStatusRequest::set_allocated_model_spec(::tensorflow::serving::ModelSpec* model_spec) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete model_spec_;
  }
  if (model_spec != NULL) {
    _slow_set_allocated_model_spec(message_arena, &model_spec);
  }
  model_spec_ = model_spec;
  if (model_spec) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.GetModelStatusRequest.model_spec)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

const ::google::protobuf::EnumDescriptor* ModelVersionStatus_State_descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ModelVersionStatus_State_descriptor_;
}
bool ModelVersionStatus_State_IsValid(int value) {
  switch(value) {
    case 0:
    case 10:
    case 20:
    case 30:
    case 40:
    case 50:
      return true;
    default:
      return false;
  }
}

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const ModelVersionStatus_State ModelVersionStatus::UNKNOWN;
const ModelVersionStatus_State ModelVersionStatus::START;
const ModelVersionStatus_State ModelVersionStatus::LOADING;
const ModelVersionStatus_State ModelVersionStatus::AVAILABLE;
const ModelVersionStatus_State ModelVersionStatus::UNLOADING;
const ModelVersionStatus_State ModelVersionStatus::END;
const ModelVersionStatus_State ModelVersionStatus::State_MIN;
const ModelVersionStatus_State ModelVersionStatus::State_MAX;
const int ModelVersionStatus::State_ARRAYSIZE;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
void ModelVersionStatus::_slow_mutable_status() {
  status_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::StatusProto >(
      GetArenaNoVirtual());
}
::tensorflow::serving::StatusProto* ModelVersionStatus::_slow_release_status() {
  if (status_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::serving::StatusProto* temp = new ::tensorflow::serving::StatusProto;
    temp->MergeFrom(*status_);
    status_ = NULL;
    return temp;
  }
}
::tensorflow::serving::StatusProto* ModelVersionStatus::unsafe_arena_release_status() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelVersionStatus.status)
  
  ::tensorflow::serving::StatusProto* temp = status_;
  status_ = NULL;
  return temp;
}
void ModelVersionStatus::_slow_set_allocated_status(
    ::google::protobuf::Arena* message_arena, ::tensorflow::serving::StatusProto** status) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*status) == NULL) {
      message_arena->Own(*status);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*status)) {
      ::tensorflow::serving::StatusProto* new_status = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::StatusProto >(
            message_arena);
      new_status->CopyFrom(**status);
      *status = new_status;
    }
}
void ModelVersionStatus::unsafe_arena_set_allocated_status(
    ::tensorflow::serving::StatusProto* status) {
  if (GetArenaNoVirtual() == NULL) {
    delete status_;
  }
  status_ = status;
  if (status) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelVersionStatus.status)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ModelVersionStatus::kVersionFieldNumber;
const int ModelVersionStatus::kStateFieldNumber;
const int ModelVersionStatus::kStatusFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ModelVersionStatus::ModelVersionStatus()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ModelVersionStatus)
}

ModelVersionStatus::ModelVersionStatus(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ModelVersionStatus)
}

void ModelVersionStatus::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  status_ = const_cast< ::tensorflow::serving::StatusProto*>(&::tensorflow::serving::StatusProto::default_instance());
}

ModelVersionStatus::ModelVersionStatus(const ModelVersionStatus& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ModelVersionStatus)
}

void ModelVersionStatus::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  version_ = GOOGLE_LONGLONG(0);
  state_ = 0;
  status_ = NULL;
}

ModelVersionStatus::~ModelVersionStatus() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ModelVersionStatus)
  SharedDtor();
}

void ModelVersionStatus::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
    delete status_;
  }
}

void ModelVersionStatus::ArenaDtor(void* object) {
  ModelVersionStatus* _this = reinterpret_cast< ModelVersionStatus* >(object);
  (void)_this;
}
void ModelVersionStatus::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ModelVersionStatus::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ModelVersionStatus::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ModelVersionStatus_descriptor_;
}

const ModelVersionStatus& ModelVersionStatus::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto();
  return *default_instance_;
}

ModelVersionStatus* ModelVersionStatus::default_instance_ = NULL;

ModelVersionStatus* ModelVersionStatus::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<ModelVersionStatus>(arena);
}

void ModelVersionStatus::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ModelVersionStatus)
  version_ = GOOGLE_LONGLONG(0);
  state_ = 0;
  if (GetArenaNoVirtual() == NULL && status_ != NULL) delete status_;
  status_ = NULL;
}

bool ModelVersionStatus::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ModelVersionStatus)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int64 version = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &version_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_state;
        break;
      }

      // optional .tensorflow.serving.ModelVersionStatus.State state = 2;
      case 2: {
        if (tag == 16) {
         parse_state:
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_state(static_cast< ::tensorflow::serving::ModelVersionStatus_State >(value));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_status;
        break;
      }

      // optional .tensorflow.serving.StatusProto status = 3;
      case 3: {
        if (tag == 26) {
         parse_status:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_status()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ModelVersionStatus)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ModelVersionStatus)
  return false;
#undef DO_
}

void ModelVersionStatus::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ModelVersionStatus)
  // optional int64 version = 1;
  if (this->version() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(1, this->version(), output);
  }

  // optional .tensorflow.serving.ModelVersionStatus.State state = 2;
  if (this->state() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      2, this->state(), output);
  }

  // optional .tensorflow.serving.StatusProto status = 3;
  if (this->has_status()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, *this->status_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ModelVersionStatus)
}

::google::protobuf::uint8* ModelVersionStatus::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ModelVersionStatus)
  // optional int64 version = 1;
  if (this->version() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(1, this->version(), target);
  }

  // optional .tensorflow.serving.ModelVersionStatus.State state = 2;
  if (this->state() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      2, this->state(), target);
  }

  // optional .tensorflow.serving.StatusProto status = 3;
  if (this->has_status()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        3, *this->status_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ModelVersionStatus)
  return target;
}

int ModelVersionStatus::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ModelVersionStatus)
  int total_size = 0;

  // optional int64 version = 1;
  if (this->version() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->version());
  }

  // optional .tensorflow.serving.ModelVersionStatus.State state = 2;
  if (this->state() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->state());
  }

  // optional .tensorflow.serving.StatusProto status = 3;
  if (this->has_status()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->status_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ModelVersionStatus::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ModelVersionStatus)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const ModelVersionStatus* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ModelVersionStatus>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ModelVersionStatus)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ModelVersionStatus)
    MergeFrom(*source);
  }
}

void ModelVersionStatus::MergeFrom(const ModelVersionStatus& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ModelVersionStatus)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  if (from.version() != 0) {
    set_version(from.version());
  }
  if (from.state() != 0) {
    set_state(from.state());
  }
  if (from.has_status()) {
    mutable_status()->::tensorflow::serving::StatusProto::MergeFrom(from.status());
  }
}

void ModelVersionStatus::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ModelVersionStatus)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ModelVersionStatus::CopyFrom(const ModelVersionStatus& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ModelVersionStatus)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelVersionStatus::IsInitialized() const {

  return true;
}

void ModelVersionStatus::Swap(ModelVersionStatus* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ModelVersionStatus temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void ModelVersionStatus::UnsafeArenaSwap(ModelVersionStatus* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ModelVersionStatus::InternalSwap(ModelVersionStatus* other) {
  std::swap(version_, other->version_);
  std::swap(state_, other->state_);
  std::swap(status_, other->status_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ModelVersionStatus::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ModelVersionStatus_descriptor_;
  metadata.reflection = ModelVersionStatus_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ModelVersionStatus

// optional int64 version = 1;
void ModelVersionStatus::clear_version() {
  version_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 ModelVersionStatus::version() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelVersionStatus.version)
  return version_;
}
 void ModelVersionStatus::set_version(::google::protobuf::int64 value) {
  
  version_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.serving.ModelVersionStatus.version)
}

// optional .tensorflow.serving.ModelVersionStatus.State state = 2;
void ModelVersionStatus::clear_state() {
  state_ = 0;
}
 ::tensorflow::serving::ModelVersionStatus_State ModelVersionStatus::state() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelVersionStatus.state)
  return static_cast< ::tensorflow::serving::ModelVersionStatus_State >(state_);
}
 void ModelVersionStatus::set_state(::tensorflow::serving::ModelVersionStatus_State value) {
  
  state_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.serving.ModelVersionStatus.state)
}

// optional .tensorflow.serving.StatusProto status = 3;
bool ModelVersionStatus::has_status() const {
  return !_is_default_instance_ && status_ != NULL;
}
void ModelVersionStatus::clear_status() {
  if (GetArenaNoVirtual() == NULL && status_ != NULL) delete status_;
  status_ = NULL;
}
const ::tensorflow::serving::StatusProto& ModelVersionStatus::status() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelVersionStatus.status)
  return status_ != NULL ? *status_ : *default_instance_->status_;
}
::tensorflow::serving::StatusProto* ModelVersionStatus::mutable_status() {
  
  if (status_ == NULL) {
    _slow_mutable_status();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelVersionStatus.status)
  return status_;
}
::tensorflow::serving::StatusProto* ModelVersionStatus::release_status() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelVersionStatus.status)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_status();
  } else {
    ::tensorflow::serving::StatusProto* temp = status_;
    status_ = NULL;
    return temp;
  }
}
 void ModelVersionStatus::set_allocated_status(::tensorflow::serving::StatusProto* status) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete status_;
  }
  if (status != NULL) {
    _slow_set_allocated_status(message_arena, &status);
  }
  status_ = status;
  if (status) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelVersionStatus.status)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int GetModelStatusResponse::kModelVersionStatusFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

GetModelStatusResponse::GetModelStatusResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.GetModelStatusResponse)
}

GetModelStatusResponse::GetModelStatusResponse(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  model_version_status_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.GetModelStatusResponse)
}

void GetModelStatusResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

GetModelStatusResponse::GetModelStatusResponse(const GetModelStatusResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.GetModelStatusResponse)
}

void GetModelStatusResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

GetModelStatusResponse::~GetModelStatusResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.GetModelStatusResponse)
  SharedDtor();
}

void GetModelStatusResponse::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
  }
}

void GetModelStatusResponse::ArenaDtor(void* object) {
  GetModelStatusResponse* _this = reinterpret_cast< GetModelStatusResponse* >(object);
  (void)_this;
}
void GetModelStatusResponse::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void GetModelStatusResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* GetModelStatusResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return GetModelStatusResponse_descriptor_;
}

const GetModelStatusResponse& GetModelStatusResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto();
  return *default_instance_;
}

GetModelStatusResponse* GetModelStatusResponse::default_instance_ = NULL;

GetModelStatusResponse* GetModelStatusResponse::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<GetModelStatusResponse>(arena);
}

void GetModelStatusResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.GetModelStatusResponse)
  model_version_status_.Clear();
}

bool GetModelStatusResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.GetModelStatusResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.serving.ModelVersionStatus model_version_status = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_model_version_status:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_model_version_status()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_model_version_status;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.GetModelStatusResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.GetModelStatusResponse)
  return false;
#undef DO_
}

void GetModelStatusResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.GetModelStatusResponse)
  // repeated .tensorflow.serving.ModelVersionStatus model_version_status = 1;
  for (unsigned int i = 0, n = this->model_version_status_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->model_version_status(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.GetModelStatusResponse)
}

::google::protobuf::uint8* GetModelStatusResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.GetModelStatusResponse)
  // repeated .tensorflow.serving.ModelVersionStatus model_version_status = 1;
  for (unsigned int i = 0, n = this->model_version_status_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, this->model_version_status(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.GetModelStatusResponse)
  return target;
}

int GetModelStatusResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.GetModelStatusResponse)
  int total_size = 0;

  // repeated .tensorflow.serving.ModelVersionStatus model_version_status = 1;
  total_size += 1 * this->model_version_status_size();
  for (int i = 0; i < this->model_version_status_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->model_version_status(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void GetModelStatusResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.GetModelStatusResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const GetModelStatusResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const GetModelStatusResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.GetModelStatusResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.GetModelStatusResponse)
    MergeFrom(*source);
  }
}

void GetModelStatusResponse::MergeFrom(const GetModelStatusResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.GetModelStatusResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  model_version_status_.MergeFrom(from.model_version_status_);
}

void GetModelStatusResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.GetModelStatusResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void GetModelStatusResponse::CopyFrom(const GetModelStatusResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.GetModelStatusResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool GetModelStatusResponse::IsInitialized() const {

  return true;
}

void GetModelStatusResponse::Swap(GetModelStatusResponse* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    GetModelStatusResponse temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void GetModelStatusResponse::UnsafeArenaSwap(GetModelStatusResponse* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void GetModelStatusResponse::InternalSwap(GetModelStatusResponse* other) {
  model_version_status_.UnsafeArenaSwap(&other->model_version_status_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata GetModelStatusResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = GetModelStatusResponse_descriptor_;
  metadata.reflection = GetModelStatusResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// GetModelStatusResponse

// repeated .tensorflow.serving.ModelVersionStatus model_version_status = 1;
int GetModelStatusResponse::model_version_status_size() const {
  return model_version_status_.size();
}
void GetModelStatusResponse::clear_model_version_status() {
  model_version_status_.Clear();
}
const ::tensorflow::serving::ModelVersionStatus& GetModelStatusResponse::model_version_status(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.GetModelStatusResponse.model_version_status)
  return model_version_status_.Get(index);
}
::tensorflow::serving::ModelVersionStatus* GetModelStatusResponse::mutable_model_version_status(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.GetModelStatusResponse.model_version_status)
  return model_version_status_.Mutable(index);
}
::tensorflow::serving::ModelVersionStatus* GetModelStatusResponse::add_model_version_status() {
  // @@protoc_insertion_point(field_add:tensorflow.serving.GetModelStatusResponse.model_version_status)
  return model_version_status_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::serving::ModelVersionStatus >*
GetModelStatusResponse::mutable_model_version_status() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.GetModelStatusResponse.model_version_status)
  return &model_version_status_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::serving::ModelVersionStatus >&
GetModelStatusResponse::model_version_status() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.GetModelStatusResponse.model_version_status)
  return model_version_status_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace serving
}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
