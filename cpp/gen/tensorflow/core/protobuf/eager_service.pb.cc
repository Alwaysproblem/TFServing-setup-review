// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/eager_service.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow/core/protobuf/eager_service.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {
namespace eager {

namespace {

const ::google::protobuf::Descriptor* Operation_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  Operation_reflection_ = NULL;
const ::google::protobuf::Descriptor* Operation_Input_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  Operation_Input_reflection_ = NULL;
struct Operation_InputOneofInstance {
  const ::tensorflow::eager::RemoteTensorHandle* remote_handle_;
  const ::tensorflow::TensorProto* tensor_;
}* Operation_Input_default_oneof_instance_ = NULL;
const ::google::protobuf::Descriptor* Operation_AttrsEntry_descriptor_ = NULL;
const ::google::protobuf::Descriptor* QueueItem_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  QueueItem_reflection_ = NULL;
struct QueueItemOneofInstance {
  const ::tensorflow::eager::RemoteTensorHandle* handle_to_decref_;
  const ::tensorflow::eager::Operation* operation_;
  const ::tensorflow::eager::SendTensorOp* send_tensor_;
  const ::tensorflow::eager::RegisterFunctionOp* register_function_;
  const ::tensorflow::eager::CleanupFunctionOp* cleanup_function_;
  const ::tensorflow::eager::SyncRemoteExecutorForStream* sync_remote_executor_for_stream_;
  const ::tensorflow::eager::SendPackedHandleOp* send_packed_handle_;
}* QueueItem_default_oneof_instance_ = NULL;
const ::google::protobuf::Descriptor* QueueResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  QueueResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* CreateContextRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CreateContextRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* CreateContextResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CreateContextResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* UpdateContextRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  UpdateContextRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* UpdateContextResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  UpdateContextResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* EnqueueRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  EnqueueRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* EnqueueResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  EnqueueResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* WaitQueueDoneRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  WaitQueueDoneRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* WaitQueueDoneResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  WaitQueueDoneResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* RunComponentFunctionRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RunComponentFunctionRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* RunComponentFunctionResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RunComponentFunctionResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* KeepAliveRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  KeepAliveRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* KeepAliveResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  KeepAliveResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* CloseContextRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CloseContextRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* CloseContextResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CloseContextResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* RegisterFunctionOp_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RegisterFunctionOp_reflection_ = NULL;
const ::google::protobuf::Descriptor* CleanupFunctionOp_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CleanupFunctionOp_reflection_ = NULL;
const ::google::protobuf::Descriptor* SyncRemoteExecutorForStream_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  SyncRemoteExecutorForStream_reflection_ = NULL;
const ::google::protobuf::Descriptor* SendTensorOp_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  SendTensorOp_reflection_ = NULL;
const ::google::protobuf::Descriptor* SendPackedHandleOp_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  SendPackedHandleOp_reflection_ = NULL;
const ::google::protobuf::Descriptor* SendPackedHandleOp_LocalTensorHandle_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  SendPackedHandleOp_LocalTensorHandle_reflection_ = NULL;
const ::google::protobuf::Descriptor* SendPackedHandleOp_Handle_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  SendPackedHandleOp_Handle_reflection_ = NULL;
struct SendPackedHandleOp_HandleOneofInstance {
  const ::tensorflow::eager::SendPackedHandleOp_LocalTensorHandle* local_handle_;
  const ::tensorflow::eager::RemoteTensorHandle* remote_handle_;
}* SendPackedHandleOp_Handle_default_oneof_instance_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto() {
  protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow/core/protobuf/eager_service.proto");
  GOOGLE_CHECK(file != NULL);
  Operation_descriptor_ = file->message_type(0);
  static const int Operation_offsets_[9] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation, id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation, name_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation, op_inputs_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation, control_op_ids_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation, attrs_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation, device_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation, is_component_function_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation, func_step_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation, is_function_),
  };
  Operation_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      Operation_descriptor_,
      Operation::default_instance_,
      Operation_offsets_,
      -1,
      -1,
      -1,
      sizeof(Operation),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation, _is_default_instance_));
  Operation_Input_descriptor_ = Operation_descriptor_->nested_type(0);
  static const int Operation_Input_offsets_[3] = {
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(Operation_Input_default_oneof_instance_, remote_handle_),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(Operation_Input_default_oneof_instance_, tensor_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation_Input, item_),
  };
  Operation_Input_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      Operation_Input_descriptor_,
      Operation_Input::default_instance_,
      Operation_Input_offsets_,
      -1,
      -1,
      -1,
      Operation_Input_default_oneof_instance_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation_Input, _oneof_case_[0]),
      sizeof(Operation_Input),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation_Input, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Operation_Input, _is_default_instance_));
  Operation_AttrsEntry_descriptor_ = Operation_descriptor_->nested_type(1);
  QueueItem_descriptor_ = file->message_type(1);
  static const int QueueItem_offsets_[8] = {
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(QueueItem_default_oneof_instance_, handle_to_decref_),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(QueueItem_default_oneof_instance_, operation_),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(QueueItem_default_oneof_instance_, send_tensor_),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(QueueItem_default_oneof_instance_, register_function_),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(QueueItem_default_oneof_instance_, cleanup_function_),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(QueueItem_default_oneof_instance_, sync_remote_executor_for_stream_),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(QueueItem_default_oneof_instance_, send_packed_handle_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(QueueItem, item_),
  };
  QueueItem_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      QueueItem_descriptor_,
      QueueItem::default_instance_,
      QueueItem_offsets_,
      -1,
      -1,
      -1,
      QueueItem_default_oneof_instance_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(QueueItem, _oneof_case_[0]),
      sizeof(QueueItem),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(QueueItem, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(QueueItem, _is_default_instance_));
  QueueResponse_descriptor_ = file->message_type(2);
  static const int QueueResponse_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(QueueResponse, shape_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(QueueResponse, tensor_),
  };
  QueueResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      QueueResponse_descriptor_,
      QueueResponse::default_instance_,
      QueueResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(QueueResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(QueueResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(QueueResponse, _is_default_instance_));
  CreateContextRequest_descriptor_ = file->message_type(3);
  static const int CreateContextRequest_offsets_[8] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextRequest, server_def_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextRequest, async_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextRequest, keep_alive_secs_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextRequest, version_def_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextRequest, cluster_device_attributes_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextRequest, context_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextRequest, context_view_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextRequest, lazy_copy_remote_function_inputs_),
  };
  CreateContextRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CreateContextRequest_descriptor_,
      CreateContextRequest::default_instance_,
      CreateContextRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(CreateContextRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextRequest, _is_default_instance_));
  CreateContextResponse_descriptor_ = file->message_type(4);
  static const int CreateContextResponse_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextResponse, device_attributes_),
  };
  CreateContextResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CreateContextResponse_descriptor_,
      CreateContextResponse::default_instance_,
      CreateContextResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(CreateContextResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateContextResponse, _is_default_instance_));
  UpdateContextRequest_descriptor_ = file->message_type(5);
  static const int UpdateContextRequest_offsets_[4] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(UpdateContextRequest, server_def_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(UpdateContextRequest, cluster_device_attributes_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(UpdateContextRequest, context_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(UpdateContextRequest, context_view_id_),
  };
  UpdateContextRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      UpdateContextRequest_descriptor_,
      UpdateContextRequest::default_instance_,
      UpdateContextRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(UpdateContextRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(UpdateContextRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(UpdateContextRequest, _is_default_instance_));
  UpdateContextResponse_descriptor_ = file->message_type(6);
  static const int UpdateContextResponse_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(UpdateContextResponse, device_attributes_),
  };
  UpdateContextResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      UpdateContextResponse_descriptor_,
      UpdateContextResponse::default_instance_,
      UpdateContextResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(UpdateContextResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(UpdateContextResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(UpdateContextResponse, _is_default_instance_));
  EnqueueRequest_descriptor_ = file->message_type(7);
  static const int EnqueueRequest_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(EnqueueRequest, context_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(EnqueueRequest, queue_),
  };
  EnqueueRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      EnqueueRequest_descriptor_,
      EnqueueRequest::default_instance_,
      EnqueueRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(EnqueueRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(EnqueueRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(EnqueueRequest, _is_default_instance_));
  EnqueueResponse_descriptor_ = file->message_type(8);
  static const int EnqueueResponse_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(EnqueueResponse, queue_response_),
  };
  EnqueueResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      EnqueueResponse_descriptor_,
      EnqueueResponse::default_instance_,
      EnqueueResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(EnqueueResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(EnqueueResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(EnqueueResponse, _is_default_instance_));
  WaitQueueDoneRequest_descriptor_ = file->message_type(9);
  static const int WaitQueueDoneRequest_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(WaitQueueDoneRequest, context_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(WaitQueueDoneRequest, op_id_),
  };
  WaitQueueDoneRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      WaitQueueDoneRequest_descriptor_,
      WaitQueueDoneRequest::default_instance_,
      WaitQueueDoneRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(WaitQueueDoneRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(WaitQueueDoneRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(WaitQueueDoneRequest, _is_default_instance_));
  WaitQueueDoneResponse_descriptor_ = file->message_type(10);
  static const int WaitQueueDoneResponse_offsets_[1] = {
  };
  WaitQueueDoneResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      WaitQueueDoneResponse_descriptor_,
      WaitQueueDoneResponse::default_instance_,
      WaitQueueDoneResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(WaitQueueDoneResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(WaitQueueDoneResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(WaitQueueDoneResponse, _is_default_instance_));
  RunComponentFunctionRequest_descriptor_ = file->message_type(11);
  static const int RunComponentFunctionRequest_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunComponentFunctionRequest, context_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunComponentFunctionRequest, operation_),
  };
  RunComponentFunctionRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RunComponentFunctionRequest_descriptor_,
      RunComponentFunctionRequest::default_instance_,
      RunComponentFunctionRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(RunComponentFunctionRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunComponentFunctionRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunComponentFunctionRequest, _is_default_instance_));
  RunComponentFunctionResponse_descriptor_ = file->message_type(12);
  static const int RunComponentFunctionResponse_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunComponentFunctionResponse, shape_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunComponentFunctionResponse, tensor_),
  };
  RunComponentFunctionResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RunComponentFunctionResponse_descriptor_,
      RunComponentFunctionResponse::default_instance_,
      RunComponentFunctionResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(RunComponentFunctionResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunComponentFunctionResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunComponentFunctionResponse, _is_default_instance_));
  KeepAliveRequest_descriptor_ = file->message_type(13);
  static const int KeepAliveRequest_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(KeepAliveRequest, context_id_),
  };
  KeepAliveRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      KeepAliveRequest_descriptor_,
      KeepAliveRequest::default_instance_,
      KeepAliveRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(KeepAliveRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(KeepAliveRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(KeepAliveRequest, _is_default_instance_));
  KeepAliveResponse_descriptor_ = file->message_type(14);
  static const int KeepAliveResponse_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(KeepAliveResponse, context_view_id_),
  };
  KeepAliveResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      KeepAliveResponse_descriptor_,
      KeepAliveResponse::default_instance_,
      KeepAliveResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(KeepAliveResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(KeepAliveResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(KeepAliveResponse, _is_default_instance_));
  CloseContextRequest_descriptor_ = file->message_type(15);
  static const int CloseContextRequest_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CloseContextRequest, context_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CloseContextRequest, context_view_id_),
  };
  CloseContextRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CloseContextRequest_descriptor_,
      CloseContextRequest::default_instance_,
      CloseContextRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(CloseContextRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CloseContextRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CloseContextRequest, _is_default_instance_));
  CloseContextResponse_descriptor_ = file->message_type(16);
  static const int CloseContextResponse_offsets_[1] = {
  };
  CloseContextResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CloseContextResponse_descriptor_,
      CloseContextResponse::default_instance_,
      CloseContextResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(CloseContextResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CloseContextResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CloseContextResponse, _is_default_instance_));
  RegisterFunctionOp_descriptor_ = file->message_type(17);
  static const int RegisterFunctionOp_offsets_[3] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterFunctionOp, function_def_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterFunctionOp, is_component_function_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterFunctionOp, library_),
  };
  RegisterFunctionOp_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RegisterFunctionOp_descriptor_,
      RegisterFunctionOp::default_instance_,
      RegisterFunctionOp_offsets_,
      -1,
      -1,
      -1,
      sizeof(RegisterFunctionOp),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterFunctionOp, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterFunctionOp, _is_default_instance_));
  CleanupFunctionOp_descriptor_ = file->message_type(18);
  static const int CleanupFunctionOp_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupFunctionOp, step_id_),
  };
  CleanupFunctionOp_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CleanupFunctionOp_descriptor_,
      CleanupFunctionOp::default_instance_,
      CleanupFunctionOp_offsets_,
      -1,
      -1,
      -1,
      sizeof(CleanupFunctionOp),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupFunctionOp, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupFunctionOp, _is_default_instance_));
  SyncRemoteExecutorForStream_descriptor_ = file->message_type(19);
  static const int SyncRemoteExecutorForStream_offsets_[1] = {
  };
  SyncRemoteExecutorForStream_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      SyncRemoteExecutorForStream_descriptor_,
      SyncRemoteExecutorForStream::default_instance_,
      SyncRemoteExecutorForStream_offsets_,
      -1,
      -1,
      -1,
      sizeof(SyncRemoteExecutorForStream),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SyncRemoteExecutorForStream, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SyncRemoteExecutorForStream, _is_default_instance_));
  SendTensorOp_descriptor_ = file->message_type(20);
  static const int SendTensorOp_offsets_[3] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendTensorOp, op_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendTensorOp, tensors_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendTensorOp, device_name_),
  };
  SendTensorOp_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      SendTensorOp_descriptor_,
      SendTensorOp::default_instance_,
      SendTensorOp_offsets_,
      -1,
      -1,
      -1,
      sizeof(SendTensorOp),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendTensorOp, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendTensorOp, _is_default_instance_));
  SendPackedHandleOp_descriptor_ = file->message_type(21);
  static const int SendPackedHandleOp_offsets_[3] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp, op_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp, handles_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp, device_name_),
  };
  SendPackedHandleOp_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      SendPackedHandleOp_descriptor_,
      SendPackedHandleOp::default_instance_,
      SendPackedHandleOp_offsets_,
      -1,
      -1,
      -1,
      sizeof(SendPackedHandleOp),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp, _is_default_instance_));
  SendPackedHandleOp_LocalTensorHandle_descriptor_ = SendPackedHandleOp_descriptor_->nested_type(0);
  static const int SendPackedHandleOp_LocalTensorHandle_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp_LocalTensorHandle, tensor_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp_LocalTensorHandle, device_),
  };
  SendPackedHandleOp_LocalTensorHandle_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      SendPackedHandleOp_LocalTensorHandle_descriptor_,
      SendPackedHandleOp_LocalTensorHandle::default_instance_,
      SendPackedHandleOp_LocalTensorHandle_offsets_,
      -1,
      -1,
      -1,
      sizeof(SendPackedHandleOp_LocalTensorHandle),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp_LocalTensorHandle, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp_LocalTensorHandle, _is_default_instance_));
  SendPackedHandleOp_Handle_descriptor_ = SendPackedHandleOp_descriptor_->nested_type(1);
  static const int SendPackedHandleOp_Handle_offsets_[3] = {
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(SendPackedHandleOp_Handle_default_oneof_instance_, local_handle_),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET(SendPackedHandleOp_Handle_default_oneof_instance_, remote_handle_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp_Handle, item_),
  };
  SendPackedHandleOp_Handle_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      SendPackedHandleOp_Handle_descriptor_,
      SendPackedHandleOp_Handle::default_instance_,
      SendPackedHandleOp_Handle_offsets_,
      -1,
      -1,
      -1,
      SendPackedHandleOp_Handle_default_oneof_instance_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp_Handle, _oneof_case_[0]),
      sizeof(SendPackedHandleOp_Handle),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp_Handle, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SendPackedHandleOp_Handle, _is_default_instance_));
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      Operation_descriptor_, &Operation::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      Operation_Input_descriptor_, &Operation_Input::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
        Operation_AttrsEntry_descriptor_,
        ::google::protobuf::internal::MapEntry<
            ::std::string,
            ::tensorflow::AttrValue,
            ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
            ::google::protobuf::internal::WireFormatLite::TYPE_MESSAGE,
            0>::CreateDefaultInstance(
                Operation_AttrsEntry_descriptor_));
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      QueueItem_descriptor_, &QueueItem::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      QueueResponse_descriptor_, &QueueResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CreateContextRequest_descriptor_, &CreateContextRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CreateContextResponse_descriptor_, &CreateContextResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      UpdateContextRequest_descriptor_, &UpdateContextRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      UpdateContextResponse_descriptor_, &UpdateContextResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      EnqueueRequest_descriptor_, &EnqueueRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      EnqueueResponse_descriptor_, &EnqueueResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      WaitQueueDoneRequest_descriptor_, &WaitQueueDoneRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      WaitQueueDoneResponse_descriptor_, &WaitQueueDoneResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RunComponentFunctionRequest_descriptor_, &RunComponentFunctionRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RunComponentFunctionResponse_descriptor_, &RunComponentFunctionResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      KeepAliveRequest_descriptor_, &KeepAliveRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      KeepAliveResponse_descriptor_, &KeepAliveResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CloseContextRequest_descriptor_, &CloseContextRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CloseContextResponse_descriptor_, &CloseContextResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RegisterFunctionOp_descriptor_, &RegisterFunctionOp::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CleanupFunctionOp_descriptor_, &CleanupFunctionOp::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      SyncRemoteExecutorForStream_descriptor_, &SyncRemoteExecutorForStream::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      SendTensorOp_descriptor_, &SendTensorOp::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      SendPackedHandleOp_descriptor_, &SendPackedHandleOp::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      SendPackedHandleOp_LocalTensorHandle_descriptor_, &SendPackedHandleOp_LocalTensorHandle::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      SendPackedHandleOp_Handle_descriptor_, &SendPackedHandleOp_Handle::default_instance());
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto() {
  delete Operation::default_instance_;
  delete Operation_reflection_;
  delete Operation_Input::default_instance_;
  delete Operation_Input_default_oneof_instance_;
  delete Operation_Input_reflection_;
  delete QueueItem::default_instance_;
  delete QueueItem_default_oneof_instance_;
  delete QueueItem_reflection_;
  delete QueueResponse::default_instance_;
  delete QueueResponse_reflection_;
  delete CreateContextRequest::default_instance_;
  delete CreateContextRequest_reflection_;
  delete CreateContextResponse::default_instance_;
  delete CreateContextResponse_reflection_;
  delete UpdateContextRequest::default_instance_;
  delete UpdateContextRequest_reflection_;
  delete UpdateContextResponse::default_instance_;
  delete UpdateContextResponse_reflection_;
  delete EnqueueRequest::default_instance_;
  delete EnqueueRequest_reflection_;
  delete EnqueueResponse::default_instance_;
  delete EnqueueResponse_reflection_;
  delete WaitQueueDoneRequest::default_instance_;
  delete WaitQueueDoneRequest_reflection_;
  delete WaitQueueDoneResponse::default_instance_;
  delete WaitQueueDoneResponse_reflection_;
  delete RunComponentFunctionRequest::default_instance_;
  delete RunComponentFunctionRequest_reflection_;
  delete RunComponentFunctionResponse::default_instance_;
  delete RunComponentFunctionResponse_reflection_;
  delete KeepAliveRequest::default_instance_;
  delete KeepAliveRequest_reflection_;
  delete KeepAliveResponse::default_instance_;
  delete KeepAliveResponse_reflection_;
  delete CloseContextRequest::default_instance_;
  delete CloseContextRequest_reflection_;
  delete CloseContextResponse::default_instance_;
  delete CloseContextResponse_reflection_;
  delete RegisterFunctionOp::default_instance_;
  delete RegisterFunctionOp_reflection_;
  delete CleanupFunctionOp::default_instance_;
  delete CleanupFunctionOp_reflection_;
  delete SyncRemoteExecutorForStream::default_instance_;
  delete SyncRemoteExecutorForStream_reflection_;
  delete SendTensorOp::default_instance_;
  delete SendTensorOp_reflection_;
  delete SendPackedHandleOp::default_instance_;
  delete SendPackedHandleOp_reflection_;
  delete SendPackedHandleOp_LocalTensorHandle::default_instance_;
  delete SendPackedHandleOp_LocalTensorHandle_reflection_;
  delete SendPackedHandleOp_Handle::default_instance_;
  delete SendPackedHandleOp_Handle_default_oneof_instance_;
  delete SendPackedHandleOp_Handle_reflection_;
}

void protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2ffunction_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2ftensor_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2fversions_2eproto();
  ::tensorflow::eager::protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fremote_5ftensor_5fhandle_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto();
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n,tensorflow/core/protobuf/eager_service"
    ".proto\022\020tensorflow.eager\032*tensorflow/cor"
    "e/framework/attr_value.proto\0321tensorflow"
    "/core/framework/device_attributes.proto\032"
    "(tensorflow/core/framework/function.prot"
    "o\032&tensorflow/core/framework/tensor.prot"
    "o\032,tensorflow/core/framework/tensor_shap"
    "e.proto\032(tensorflow/core/framework/versi"
    "ons.proto\0323tensorflow/core/protobuf/remo"
    "te_tensor_handle.proto\0320tensorflow/core/"
    "protobuf/tensorflow_server.proto\"\312\003\n\tOpe"
    "ration\022\n\n\002id\030\001 \001(\003\022\014\n\004name\030\002 \001(\t\0224\n\top_i"
    "nputs\030\n \003(\0132!.tensorflow.eager.Operation"
    ".Input\022\026\n\016control_op_ids\030\004 \003(\003\0225\n\005attrs\030"
    "\005 \003(\0132&.tensorflow.eager.Operation.Attrs"
    "Entry\022\016\n\006device\030\006 \001(\t\022\035\n\025is_component_fu"
    "nction\030\007 \001(\010\022\024\n\014func_step_id\030\010 \001(\003\022\023\n\013is"
    "_function\030\t \001(\010\032y\n\005Input\022=\n\rremote_handl"
    "e\030\001 \001(\0132$.tensorflow.eager.RemoteTensorH"
    "andleH\000\022)\n\006tensor\030\002 \001(\0132\027.tensorflow.Ten"
    "sorProtoH\000B\006\n\004item\032C\n\nAttrsEntry\022\013\n\003key\030"
    "\001 \001(\t\022$\n\005value\030\002 \001(\0132\025.tensorflow.AttrVa"
    "lue:\0028\001J\004\010\003\020\004\"\340\003\n\tQueueItem\022@\n\020handle_to"
    "_decref\030\001 \001(\0132$.tensorflow.eager.RemoteT"
    "ensorHandleH\000\0220\n\toperation\030\002 \001(\0132\033.tenso"
    "rflow.eager.OperationH\000\0225\n\013send_tensor\030\003"
    " \001(\0132\036.tensorflow.eager.SendTensorOpH\000\022A"
    "\n\021register_function\030\004 \001(\0132$.tensorflow.e"
    "ager.RegisterFunctionOpH\000\022\?\n\020cleanup_fun"
    "ction\030\005 \001(\0132#.tensorflow.eager.CleanupFu"
    "nctionOpH\000\022X\n\037sync_remote_executor_for_s"
    "tream\030\006 \001(\0132-.tensorflow.eager.SyncRemot"
    "eExecutorForStreamH\000\022B\n\022send_packed_hand"
    "le\030\007 \001(\0132$.tensorflow.eager.SendPackedHa"
    "ndleOpH\000B\006\n\004item\"e\n\rQueueResponse\022+\n\005sha"
    "pe\030\001 \003(\0132\034.tensorflow.TensorShapeProto\022\'"
    "\n\006tensor\030\002 \003(\0132\027.tensorflow.TensorProto\""
    "\264\002\n\024CreateContextRequest\022)\n\nserver_def\030\001"
    " \001(\0132\025.tensorflow.ServerDef\022\r\n\005async\030\002 \001"
    "(\010\022\027\n\017keep_alive_secs\030\003 \001(\003\022+\n\013version_d"
    "ef\030\004 \001(\0132\026.tensorflow.VersionDef\022\?\n\031clus"
    "ter_device_attributes\030\006 \003(\0132\034.tensorflow"
    ".DeviceAttributes\022\022\n\ncontext_id\030\007 \001(\006\022\027\n"
    "\017context_view_id\030\010 \001(\006\022(\n lazy_copy_remo"
    "te_function_inputs\030\t \001(\010J\004\010\005\020\006\"V\n\025Create"
    "ContextResponse\0227\n\021device_attributes\030\002 \003"
    "(\0132\034.tensorflow.DeviceAttributesJ\004\010\001\020\002\"\257"
    "\001\n\024UpdateContextRequest\022)\n\nserver_def\030\001 "
    "\001(\0132\025.tensorflow.ServerDef\022\?\n\031cluster_de"
    "vice_attributes\030\002 \003(\0132\034.tensorflow.Devic"
    "eAttributes\022\022\n\ncontext_id\030\003 \001(\006\022\027\n\017conte"
    "xt_view_id\030\004 \001(\006\"P\n\025UpdateContextRespons"
    "e\0227\n\021device_attributes\030\001 \003(\0132\034.tensorflo"
    "w.DeviceAttributes\"P\n\016EnqueueRequest\022\022\n\n"
    "context_id\030\001 \001(\006\022*\n\005queue\030\003 \003(\0132\033.tensor"
    "flow.eager.QueueItem\"J\n\017EnqueueResponse\022"
    "7\n\016queue_response\030\001 \003(\0132\037.tensorflow.eag"
    "er.QueueResponse\"9\n\024WaitQueueDoneRequest"
    "\022\022\n\ncontext_id\030\001 \001(\006\022\r\n\005op_id\030\002 \003(\003\"\027\n\025W"
    "aitQueueDoneResponse\"a\n\033RunComponentFunc"
    "tionRequest\022\022\n\ncontext_id\030\001 \001(\006\022.\n\topera"
    "tion\030\002 \001(\0132\033.tensorflow.eager.Operation\""
    "t\n\034RunComponentFunctionResponse\022+\n\005shape"
    "\030\001 \003(\0132\034.tensorflow.TensorShapeProto\022\'\n\006"
    "tensor\030\002 \003(\0132\027.tensorflow.TensorProto\"&\n"
    "\020KeepAliveRequest\022\022\n\ncontext_id\030\001 \001(\006\",\n"
    "\021KeepAliveResponse\022\027\n\017context_view_id\030\001 "
    "\001(\006\"B\n\023CloseContextRequest\022\022\n\ncontext_id"
    "\030\001 \001(\006\022\027\n\017context_view_id\030\002 \001(\006\"\026\n\024Close"
    "ContextResponse\"\223\001\n\022RegisterFunctionOp\022-"
    "\n\014function_def\030\001 \001(\0132\027.tensorflow.Functi"
    "onDef\022\035\n\025is_component_function\030\002 \001(\010\022/\n\007"
    "library\030\003 \001(\0132\036.tensorflow.FunctionDefLi"
    "brary\"$\n\021CleanupFunctionOp\022\017\n\007step_id\030\001 "
    "\001(\003\"\035\n\033SyncRemoteExecutorForStream\"\\\n\014Se"
    "ndTensorOp\022\r\n\005op_id\030\001 \001(\003\022(\n\007tensors\030\002 \003"
    "(\0132\027.tensorflow.TensorProto\022\023\n\013device_na"
    "me\030\003 \001(\t\"\346\002\n\022SendPackedHandleOp\022\r\n\005op_id"
    "\030\001 \001(\003\022<\n\007handles\030\002 \003(\0132+.tensorflow.eag"
    "er.SendPackedHandleOp.Handle\022\023\n\013device_n"
    "ame\030\003 \001(\t\032L\n\021LocalTensorHandle\022\'\n\006tensor"
    "\030\001 \001(\0132\027.tensorflow.TensorProto\022\016\n\006devic"
    "e\030\002 \001(\t\032\237\001\n\006Handle\022N\n\014local_handle\030\001 \001(\013"
    "26.tensorflow.eager.SendPackedHandleOp.L"
    "ocalTensorHandleH\000\022=\n\rremote_handle\030\002 \001("
    "\0132$.tensorflow.eager.RemoteTensorHandleH"
    "\000B\006\n\004item2\215\006\n\014EagerService\022`\n\rCreateCont"
    "ext\022&.tensorflow.eager.CreateContextRequ"
    "est\032\'.tensorflow.eager.CreateContextResp"
    "onse\022`\n\rUpdateContext\022&.tensorflow.eager"
    ".UpdateContextRequest\032\'.tensorflow.eager"
    ".UpdateContextResponse\022N\n\007Enqueue\022 .tens"
    "orflow.eager.EnqueueRequest\032!.tensorflow"
    ".eager.EnqueueResponse\022[\n\020StreamingEnque"
    "ue\022 .tensorflow.eager.EnqueueRequest\032!.t"
    "ensorflow.eager.EnqueueResponse(\0010\001\022`\n\rW"
    "aitQueueDone\022&.tensorflow.eager.WaitQueu"
    "eDoneRequest\032\'.tensorflow.eager.WaitQueu"
    "eDoneResponse\022u\n\024RunComponentFunction\022-."
    "tensorflow.eager.RunComponentFunctionReq"
    "uest\032..tensorflow.eager.RunComponentFunc"
    "tionResponse\022T\n\tKeepAlive\022\".tensorflow.e"
    "ager.KeepAliveRequest\032#.tensorflow.eager"
    ".KeepAliveResponse\022]\n\014CloseContext\022%.ten"
    "sorflow.eager.CloseContextRequest\032&.tens"
    "orflow.eager.CloseContextResponseBJZHgit"
    "hub.com/tensorflow/tensorflow/tensorflow"
    "/go/core/core_protos_go_protob\006proto3", 4317);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow/core/protobuf/eager_service.proto", &protobuf_RegisterTypes);
  Operation::default_instance_ = new Operation();
  Operation_Input::default_instance_ = new Operation_Input();
  Operation_Input_default_oneof_instance_ = new Operation_InputOneofInstance();
  QueueItem::default_instance_ = new QueueItem();
  QueueItem_default_oneof_instance_ = new QueueItemOneofInstance();
  QueueResponse::default_instance_ = new QueueResponse();
  CreateContextRequest::default_instance_ = new CreateContextRequest();
  CreateContextResponse::default_instance_ = new CreateContextResponse();
  UpdateContextRequest::default_instance_ = new UpdateContextRequest();
  UpdateContextResponse::default_instance_ = new UpdateContextResponse();
  EnqueueRequest::default_instance_ = new EnqueueRequest();
  EnqueueResponse::default_instance_ = new EnqueueResponse();
  WaitQueueDoneRequest::default_instance_ = new WaitQueueDoneRequest();
  WaitQueueDoneResponse::default_instance_ = new WaitQueueDoneResponse();
  RunComponentFunctionRequest::default_instance_ = new RunComponentFunctionRequest();
  RunComponentFunctionResponse::default_instance_ = new RunComponentFunctionResponse();
  KeepAliveRequest::default_instance_ = new KeepAliveRequest();
  KeepAliveResponse::default_instance_ = new KeepAliveResponse();
  CloseContextRequest::default_instance_ = new CloseContextRequest();
  CloseContextResponse::default_instance_ = new CloseContextResponse();
  RegisterFunctionOp::default_instance_ = new RegisterFunctionOp();
  CleanupFunctionOp::default_instance_ = new CleanupFunctionOp();
  SyncRemoteExecutorForStream::default_instance_ = new SyncRemoteExecutorForStream();
  SendTensorOp::default_instance_ = new SendTensorOp();
  SendPackedHandleOp::default_instance_ = new SendPackedHandleOp();
  SendPackedHandleOp_LocalTensorHandle::default_instance_ = new SendPackedHandleOp_LocalTensorHandle();
  SendPackedHandleOp_Handle::default_instance_ = new SendPackedHandleOp_Handle();
  SendPackedHandleOp_Handle_default_oneof_instance_ = new SendPackedHandleOp_HandleOneofInstance();
  Operation::default_instance_->InitAsDefaultInstance();
  Operation_Input::default_instance_->InitAsDefaultInstance();
  QueueItem::default_instance_->InitAsDefaultInstance();
  QueueResponse::default_instance_->InitAsDefaultInstance();
  CreateContextRequest::default_instance_->InitAsDefaultInstance();
  CreateContextResponse::default_instance_->InitAsDefaultInstance();
  UpdateContextRequest::default_instance_->InitAsDefaultInstance();
  UpdateContextResponse::default_instance_->InitAsDefaultInstance();
  EnqueueRequest::default_instance_->InitAsDefaultInstance();
  EnqueueResponse::default_instance_->InitAsDefaultInstance();
  WaitQueueDoneRequest::default_instance_->InitAsDefaultInstance();
  WaitQueueDoneResponse::default_instance_->InitAsDefaultInstance();
  RunComponentFunctionRequest::default_instance_->InitAsDefaultInstance();
  RunComponentFunctionResponse::default_instance_->InitAsDefaultInstance();
  KeepAliveRequest::default_instance_->InitAsDefaultInstance();
  KeepAliveResponse::default_instance_->InitAsDefaultInstance();
  CloseContextRequest::default_instance_->InitAsDefaultInstance();
  CloseContextResponse::default_instance_->InitAsDefaultInstance();
  RegisterFunctionOp::default_instance_->InitAsDefaultInstance();
  CleanupFunctionOp::default_instance_->InitAsDefaultInstance();
  SyncRemoteExecutorForStream::default_instance_->InitAsDefaultInstance();
  SendTensorOp::default_instance_->InitAsDefaultInstance();
  SendPackedHandleOp::default_instance_->InitAsDefaultInstance();
  SendPackedHandleOp_LocalTensorHandle::default_instance_->InitAsDefaultInstance();
  SendPackedHandleOp_Handle::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto {
  StaticDescriptorInitializer_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto() {
    protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  }
} static_descriptor_initializer_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto_;

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int Operation_Input::kRemoteHandleFieldNumber;
const int Operation_Input::kTensorFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

Operation_Input::Operation_Input()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.Operation.Input)
}

void Operation_Input::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  Operation_Input_default_oneof_instance_->remote_handle_ = const_cast< ::tensorflow::eager::RemoteTensorHandle*>(&::tensorflow::eager::RemoteTensorHandle::default_instance());
  Operation_Input_default_oneof_instance_->tensor_ = const_cast< ::tensorflow::TensorProto*>(&::tensorflow::TensorProto::default_instance());
}

Operation_Input::Operation_Input(const Operation_Input& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.Operation.Input)
}

void Operation_Input::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  clear_has_item();
}

Operation_Input::~Operation_Input() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.Operation.Input)
  SharedDtor();
}

void Operation_Input::SharedDtor() {
  if (has_item()) {
    clear_item();
  }
  if (this != default_instance_) {
  }
}

void Operation_Input::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* Operation_Input::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return Operation_Input_descriptor_;
}

const Operation_Input& Operation_Input::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

Operation_Input* Operation_Input::default_instance_ = NULL;

Operation_Input* Operation_Input::New(::google::protobuf::Arena* arena) const {
  Operation_Input* n = new Operation_Input;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void Operation_Input::clear_item() {
// @@protoc_insertion_point(one_of_clear_start:tensorflow.eager.Operation.Input)
  switch(item_case()) {
    case kRemoteHandle: {
      delete item_.remote_handle_;
      break;
    }
    case kTensor: {
      delete item_.tensor_;
      break;
    }
    case ITEM_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = ITEM_NOT_SET;
}


void Operation_Input::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.Operation.Input)
  clear_item();
}

bool Operation_Input::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.Operation.Input)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.eager.RemoteTensorHandle remote_handle = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_remote_handle()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_tensor;
        break;
      }

      // optional .tensorflow.TensorProto tensor = 2;
      case 2: {
        if (tag == 18) {
         parse_tensor:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_tensor()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.Operation.Input)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.Operation.Input)
  return false;
#undef DO_
}

void Operation_Input::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.Operation.Input)
  // optional .tensorflow.eager.RemoteTensorHandle remote_handle = 1;
  if (has_remote_handle()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *item_.remote_handle_, output);
  }

  // optional .tensorflow.TensorProto tensor = 2;
  if (has_tensor()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *item_.tensor_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.Operation.Input)
}

::google::protobuf::uint8* Operation_Input::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.Operation.Input)
  // optional .tensorflow.eager.RemoteTensorHandle remote_handle = 1;
  if (has_remote_handle()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *item_.remote_handle_, false, target);
  }

  // optional .tensorflow.TensorProto tensor = 2;
  if (has_tensor()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *item_.tensor_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.Operation.Input)
  return target;
}

int Operation_Input::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.Operation.Input)
  int total_size = 0;

  switch (item_case()) {
    // optional .tensorflow.eager.RemoteTensorHandle remote_handle = 1;
    case kRemoteHandle: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *item_.remote_handle_);
      break;
    }
    // optional .tensorflow.TensorProto tensor = 2;
    case kTensor: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *item_.tensor_);
      break;
    }
    case ITEM_NOT_SET: {
      break;
    }
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void Operation_Input::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.Operation.Input)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const Operation_Input* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const Operation_Input>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.Operation.Input)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.Operation.Input)
    MergeFrom(*source);
  }
}

void Operation_Input::MergeFrom(const Operation_Input& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.Operation.Input)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  switch (from.item_case()) {
    case kRemoteHandle: {
      mutable_remote_handle()->::tensorflow::eager::RemoteTensorHandle::MergeFrom(from.remote_handle());
      break;
    }
    case kTensor: {
      mutable_tensor()->::tensorflow::TensorProto::MergeFrom(from.tensor());
      break;
    }
    case ITEM_NOT_SET: {
      break;
    }
  }
}

void Operation_Input::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.Operation.Input)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void Operation_Input::CopyFrom(const Operation_Input& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.Operation.Input)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool Operation_Input::IsInitialized() const {

  return true;
}

void Operation_Input::Swap(Operation_Input* other) {
  if (other == this) return;
  InternalSwap(other);
}
void Operation_Input::InternalSwap(Operation_Input* other) {
  std::swap(item_, other->item_);
  std::swap(_oneof_case_[0], other->_oneof_case_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata Operation_Input::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = Operation_Input_descriptor_;
  metadata.reflection = Operation_Input_reflection_;
  return metadata;
}


// -------------------------------------------------------------------

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int Operation::kIdFieldNumber;
const int Operation::kNameFieldNumber;
const int Operation::kOpInputsFieldNumber;
const int Operation::kControlOpIdsFieldNumber;
const int Operation::kAttrsFieldNumber;
const int Operation::kDeviceFieldNumber;
const int Operation::kIsComponentFunctionFieldNumber;
const int Operation::kFuncStepIdFieldNumber;
const int Operation::kIsFunctionFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

Operation::Operation()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.Operation)
}

void Operation::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

Operation::Operation(const Operation& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.Operation)
}

void Operation::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  id_ = GOOGLE_LONGLONG(0);
  name_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  attrs_.SetAssignDescriptorCallback(
      protobuf_AssignDescriptorsOnce);
  attrs_.SetEntryDescriptor(
      &::tensorflow::eager::Operation_AttrsEntry_descriptor_);
  device_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  is_component_function_ = false;
  func_step_id_ = GOOGLE_LONGLONG(0);
  is_function_ = false;
}

Operation::~Operation() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.Operation)
  SharedDtor();
}

void Operation::SharedDtor() {
  name_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  device_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
  }
}

void Operation::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* Operation::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return Operation_descriptor_;
}

const Operation& Operation::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

Operation* Operation::default_instance_ = NULL;

Operation* Operation::New(::google::protobuf::Arena* arena) const {
  Operation* n = new Operation;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void Operation::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.Operation)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(Operation, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<Operation*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(func_step_id_, is_component_function_);
  id_ = GOOGLE_LONGLONG(0);
  name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  device_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  is_function_ = false;

#undef ZR_HELPER_
#undef ZR_

  op_inputs_.Clear();
  control_op_ids_.Clear();
  attrs_.Clear();
}

bool Operation::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.Operation)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int64 id = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_name;
        break;
      }

      // optional string name = 2;
      case 2: {
        if (tag == 18) {
         parse_name:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_name()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->name().data(), this->name().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.eager.Operation.name"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_control_op_ids;
        break;
      }

      // repeated int64 control_op_ids = 4;
      case 4: {
        if (tag == 34) {
         parse_control_op_ids:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPackedPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, this->mutable_control_op_ids())));
        } else if (tag == 32) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadRepeatedPrimitiveNoInline<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 1, 34, input, this->mutable_control_op_ids())));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(42)) goto parse_attrs;
        break;
      }

      // map<string, .tensorflow.AttrValue> attrs = 5;
      case 5: {
        if (tag == 42) {
         parse_attrs:
          DO_(input->IncrementRecursionDepth());
         parse_loop_attrs:
          Operation_AttrsEntry::Parser< ::google::protobuf::internal::MapField<
              ::std::string, ::tensorflow::AttrValue,
              ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
              ::google::protobuf::internal::WireFormatLite::TYPE_MESSAGE,
              0 >,
            ::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue > > parser(&attrs_);
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
              input, &parser));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            parser.key().data(), parser.key().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.eager.Operation.AttrsEntry.key"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(42)) goto parse_loop_attrs;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(50)) goto parse_device;
        break;
      }

      // optional string device = 6;
      case 6: {
        if (tag == 50) {
         parse_device:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_device()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->device().data(), this->device().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.eager.Operation.device"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(56)) goto parse_is_component_function;
        break;
      }

      // optional bool is_component_function = 7;
      case 7: {
        if (tag == 56) {
         parse_is_component_function:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &is_component_function_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(64)) goto parse_func_step_id;
        break;
      }

      // optional int64 func_step_id = 8;
      case 8: {
        if (tag == 64) {
         parse_func_step_id:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &func_step_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(72)) goto parse_is_function;
        break;
      }

      // optional bool is_function = 9;
      case 9: {
        if (tag == 72) {
         parse_is_function:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &is_function_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(82)) goto parse_op_inputs;
        break;
      }

      // repeated .tensorflow.eager.Operation.Input op_inputs = 10;
      case 10: {
        if (tag == 82) {
         parse_op_inputs:
          DO_(input->IncrementRecursionDepth());
         parse_loop_op_inputs:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_op_inputs()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(82)) goto parse_loop_op_inputs;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.Operation)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.Operation)
  return false;
#undef DO_
}

void Operation::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.Operation)
  // optional int64 id = 1;
  if (this->id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(1, this->id(), output);
  }

  // optional string name = 2;
  if (this->name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.eager.Operation.name");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      2, this->name(), output);
  }

  // repeated int64 control_op_ids = 4;
  if (this->control_op_ids_size() > 0) {
    ::google::protobuf::internal::WireFormatLite::WriteTag(4, ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED, output);
    output->WriteVarint32(_control_op_ids_cached_byte_size_);
  }
  for (int i = 0; i < this->control_op_ids_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64NoTag(
      this->control_op_ids(i), output);
  }

  // map<string, .tensorflow.AttrValue> attrs = 5;
  if (!this->attrs().empty()) {
    typedef ::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue >::const_pointer
        ConstPtr;
    typedef ConstPtr SortItem;
    typedef ::google::protobuf::internal::CompareByDerefFirst<SortItem> Less;
    struct Utf8Check {
      static void Check(ConstPtr p) {
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          p->first.data(), p->first.length(),
          ::google::protobuf::internal::WireFormatLite::SERIALIZE,
          "tensorflow.eager.Operation.AttrsEntry.key");
      }
    };

    if (output->IsSerializationDeterminstic() &&
        this->attrs().size() > 1) {
      ::google::protobuf::scoped_array<SortItem> items(
          new SortItem[this->attrs().size()]);
      typedef ::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue >::size_type size_type;
      size_type n = 0;
      for (::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue >::const_iterator
          it = this->attrs().begin();
          it != this->attrs().end(); ++it, ++n) {
        items[n] = SortItem(&*it);
      }
      ::std::sort(&items[0], &items[n], Less());
      ::google::protobuf::scoped_ptr<Operation_AttrsEntry> entry;
      for (size_type i = 0; i < n; i++) {
        entry.reset(attrs_.NewEntryWrapper(
            items[i]->first, items[i]->second));
        ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
            5, *entry, output);
        Utf8Check::Check(items[i]);
      }
    } else {
      ::google::protobuf::scoped_ptr<Operation_AttrsEntry> entry;
      for (::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue >::const_iterator
          it = this->attrs().begin();
          it != this->attrs().end(); ++it) {
        entry.reset(attrs_.NewEntryWrapper(
            it->first, it->second));
        ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
            5, *entry, output);
        Utf8Check::Check(&*it);
      }
    }
  }

  // optional string device = 6;
  if (this->device().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device().data(), this->device().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.eager.Operation.device");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      6, this->device(), output);
  }

  // optional bool is_component_function = 7;
  if (this->is_component_function() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(7, this->is_component_function(), output);
  }

  // optional int64 func_step_id = 8;
  if (this->func_step_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(8, this->func_step_id(), output);
  }

  // optional bool is_function = 9;
  if (this->is_function() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(9, this->is_function(), output);
  }

  // repeated .tensorflow.eager.Operation.Input op_inputs = 10;
  for (unsigned int i = 0, n = this->op_inputs_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      10, this->op_inputs(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.Operation)
}

::google::protobuf::uint8* Operation::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.Operation)
  // optional int64 id = 1;
  if (this->id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(1, this->id(), target);
  }

  // optional string name = 2;
  if (this->name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.eager.Operation.name");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        2, this->name(), target);
  }

  // repeated int64 control_op_ids = 4;
  if (this->control_op_ids_size() > 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteTagToArray(
      4,
      ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED,
      target);
    target = ::google::protobuf::io::CodedOutputStream::WriteVarint32ToArray(
      _control_op_ids_cached_byte_size_, target);
  }
  for (int i = 0; i < this->control_op_ids_size(); i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteInt64NoTagToArray(this->control_op_ids(i), target);
  }

  // map<string, .tensorflow.AttrValue> attrs = 5;
  if (!this->attrs().empty()) {
    typedef ::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue >::const_pointer
        ConstPtr;
    typedef ConstPtr SortItem;
    typedef ::google::protobuf::internal::CompareByDerefFirst<SortItem> Less;
    struct Utf8Check {
      static void Check(ConstPtr p) {
        ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          p->first.data(), p->first.length(),
          ::google::protobuf::internal::WireFormatLite::SERIALIZE,
          "tensorflow.eager.Operation.AttrsEntry.key");
      }
    };

    if (deterministic &&
        this->attrs().size() > 1) {
      ::google::protobuf::scoped_array<SortItem> items(
          new SortItem[this->attrs().size()]);
      typedef ::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue >::size_type size_type;
      size_type n = 0;
      for (::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue >::const_iterator
          it = this->attrs().begin();
          it != this->attrs().end(); ++it, ++n) {
        items[n] = SortItem(&*it);
      }
      ::std::sort(&items[0], &items[n], Less());
      ::google::protobuf::scoped_ptr<Operation_AttrsEntry> entry;
      for (size_type i = 0; i < n; i++) {
        entry.reset(attrs_.NewEntryWrapper(
            items[i]->first, items[i]->second));
        target = ::google::protobuf::internal::WireFormatLite::
                   InternalWriteMessageNoVirtualToArray(
                       5, *entry, deterministic, target);
;
        Utf8Check::Check(items[i]);
      }
    } else {
      ::google::protobuf::scoped_ptr<Operation_AttrsEntry> entry;
      for (::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue >::const_iterator
          it = this->attrs().begin();
          it != this->attrs().end(); ++it) {
        entry.reset(attrs_.NewEntryWrapper(
            it->first, it->second));
        target = ::google::protobuf::internal::WireFormatLite::
                   InternalWriteMessageNoVirtualToArray(
                       5, *entry, deterministic, target);
;
        Utf8Check::Check(&*it);
      }
    }
  }

  // optional string device = 6;
  if (this->device().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device().data(), this->device().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.eager.Operation.device");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        6, this->device(), target);
  }

  // optional bool is_component_function = 7;
  if (this->is_component_function() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(7, this->is_component_function(), target);
  }

  // optional int64 func_step_id = 8;
  if (this->func_step_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(8, this->func_step_id(), target);
  }

  // optional bool is_function = 9;
  if (this->is_function() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(9, this->is_function(), target);
  }

  // repeated .tensorflow.eager.Operation.Input op_inputs = 10;
  for (unsigned int i = 0, n = this->op_inputs_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        10, this->op_inputs(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.Operation)
  return target;
}

int Operation::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.Operation)
  int total_size = 0;

  // optional int64 id = 1;
  if (this->id() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->id());
  }

  // optional string name = 2;
  if (this->name().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->name());
  }

  // optional string device = 6;
  if (this->device().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->device());
  }

  // optional bool is_component_function = 7;
  if (this->is_component_function() != 0) {
    total_size += 1 + 1;
  }

  // optional int64 func_step_id = 8;
  if (this->func_step_id() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->func_step_id());
  }

  // optional bool is_function = 9;
  if (this->is_function() != 0) {
    total_size += 1 + 1;
  }

  // repeated .tensorflow.eager.Operation.Input op_inputs = 10;
  total_size += 1 * this->op_inputs_size();
  for (int i = 0; i < this->op_inputs_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->op_inputs(i));
  }

  // repeated int64 control_op_ids = 4;
  {
    int data_size = 0;
    for (int i = 0; i < this->control_op_ids_size(); i++) {
      data_size += ::google::protobuf::internal::WireFormatLite::
        Int64Size(this->control_op_ids(i));
    }
    if (data_size > 0) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(data_size);
    }
    GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
    _control_op_ids_cached_byte_size_ = data_size;
    GOOGLE_SAFE_CONCURRENT_WRITES_END();
    total_size += data_size;
  }

  // map<string, .tensorflow.AttrValue> attrs = 5;
  total_size += 1 * this->attrs_size();
  {
    ::google::protobuf::scoped_ptr<Operation_AttrsEntry> entry;
    for (::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue >::const_iterator
        it = this->attrs().begin();
        it != this->attrs().end(); ++it) {
      entry.reset(attrs_.NewEntryWrapper(it->first, it->second));
      total_size += ::google::protobuf::internal::WireFormatLite::
          MessageSizeNoVirtual(*entry);
    }
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void Operation::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.Operation)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const Operation* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const Operation>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.Operation)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.Operation)
    MergeFrom(*source);
  }
}

void Operation::MergeFrom(const Operation& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.Operation)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  op_inputs_.MergeFrom(from.op_inputs_);
  control_op_ids_.MergeFrom(from.control_op_ids_);
  attrs_.MergeFrom(from.attrs_);
  if (from.id() != 0) {
    set_id(from.id());
  }
  if (from.name().size() > 0) {

    name_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.name_);
  }
  if (from.device().size() > 0) {

    device_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.device_);
  }
  if (from.is_component_function() != 0) {
    set_is_component_function(from.is_component_function());
  }
  if (from.func_step_id() != 0) {
    set_func_step_id(from.func_step_id());
  }
  if (from.is_function() != 0) {
    set_is_function(from.is_function());
  }
}

void Operation::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.Operation)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void Operation::CopyFrom(const Operation& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.Operation)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool Operation::IsInitialized() const {

  return true;
}

void Operation::Swap(Operation* other) {
  if (other == this) return;
  InternalSwap(other);
}
void Operation::InternalSwap(Operation* other) {
  std::swap(id_, other->id_);
  name_.Swap(&other->name_);
  op_inputs_.UnsafeArenaSwap(&other->op_inputs_);
  control_op_ids_.UnsafeArenaSwap(&other->control_op_ids_);
  attrs_.Swap(&other->attrs_);
  device_.Swap(&other->device_);
  std::swap(is_component_function_, other->is_component_function_);
  std::swap(func_step_id_, other->func_step_id_);
  std::swap(is_function_, other->is_function_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata Operation::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = Operation_descriptor_;
  metadata.reflection = Operation_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// Operation_Input

// optional .tensorflow.eager.RemoteTensorHandle remote_handle = 1;
bool Operation_Input::has_remote_handle() const {
  return item_case() == kRemoteHandle;
}
void Operation_Input::set_has_remote_handle() {
  _oneof_case_[0] = kRemoteHandle;
}
void Operation_Input::clear_remote_handle() {
  if (has_remote_handle()) {
    delete item_.remote_handle_;
    clear_has_item();
  }
}
 const ::tensorflow::eager::RemoteTensorHandle& Operation_Input::remote_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.Operation.Input.remote_handle)
  return has_remote_handle()
      ? *item_.remote_handle_
      : ::tensorflow::eager::RemoteTensorHandle::default_instance();
}
::tensorflow::eager::RemoteTensorHandle* Operation_Input::mutable_remote_handle() {
  if (!has_remote_handle()) {
    clear_item();
    set_has_remote_handle();
    item_.remote_handle_ = new ::tensorflow::eager::RemoteTensorHandle;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.Operation.Input.remote_handle)
  return item_.remote_handle_;
}
::tensorflow::eager::RemoteTensorHandle* Operation_Input::release_remote_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.Operation.Input.remote_handle)
  if (has_remote_handle()) {
    clear_has_item();
    ::tensorflow::eager::RemoteTensorHandle* temp = item_.remote_handle_;
    item_.remote_handle_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void Operation_Input::set_allocated_remote_handle(::tensorflow::eager::RemoteTensorHandle* remote_handle) {
  clear_item();
  if (remote_handle) {
    if (static_cast< ::tensorflow::eager::RemoteTensorHandle*>(remote_handle)->GetArena() != NULL) {
      ::tensorflow::eager::RemoteTensorHandle* new_remote_handle = new ::tensorflow::eager::RemoteTensorHandle;
      new_remote_handle->CopyFrom(*remote_handle);
      remote_handle = new_remote_handle;
    }
    set_has_remote_handle();
    item_.remote_handle_ = remote_handle;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.Operation.Input.remote_handle)
}

// optional .tensorflow.TensorProto tensor = 2;
bool Operation_Input::has_tensor() const {
  return item_case() == kTensor;
}
void Operation_Input::set_has_tensor() {
  _oneof_case_[0] = kTensor;
}
void Operation_Input::clear_tensor() {
  if (has_tensor()) {
    delete item_.tensor_;
    clear_has_item();
  }
}
 const ::tensorflow::TensorProto& Operation_Input::tensor() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.Operation.Input.tensor)
  return has_tensor()
      ? *item_.tensor_
      : ::tensorflow::TensorProto::default_instance();
}
::tensorflow::TensorProto* Operation_Input::mutable_tensor() {
  if (!has_tensor()) {
    clear_item();
    set_has_tensor();
    item_.tensor_ = new ::tensorflow::TensorProto;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.Operation.Input.tensor)
  return item_.tensor_;
}
::tensorflow::TensorProto* Operation_Input::release_tensor() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.Operation.Input.tensor)
  if (has_tensor()) {
    clear_has_item();
    ::tensorflow::TensorProto* temp = item_.tensor_;
    item_.tensor_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void Operation_Input::set_allocated_tensor(::tensorflow::TensorProto* tensor) {
  clear_item();
  if (tensor) {
    if (static_cast< ::tensorflow::TensorProto*>(tensor)->GetArena() != NULL) {
      ::tensorflow::TensorProto* new_tensor = new ::tensorflow::TensorProto;
      new_tensor->CopyFrom(*tensor);
      tensor = new_tensor;
    }
    set_has_tensor();
    item_.tensor_ = tensor;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.Operation.Input.tensor)
}

bool Operation_Input::has_item() const {
  return item_case() != ITEM_NOT_SET;
}
void Operation_Input::clear_has_item() {
  _oneof_case_[0] = ITEM_NOT_SET;
}
Operation_Input::ItemCase Operation_Input::item_case() const {
  return Operation_Input::ItemCase(_oneof_case_[0]);
}
// -------------------------------------------------------------------

// Operation

// optional int64 id = 1;
void Operation::clear_id() {
  id_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 Operation::id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.Operation.id)
  return id_;
}
 void Operation::set_id(::google::protobuf::int64 value) {
  
  id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.Operation.id)
}

// optional string name = 2;
void Operation::clear_name() {
  name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& Operation::name() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.Operation.name)
  return name_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void Operation::set_name(const ::std::string& value) {
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.eager.Operation.name)
}
 void Operation::set_name(const char* value) {
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.eager.Operation.name)
}
 void Operation::set_name(const char* value, size_t size) {
  
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.eager.Operation.name)
}
 ::std::string* Operation::mutable_name() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.Operation.name)
  return name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* Operation::release_name() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.Operation.name)
  
  return name_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void Operation::set_allocated_name(::std::string* name) {
  if (name != NULL) {
    
  } else {
    
  }
  name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), name);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.Operation.name)
}

// repeated .tensorflow.eager.Operation.Input op_inputs = 10;
int Operation::op_inputs_size() const {
  return op_inputs_.size();
}
void Operation::clear_op_inputs() {
  op_inputs_.Clear();
}
const ::tensorflow::eager::Operation_Input& Operation::op_inputs(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.Operation.op_inputs)
  return op_inputs_.Get(index);
}
::tensorflow::eager::Operation_Input* Operation::mutable_op_inputs(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.Operation.op_inputs)
  return op_inputs_.Mutable(index);
}
::tensorflow::eager::Operation_Input* Operation::add_op_inputs() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.Operation.op_inputs)
  return op_inputs_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::eager::Operation_Input >*
Operation::mutable_op_inputs() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.Operation.op_inputs)
  return &op_inputs_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::eager::Operation_Input >&
Operation::op_inputs() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.Operation.op_inputs)
  return op_inputs_;
}

// repeated int64 control_op_ids = 4;
int Operation::control_op_ids_size() const {
  return control_op_ids_.size();
}
void Operation::clear_control_op_ids() {
  control_op_ids_.Clear();
}
 ::google::protobuf::int64 Operation::control_op_ids(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.Operation.control_op_ids)
  return control_op_ids_.Get(index);
}
 void Operation::set_control_op_ids(int index, ::google::protobuf::int64 value) {
  control_op_ids_.Set(index, value);
  // @@protoc_insertion_point(field_set:tensorflow.eager.Operation.control_op_ids)
}
 void Operation::add_control_op_ids(::google::protobuf::int64 value) {
  control_op_ids_.Add(value);
  // @@protoc_insertion_point(field_add:tensorflow.eager.Operation.control_op_ids)
}
 const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
Operation::control_op_ids() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.Operation.control_op_ids)
  return control_op_ids_;
}
 ::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
Operation::mutable_control_op_ids() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.Operation.control_op_ids)
  return &control_op_ids_;
}

// map<string, .tensorflow.AttrValue> attrs = 5;
int Operation::attrs_size() const {
  return attrs_.size();
}
void Operation::clear_attrs() {
  attrs_.Clear();
}
 const ::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue >&
Operation::attrs() const {
  // @@protoc_insertion_point(field_map:tensorflow.eager.Operation.attrs)
  return attrs_.GetMap();
}
 ::google::protobuf::Map< ::std::string, ::tensorflow::AttrValue >*
Operation::mutable_attrs() {
  // @@protoc_insertion_point(field_mutable_map:tensorflow.eager.Operation.attrs)
  return attrs_.MutableMap();
}

// optional string device = 6;
void Operation::clear_device() {
  device_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& Operation::device() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.Operation.device)
  return device_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void Operation::set_device(const ::std::string& value) {
  
  device_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.eager.Operation.device)
}
 void Operation::set_device(const char* value) {
  
  device_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.eager.Operation.device)
}
 void Operation::set_device(const char* value, size_t size) {
  
  device_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.eager.Operation.device)
}
 ::std::string* Operation::mutable_device() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.Operation.device)
  return device_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* Operation::release_device() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.Operation.device)
  
  return device_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void Operation::set_allocated_device(::std::string* device) {
  if (device != NULL) {
    
  } else {
    
  }
  device_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), device);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.Operation.device)
}

// optional bool is_component_function = 7;
void Operation::clear_is_component_function() {
  is_component_function_ = false;
}
 bool Operation::is_component_function() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.Operation.is_component_function)
  return is_component_function_;
}
 void Operation::set_is_component_function(bool value) {
  
  is_component_function_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.Operation.is_component_function)
}

// optional int64 func_step_id = 8;
void Operation::clear_func_step_id() {
  func_step_id_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 Operation::func_step_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.Operation.func_step_id)
  return func_step_id_;
}
 void Operation::set_func_step_id(::google::protobuf::int64 value) {
  
  func_step_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.Operation.func_step_id)
}

// optional bool is_function = 9;
void Operation::clear_is_function() {
  is_function_ = false;
}
 bool Operation::is_function() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.Operation.is_function)
  return is_function_;
}
 void Operation::set_is_function(bool value) {
  
  is_function_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.Operation.is_function)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int QueueItem::kHandleToDecrefFieldNumber;
const int QueueItem::kOperationFieldNumber;
const int QueueItem::kSendTensorFieldNumber;
const int QueueItem::kRegisterFunctionFieldNumber;
const int QueueItem::kCleanupFunctionFieldNumber;
const int QueueItem::kSyncRemoteExecutorForStreamFieldNumber;
const int QueueItem::kSendPackedHandleFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

QueueItem::QueueItem()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.QueueItem)
}

void QueueItem::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  QueueItem_default_oneof_instance_->handle_to_decref_ = const_cast< ::tensorflow::eager::RemoteTensorHandle*>(&::tensorflow::eager::RemoteTensorHandle::default_instance());
  QueueItem_default_oneof_instance_->operation_ = const_cast< ::tensorflow::eager::Operation*>(&::tensorflow::eager::Operation::default_instance());
  QueueItem_default_oneof_instance_->send_tensor_ = const_cast< ::tensorflow::eager::SendTensorOp*>(&::tensorflow::eager::SendTensorOp::default_instance());
  QueueItem_default_oneof_instance_->register_function_ = const_cast< ::tensorflow::eager::RegisterFunctionOp*>(&::tensorflow::eager::RegisterFunctionOp::default_instance());
  QueueItem_default_oneof_instance_->cleanup_function_ = const_cast< ::tensorflow::eager::CleanupFunctionOp*>(&::tensorflow::eager::CleanupFunctionOp::default_instance());
  QueueItem_default_oneof_instance_->sync_remote_executor_for_stream_ = const_cast< ::tensorflow::eager::SyncRemoteExecutorForStream*>(&::tensorflow::eager::SyncRemoteExecutorForStream::default_instance());
  QueueItem_default_oneof_instance_->send_packed_handle_ = const_cast< ::tensorflow::eager::SendPackedHandleOp*>(&::tensorflow::eager::SendPackedHandleOp::default_instance());
}

QueueItem::QueueItem(const QueueItem& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.QueueItem)
}

void QueueItem::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  clear_has_item();
}

QueueItem::~QueueItem() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.QueueItem)
  SharedDtor();
}

void QueueItem::SharedDtor() {
  if (has_item()) {
    clear_item();
  }
  if (this != default_instance_) {
  }
}

void QueueItem::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* QueueItem::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return QueueItem_descriptor_;
}

const QueueItem& QueueItem::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

QueueItem* QueueItem::default_instance_ = NULL;

QueueItem* QueueItem::New(::google::protobuf::Arena* arena) const {
  QueueItem* n = new QueueItem;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void QueueItem::clear_item() {
// @@protoc_insertion_point(one_of_clear_start:tensorflow.eager.QueueItem)
  switch(item_case()) {
    case kHandleToDecref: {
      delete item_.handle_to_decref_;
      break;
    }
    case kOperation: {
      delete item_.operation_;
      break;
    }
    case kSendTensor: {
      delete item_.send_tensor_;
      break;
    }
    case kRegisterFunction: {
      delete item_.register_function_;
      break;
    }
    case kCleanupFunction: {
      delete item_.cleanup_function_;
      break;
    }
    case kSyncRemoteExecutorForStream: {
      delete item_.sync_remote_executor_for_stream_;
      break;
    }
    case kSendPackedHandle: {
      delete item_.send_packed_handle_;
      break;
    }
    case ITEM_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = ITEM_NOT_SET;
}


void QueueItem::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.QueueItem)
  clear_item();
}

bool QueueItem::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.QueueItem)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.eager.RemoteTensorHandle handle_to_decref = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_handle_to_decref()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_operation;
        break;
      }

      // optional .tensorflow.eager.Operation operation = 2;
      case 2: {
        if (tag == 18) {
         parse_operation:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_operation()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_send_tensor;
        break;
      }

      // optional .tensorflow.eager.SendTensorOp send_tensor = 3;
      case 3: {
        if (tag == 26) {
         parse_send_tensor:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_send_tensor()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_register_function;
        break;
      }

      // optional .tensorflow.eager.RegisterFunctionOp register_function = 4;
      case 4: {
        if (tag == 34) {
         parse_register_function:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_register_function()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(42)) goto parse_cleanup_function;
        break;
      }

      // optional .tensorflow.eager.CleanupFunctionOp cleanup_function = 5;
      case 5: {
        if (tag == 42) {
         parse_cleanup_function:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_cleanup_function()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(50)) goto parse_sync_remote_executor_for_stream;
        break;
      }

      // optional .tensorflow.eager.SyncRemoteExecutorForStream sync_remote_executor_for_stream = 6;
      case 6: {
        if (tag == 50) {
         parse_sync_remote_executor_for_stream:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_sync_remote_executor_for_stream()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(58)) goto parse_send_packed_handle;
        break;
      }

      // optional .tensorflow.eager.SendPackedHandleOp send_packed_handle = 7;
      case 7: {
        if (tag == 58) {
         parse_send_packed_handle:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_send_packed_handle()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.QueueItem)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.QueueItem)
  return false;
#undef DO_
}

void QueueItem::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.QueueItem)
  // optional .tensorflow.eager.RemoteTensorHandle handle_to_decref = 1;
  if (has_handle_to_decref()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *item_.handle_to_decref_, output);
  }

  // optional .tensorflow.eager.Operation operation = 2;
  if (has_operation()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *item_.operation_, output);
  }

  // optional .tensorflow.eager.SendTensorOp send_tensor = 3;
  if (has_send_tensor()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, *item_.send_tensor_, output);
  }

  // optional .tensorflow.eager.RegisterFunctionOp register_function = 4;
  if (has_register_function()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, *item_.register_function_, output);
  }

  // optional .tensorflow.eager.CleanupFunctionOp cleanup_function = 5;
  if (has_cleanup_function()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      5, *item_.cleanup_function_, output);
  }

  // optional .tensorflow.eager.SyncRemoteExecutorForStream sync_remote_executor_for_stream = 6;
  if (has_sync_remote_executor_for_stream()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      6, *item_.sync_remote_executor_for_stream_, output);
  }

  // optional .tensorflow.eager.SendPackedHandleOp send_packed_handle = 7;
  if (has_send_packed_handle()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      7, *item_.send_packed_handle_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.QueueItem)
}

::google::protobuf::uint8* QueueItem::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.QueueItem)
  // optional .tensorflow.eager.RemoteTensorHandle handle_to_decref = 1;
  if (has_handle_to_decref()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *item_.handle_to_decref_, false, target);
  }

  // optional .tensorflow.eager.Operation operation = 2;
  if (has_operation()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *item_.operation_, false, target);
  }

  // optional .tensorflow.eager.SendTensorOp send_tensor = 3;
  if (has_send_tensor()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        3, *item_.send_tensor_, false, target);
  }

  // optional .tensorflow.eager.RegisterFunctionOp register_function = 4;
  if (has_register_function()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        4, *item_.register_function_, false, target);
  }

  // optional .tensorflow.eager.CleanupFunctionOp cleanup_function = 5;
  if (has_cleanup_function()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        5, *item_.cleanup_function_, false, target);
  }

  // optional .tensorflow.eager.SyncRemoteExecutorForStream sync_remote_executor_for_stream = 6;
  if (has_sync_remote_executor_for_stream()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        6, *item_.sync_remote_executor_for_stream_, false, target);
  }

  // optional .tensorflow.eager.SendPackedHandleOp send_packed_handle = 7;
  if (has_send_packed_handle()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        7, *item_.send_packed_handle_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.QueueItem)
  return target;
}

int QueueItem::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.QueueItem)
  int total_size = 0;

  switch (item_case()) {
    // optional .tensorflow.eager.RemoteTensorHandle handle_to_decref = 1;
    case kHandleToDecref: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *item_.handle_to_decref_);
      break;
    }
    // optional .tensorflow.eager.Operation operation = 2;
    case kOperation: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *item_.operation_);
      break;
    }
    // optional .tensorflow.eager.SendTensorOp send_tensor = 3;
    case kSendTensor: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *item_.send_tensor_);
      break;
    }
    // optional .tensorflow.eager.RegisterFunctionOp register_function = 4;
    case kRegisterFunction: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *item_.register_function_);
      break;
    }
    // optional .tensorflow.eager.CleanupFunctionOp cleanup_function = 5;
    case kCleanupFunction: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *item_.cleanup_function_);
      break;
    }
    // optional .tensorflow.eager.SyncRemoteExecutorForStream sync_remote_executor_for_stream = 6;
    case kSyncRemoteExecutorForStream: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *item_.sync_remote_executor_for_stream_);
      break;
    }
    // optional .tensorflow.eager.SendPackedHandleOp send_packed_handle = 7;
    case kSendPackedHandle: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *item_.send_packed_handle_);
      break;
    }
    case ITEM_NOT_SET: {
      break;
    }
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void QueueItem::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.QueueItem)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const QueueItem* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const QueueItem>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.QueueItem)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.QueueItem)
    MergeFrom(*source);
  }
}

void QueueItem::MergeFrom(const QueueItem& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.QueueItem)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  switch (from.item_case()) {
    case kHandleToDecref: {
      mutable_handle_to_decref()->::tensorflow::eager::RemoteTensorHandle::MergeFrom(from.handle_to_decref());
      break;
    }
    case kOperation: {
      mutable_operation()->::tensorflow::eager::Operation::MergeFrom(from.operation());
      break;
    }
    case kSendTensor: {
      mutable_send_tensor()->::tensorflow::eager::SendTensorOp::MergeFrom(from.send_tensor());
      break;
    }
    case kRegisterFunction: {
      mutable_register_function()->::tensorflow::eager::RegisterFunctionOp::MergeFrom(from.register_function());
      break;
    }
    case kCleanupFunction: {
      mutable_cleanup_function()->::tensorflow::eager::CleanupFunctionOp::MergeFrom(from.cleanup_function());
      break;
    }
    case kSyncRemoteExecutorForStream: {
      mutable_sync_remote_executor_for_stream()->::tensorflow::eager::SyncRemoteExecutorForStream::MergeFrom(from.sync_remote_executor_for_stream());
      break;
    }
    case kSendPackedHandle: {
      mutable_send_packed_handle()->::tensorflow::eager::SendPackedHandleOp::MergeFrom(from.send_packed_handle());
      break;
    }
    case ITEM_NOT_SET: {
      break;
    }
  }
}

void QueueItem::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.QueueItem)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void QueueItem::CopyFrom(const QueueItem& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.QueueItem)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool QueueItem::IsInitialized() const {

  return true;
}

void QueueItem::Swap(QueueItem* other) {
  if (other == this) return;
  InternalSwap(other);
}
void QueueItem::InternalSwap(QueueItem* other) {
  std::swap(item_, other->item_);
  std::swap(_oneof_case_[0], other->_oneof_case_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata QueueItem::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = QueueItem_descriptor_;
  metadata.reflection = QueueItem_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// QueueItem

// optional .tensorflow.eager.RemoteTensorHandle handle_to_decref = 1;
bool QueueItem::has_handle_to_decref() const {
  return item_case() == kHandleToDecref;
}
void QueueItem::set_has_handle_to_decref() {
  _oneof_case_[0] = kHandleToDecref;
}
void QueueItem::clear_handle_to_decref() {
  if (has_handle_to_decref()) {
    delete item_.handle_to_decref_;
    clear_has_item();
  }
}
 const ::tensorflow::eager::RemoteTensorHandle& QueueItem::handle_to_decref() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.QueueItem.handle_to_decref)
  return has_handle_to_decref()
      ? *item_.handle_to_decref_
      : ::tensorflow::eager::RemoteTensorHandle::default_instance();
}
::tensorflow::eager::RemoteTensorHandle* QueueItem::mutable_handle_to_decref() {
  if (!has_handle_to_decref()) {
    clear_item();
    set_has_handle_to_decref();
    item_.handle_to_decref_ = new ::tensorflow::eager::RemoteTensorHandle;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.QueueItem.handle_to_decref)
  return item_.handle_to_decref_;
}
::tensorflow::eager::RemoteTensorHandle* QueueItem::release_handle_to_decref() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.QueueItem.handle_to_decref)
  if (has_handle_to_decref()) {
    clear_has_item();
    ::tensorflow::eager::RemoteTensorHandle* temp = item_.handle_to_decref_;
    item_.handle_to_decref_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void QueueItem::set_allocated_handle_to_decref(::tensorflow::eager::RemoteTensorHandle* handle_to_decref) {
  clear_item();
  if (handle_to_decref) {
    if (static_cast< ::tensorflow::eager::RemoteTensorHandle*>(handle_to_decref)->GetArena() != NULL) {
      ::tensorflow::eager::RemoteTensorHandle* new_handle_to_decref = new ::tensorflow::eager::RemoteTensorHandle;
      new_handle_to_decref->CopyFrom(*handle_to_decref);
      handle_to_decref = new_handle_to_decref;
    }
    set_has_handle_to_decref();
    item_.handle_to_decref_ = handle_to_decref;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.QueueItem.handle_to_decref)
}

// optional .tensorflow.eager.Operation operation = 2;
bool QueueItem::has_operation() const {
  return item_case() == kOperation;
}
void QueueItem::set_has_operation() {
  _oneof_case_[0] = kOperation;
}
void QueueItem::clear_operation() {
  if (has_operation()) {
    delete item_.operation_;
    clear_has_item();
  }
}
 const ::tensorflow::eager::Operation& QueueItem::operation() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.QueueItem.operation)
  return has_operation()
      ? *item_.operation_
      : ::tensorflow::eager::Operation::default_instance();
}
::tensorflow::eager::Operation* QueueItem::mutable_operation() {
  if (!has_operation()) {
    clear_item();
    set_has_operation();
    item_.operation_ = new ::tensorflow::eager::Operation;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.QueueItem.operation)
  return item_.operation_;
}
::tensorflow::eager::Operation* QueueItem::release_operation() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.QueueItem.operation)
  if (has_operation()) {
    clear_has_item();
    ::tensorflow::eager::Operation* temp = item_.operation_;
    item_.operation_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void QueueItem::set_allocated_operation(::tensorflow::eager::Operation* operation) {
  clear_item();
  if (operation) {
    set_has_operation();
    item_.operation_ = operation;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.QueueItem.operation)
}

// optional .tensorflow.eager.SendTensorOp send_tensor = 3;
bool QueueItem::has_send_tensor() const {
  return item_case() == kSendTensor;
}
void QueueItem::set_has_send_tensor() {
  _oneof_case_[0] = kSendTensor;
}
void QueueItem::clear_send_tensor() {
  if (has_send_tensor()) {
    delete item_.send_tensor_;
    clear_has_item();
  }
}
 const ::tensorflow::eager::SendTensorOp& QueueItem::send_tensor() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.QueueItem.send_tensor)
  return has_send_tensor()
      ? *item_.send_tensor_
      : ::tensorflow::eager::SendTensorOp::default_instance();
}
::tensorflow::eager::SendTensorOp* QueueItem::mutable_send_tensor() {
  if (!has_send_tensor()) {
    clear_item();
    set_has_send_tensor();
    item_.send_tensor_ = new ::tensorflow::eager::SendTensorOp;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.QueueItem.send_tensor)
  return item_.send_tensor_;
}
::tensorflow::eager::SendTensorOp* QueueItem::release_send_tensor() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.QueueItem.send_tensor)
  if (has_send_tensor()) {
    clear_has_item();
    ::tensorflow::eager::SendTensorOp* temp = item_.send_tensor_;
    item_.send_tensor_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void QueueItem::set_allocated_send_tensor(::tensorflow::eager::SendTensorOp* send_tensor) {
  clear_item();
  if (send_tensor) {
    set_has_send_tensor();
    item_.send_tensor_ = send_tensor;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.QueueItem.send_tensor)
}

// optional .tensorflow.eager.RegisterFunctionOp register_function = 4;
bool QueueItem::has_register_function() const {
  return item_case() == kRegisterFunction;
}
void QueueItem::set_has_register_function() {
  _oneof_case_[0] = kRegisterFunction;
}
void QueueItem::clear_register_function() {
  if (has_register_function()) {
    delete item_.register_function_;
    clear_has_item();
  }
}
 const ::tensorflow::eager::RegisterFunctionOp& QueueItem::register_function() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.QueueItem.register_function)
  return has_register_function()
      ? *item_.register_function_
      : ::tensorflow::eager::RegisterFunctionOp::default_instance();
}
::tensorflow::eager::RegisterFunctionOp* QueueItem::mutable_register_function() {
  if (!has_register_function()) {
    clear_item();
    set_has_register_function();
    item_.register_function_ = new ::tensorflow::eager::RegisterFunctionOp;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.QueueItem.register_function)
  return item_.register_function_;
}
::tensorflow::eager::RegisterFunctionOp* QueueItem::release_register_function() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.QueueItem.register_function)
  if (has_register_function()) {
    clear_has_item();
    ::tensorflow::eager::RegisterFunctionOp* temp = item_.register_function_;
    item_.register_function_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void QueueItem::set_allocated_register_function(::tensorflow::eager::RegisterFunctionOp* register_function) {
  clear_item();
  if (register_function) {
    set_has_register_function();
    item_.register_function_ = register_function;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.QueueItem.register_function)
}

// optional .tensorflow.eager.CleanupFunctionOp cleanup_function = 5;
bool QueueItem::has_cleanup_function() const {
  return item_case() == kCleanupFunction;
}
void QueueItem::set_has_cleanup_function() {
  _oneof_case_[0] = kCleanupFunction;
}
void QueueItem::clear_cleanup_function() {
  if (has_cleanup_function()) {
    delete item_.cleanup_function_;
    clear_has_item();
  }
}
 const ::tensorflow::eager::CleanupFunctionOp& QueueItem::cleanup_function() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.QueueItem.cleanup_function)
  return has_cleanup_function()
      ? *item_.cleanup_function_
      : ::tensorflow::eager::CleanupFunctionOp::default_instance();
}
::tensorflow::eager::CleanupFunctionOp* QueueItem::mutable_cleanup_function() {
  if (!has_cleanup_function()) {
    clear_item();
    set_has_cleanup_function();
    item_.cleanup_function_ = new ::tensorflow::eager::CleanupFunctionOp;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.QueueItem.cleanup_function)
  return item_.cleanup_function_;
}
::tensorflow::eager::CleanupFunctionOp* QueueItem::release_cleanup_function() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.QueueItem.cleanup_function)
  if (has_cleanup_function()) {
    clear_has_item();
    ::tensorflow::eager::CleanupFunctionOp* temp = item_.cleanup_function_;
    item_.cleanup_function_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void QueueItem::set_allocated_cleanup_function(::tensorflow::eager::CleanupFunctionOp* cleanup_function) {
  clear_item();
  if (cleanup_function) {
    set_has_cleanup_function();
    item_.cleanup_function_ = cleanup_function;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.QueueItem.cleanup_function)
}

// optional .tensorflow.eager.SyncRemoteExecutorForStream sync_remote_executor_for_stream = 6;
bool QueueItem::has_sync_remote_executor_for_stream() const {
  return item_case() == kSyncRemoteExecutorForStream;
}
void QueueItem::set_has_sync_remote_executor_for_stream() {
  _oneof_case_[0] = kSyncRemoteExecutorForStream;
}
void QueueItem::clear_sync_remote_executor_for_stream() {
  if (has_sync_remote_executor_for_stream()) {
    delete item_.sync_remote_executor_for_stream_;
    clear_has_item();
  }
}
 const ::tensorflow::eager::SyncRemoteExecutorForStream& QueueItem::sync_remote_executor_for_stream() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.QueueItem.sync_remote_executor_for_stream)
  return has_sync_remote_executor_for_stream()
      ? *item_.sync_remote_executor_for_stream_
      : ::tensorflow::eager::SyncRemoteExecutorForStream::default_instance();
}
::tensorflow::eager::SyncRemoteExecutorForStream* QueueItem::mutable_sync_remote_executor_for_stream() {
  if (!has_sync_remote_executor_for_stream()) {
    clear_item();
    set_has_sync_remote_executor_for_stream();
    item_.sync_remote_executor_for_stream_ = new ::tensorflow::eager::SyncRemoteExecutorForStream;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.QueueItem.sync_remote_executor_for_stream)
  return item_.sync_remote_executor_for_stream_;
}
::tensorflow::eager::SyncRemoteExecutorForStream* QueueItem::release_sync_remote_executor_for_stream() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.QueueItem.sync_remote_executor_for_stream)
  if (has_sync_remote_executor_for_stream()) {
    clear_has_item();
    ::tensorflow::eager::SyncRemoteExecutorForStream* temp = item_.sync_remote_executor_for_stream_;
    item_.sync_remote_executor_for_stream_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void QueueItem::set_allocated_sync_remote_executor_for_stream(::tensorflow::eager::SyncRemoteExecutorForStream* sync_remote_executor_for_stream) {
  clear_item();
  if (sync_remote_executor_for_stream) {
    set_has_sync_remote_executor_for_stream();
    item_.sync_remote_executor_for_stream_ = sync_remote_executor_for_stream;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.QueueItem.sync_remote_executor_for_stream)
}

// optional .tensorflow.eager.SendPackedHandleOp send_packed_handle = 7;
bool QueueItem::has_send_packed_handle() const {
  return item_case() == kSendPackedHandle;
}
void QueueItem::set_has_send_packed_handle() {
  _oneof_case_[0] = kSendPackedHandle;
}
void QueueItem::clear_send_packed_handle() {
  if (has_send_packed_handle()) {
    delete item_.send_packed_handle_;
    clear_has_item();
  }
}
 const ::tensorflow::eager::SendPackedHandleOp& QueueItem::send_packed_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.QueueItem.send_packed_handle)
  return has_send_packed_handle()
      ? *item_.send_packed_handle_
      : ::tensorflow::eager::SendPackedHandleOp::default_instance();
}
::tensorflow::eager::SendPackedHandleOp* QueueItem::mutable_send_packed_handle() {
  if (!has_send_packed_handle()) {
    clear_item();
    set_has_send_packed_handle();
    item_.send_packed_handle_ = new ::tensorflow::eager::SendPackedHandleOp;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.QueueItem.send_packed_handle)
  return item_.send_packed_handle_;
}
::tensorflow::eager::SendPackedHandleOp* QueueItem::release_send_packed_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.QueueItem.send_packed_handle)
  if (has_send_packed_handle()) {
    clear_has_item();
    ::tensorflow::eager::SendPackedHandleOp* temp = item_.send_packed_handle_;
    item_.send_packed_handle_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void QueueItem::set_allocated_send_packed_handle(::tensorflow::eager::SendPackedHandleOp* send_packed_handle) {
  clear_item();
  if (send_packed_handle) {
    set_has_send_packed_handle();
    item_.send_packed_handle_ = send_packed_handle;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.QueueItem.send_packed_handle)
}

bool QueueItem::has_item() const {
  return item_case() != ITEM_NOT_SET;
}
void QueueItem::clear_has_item() {
  _oneof_case_[0] = ITEM_NOT_SET;
}
QueueItem::ItemCase QueueItem::item_case() const {
  return QueueItem::ItemCase(_oneof_case_[0]);
}
#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int QueueResponse::kShapeFieldNumber;
const int QueueResponse::kTensorFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

QueueResponse::QueueResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.QueueResponse)
}

void QueueResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

QueueResponse::QueueResponse(const QueueResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.QueueResponse)
}

void QueueResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

QueueResponse::~QueueResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.QueueResponse)
  SharedDtor();
}

void QueueResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void QueueResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* QueueResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return QueueResponse_descriptor_;
}

const QueueResponse& QueueResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

QueueResponse* QueueResponse::default_instance_ = NULL;

QueueResponse* QueueResponse::New(::google::protobuf::Arena* arena) const {
  QueueResponse* n = new QueueResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void QueueResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.QueueResponse)
  shape_.Clear();
  tensor_.Clear();
}

bool QueueResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.QueueResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.TensorShapeProto shape = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_shape:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_shape()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_shape;
        if (input->ExpectTag(18)) goto parse_loop_tensor;
        input->UnsafeDecrementRecursionDepth();
        break;
      }

      // repeated .tensorflow.TensorProto tensor = 2;
      case 2: {
        if (tag == 18) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_tensor:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_tensor()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_loop_tensor;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.QueueResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.QueueResponse)
  return false;
#undef DO_
}

void QueueResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.QueueResponse)
  // repeated .tensorflow.TensorShapeProto shape = 1;
  for (unsigned int i = 0, n = this->shape_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->shape(i), output);
  }

  // repeated .tensorflow.TensorProto tensor = 2;
  for (unsigned int i = 0, n = this->tensor_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->tensor(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.QueueResponse)
}

::google::protobuf::uint8* QueueResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.QueueResponse)
  // repeated .tensorflow.TensorShapeProto shape = 1;
  for (unsigned int i = 0, n = this->shape_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, this->shape(i), false, target);
  }

  // repeated .tensorflow.TensorProto tensor = 2;
  for (unsigned int i = 0, n = this->tensor_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, this->tensor(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.QueueResponse)
  return target;
}

int QueueResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.QueueResponse)
  int total_size = 0;

  // repeated .tensorflow.TensorShapeProto shape = 1;
  total_size += 1 * this->shape_size();
  for (int i = 0; i < this->shape_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->shape(i));
  }

  // repeated .tensorflow.TensorProto tensor = 2;
  total_size += 1 * this->tensor_size();
  for (int i = 0; i < this->tensor_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->tensor(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void QueueResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.QueueResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const QueueResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const QueueResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.QueueResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.QueueResponse)
    MergeFrom(*source);
  }
}

void QueueResponse::MergeFrom(const QueueResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.QueueResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  shape_.MergeFrom(from.shape_);
  tensor_.MergeFrom(from.tensor_);
}

void QueueResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.QueueResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void QueueResponse::CopyFrom(const QueueResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.QueueResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool QueueResponse::IsInitialized() const {

  return true;
}

void QueueResponse::Swap(QueueResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void QueueResponse::InternalSwap(QueueResponse* other) {
  shape_.UnsafeArenaSwap(&other->shape_);
  tensor_.UnsafeArenaSwap(&other->tensor_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata QueueResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = QueueResponse_descriptor_;
  metadata.reflection = QueueResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// QueueResponse

// repeated .tensorflow.TensorShapeProto shape = 1;
int QueueResponse::shape_size() const {
  return shape_.size();
}
void QueueResponse::clear_shape() {
  shape_.Clear();
}
const ::tensorflow::TensorShapeProto& QueueResponse::shape(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.QueueResponse.shape)
  return shape_.Get(index);
}
::tensorflow::TensorShapeProto* QueueResponse::mutable_shape(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.QueueResponse.shape)
  return shape_.Mutable(index);
}
::tensorflow::TensorShapeProto* QueueResponse::add_shape() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.QueueResponse.shape)
  return shape_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::TensorShapeProto >*
QueueResponse::mutable_shape() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.QueueResponse.shape)
  return &shape_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::TensorShapeProto >&
QueueResponse::shape() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.QueueResponse.shape)
  return shape_;
}

// repeated .tensorflow.TensorProto tensor = 2;
int QueueResponse::tensor_size() const {
  return tensor_.size();
}
void QueueResponse::clear_tensor() {
  tensor_.Clear();
}
const ::tensorflow::TensorProto& QueueResponse::tensor(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.QueueResponse.tensor)
  return tensor_.Get(index);
}
::tensorflow::TensorProto* QueueResponse::mutable_tensor(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.QueueResponse.tensor)
  return tensor_.Mutable(index);
}
::tensorflow::TensorProto* QueueResponse::add_tensor() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.QueueResponse.tensor)
  return tensor_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::TensorProto >*
QueueResponse::mutable_tensor() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.QueueResponse.tensor)
  return &tensor_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::TensorProto >&
QueueResponse::tensor() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.QueueResponse.tensor)
  return tensor_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CreateContextRequest::kServerDefFieldNumber;
const int CreateContextRequest::kAsyncFieldNumber;
const int CreateContextRequest::kKeepAliveSecsFieldNumber;
const int CreateContextRequest::kVersionDefFieldNumber;
const int CreateContextRequest::kClusterDeviceAttributesFieldNumber;
const int CreateContextRequest::kContextIdFieldNumber;
const int CreateContextRequest::kContextViewIdFieldNumber;
const int CreateContextRequest::kLazyCopyRemoteFunctionInputsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CreateContextRequest::CreateContextRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.CreateContextRequest)
}

void CreateContextRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  server_def_ = const_cast< ::tensorflow::ServerDef*>(&::tensorflow::ServerDef::default_instance());
  version_def_ = const_cast< ::tensorflow::VersionDef*>(&::tensorflow::VersionDef::default_instance());
}

CreateContextRequest::CreateContextRequest(const CreateContextRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.CreateContextRequest)
}

void CreateContextRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  server_def_ = NULL;
  async_ = false;
  keep_alive_secs_ = GOOGLE_LONGLONG(0);
  version_def_ = NULL;
  context_id_ = GOOGLE_ULONGLONG(0);
  context_view_id_ = GOOGLE_ULONGLONG(0);
  lazy_copy_remote_function_inputs_ = false;
}

CreateContextRequest::~CreateContextRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.CreateContextRequest)
  SharedDtor();
}

void CreateContextRequest::SharedDtor() {
  if (this != default_instance_) {
    delete server_def_;
    delete version_def_;
  }
}

void CreateContextRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CreateContextRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CreateContextRequest_descriptor_;
}

const CreateContextRequest& CreateContextRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

CreateContextRequest* CreateContextRequest::default_instance_ = NULL;

CreateContextRequest* CreateContextRequest::New(::google::protobuf::Arena* arena) const {
  CreateContextRequest* n = new CreateContextRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CreateContextRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.CreateContextRequest)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(CreateContextRequest, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<CreateContextRequest*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(context_id_, lazy_copy_remote_function_inputs_);
  if (GetArenaNoVirtual() == NULL && server_def_ != NULL) delete server_def_;
  server_def_ = NULL;
  keep_alive_secs_ = GOOGLE_LONGLONG(0);
  if (GetArenaNoVirtual() == NULL && version_def_ != NULL) delete version_def_;
  version_def_ = NULL;

#undef ZR_HELPER_
#undef ZR_

  cluster_device_attributes_.Clear();
}

bool CreateContextRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.CreateContextRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.ServerDef server_def = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_server_def()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_async;
        break;
      }

      // optional bool async = 2;
      case 2: {
        if (tag == 16) {
         parse_async:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &async_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_keep_alive_secs;
        break;
      }

      // optional int64 keep_alive_secs = 3;
      case 3: {
        if (tag == 24) {
         parse_keep_alive_secs:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &keep_alive_secs_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_version_def;
        break;
      }

      // optional .tensorflow.VersionDef version_def = 4;
      case 4: {
        if (tag == 34) {
         parse_version_def:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_version_def()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(50)) goto parse_cluster_device_attributes;
        break;
      }

      // repeated .tensorflow.DeviceAttributes cluster_device_attributes = 6;
      case 6: {
        if (tag == 50) {
         parse_cluster_device_attributes:
          DO_(input->IncrementRecursionDepth());
         parse_loop_cluster_device_attributes:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_cluster_device_attributes()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(50)) goto parse_loop_cluster_device_attributes;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(57)) goto parse_context_id;
        break;
      }

      // optional fixed64 context_id = 7;
      case 7: {
        if (tag == 57) {
         parse_context_id:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_FIXED64>(
                 input, &context_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(65)) goto parse_context_view_id;
        break;
      }

      // optional fixed64 context_view_id = 8;
      case 8: {
        if (tag == 65) {
         parse_context_view_id:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_FIXED64>(
                 input, &context_view_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(72)) goto parse_lazy_copy_remote_function_inputs;
        break;
      }

      // optional bool lazy_copy_remote_function_inputs = 9;
      case 9: {
        if (tag == 72) {
         parse_lazy_copy_remote_function_inputs:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &lazy_copy_remote_function_inputs_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.CreateContextRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.CreateContextRequest)
  return false;
#undef DO_
}

void CreateContextRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.CreateContextRequest)
  // optional .tensorflow.ServerDef server_def = 1;
  if (this->has_server_def()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->server_def_, output);
  }

  // optional bool async = 2;
  if (this->async() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->async(), output);
  }

  // optional int64 keep_alive_secs = 3;
  if (this->keep_alive_secs() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(3, this->keep_alive_secs(), output);
  }

  // optional .tensorflow.VersionDef version_def = 4;
  if (this->has_version_def()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, *this->version_def_, output);
  }

  // repeated .tensorflow.DeviceAttributes cluster_device_attributes = 6;
  for (unsigned int i = 0, n = this->cluster_device_attributes_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      6, this->cluster_device_attributes(i), output);
  }

  // optional fixed64 context_id = 7;
  if (this->context_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFixed64(7, this->context_id(), output);
  }

  // optional fixed64 context_view_id = 8;
  if (this->context_view_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFixed64(8, this->context_view_id(), output);
  }

  // optional bool lazy_copy_remote_function_inputs = 9;
  if (this->lazy_copy_remote_function_inputs() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(9, this->lazy_copy_remote_function_inputs(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.CreateContextRequest)
}

::google::protobuf::uint8* CreateContextRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.CreateContextRequest)
  // optional .tensorflow.ServerDef server_def = 1;
  if (this->has_server_def()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->server_def_, false, target);
  }

  // optional bool async = 2;
  if (this->async() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->async(), target);
  }

  // optional int64 keep_alive_secs = 3;
  if (this->keep_alive_secs() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(3, this->keep_alive_secs(), target);
  }

  // optional .tensorflow.VersionDef version_def = 4;
  if (this->has_version_def()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        4, *this->version_def_, false, target);
  }

  // repeated .tensorflow.DeviceAttributes cluster_device_attributes = 6;
  for (unsigned int i = 0, n = this->cluster_device_attributes_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        6, this->cluster_device_attributes(i), false, target);
  }

  // optional fixed64 context_id = 7;
  if (this->context_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFixed64ToArray(7, this->context_id(), target);
  }

  // optional fixed64 context_view_id = 8;
  if (this->context_view_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFixed64ToArray(8, this->context_view_id(), target);
  }

  // optional bool lazy_copy_remote_function_inputs = 9;
  if (this->lazy_copy_remote_function_inputs() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(9, this->lazy_copy_remote_function_inputs(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.CreateContextRequest)
  return target;
}

int CreateContextRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.CreateContextRequest)
  int total_size = 0;

  // optional .tensorflow.ServerDef server_def = 1;
  if (this->has_server_def()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->server_def_);
  }

  // optional bool async = 2;
  if (this->async() != 0) {
    total_size += 1 + 1;
  }

  // optional int64 keep_alive_secs = 3;
  if (this->keep_alive_secs() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->keep_alive_secs());
  }

  // optional .tensorflow.VersionDef version_def = 4;
  if (this->has_version_def()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->version_def_);
  }

  // optional fixed64 context_id = 7;
  if (this->context_id() != 0) {
    total_size += 1 + 8;
  }

  // optional fixed64 context_view_id = 8;
  if (this->context_view_id() != 0) {
    total_size += 1 + 8;
  }

  // optional bool lazy_copy_remote_function_inputs = 9;
  if (this->lazy_copy_remote_function_inputs() != 0) {
    total_size += 1 + 1;
  }

  // repeated .tensorflow.DeviceAttributes cluster_device_attributes = 6;
  total_size += 1 * this->cluster_device_attributes_size();
  for (int i = 0; i < this->cluster_device_attributes_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->cluster_device_attributes(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CreateContextRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.CreateContextRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const CreateContextRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CreateContextRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.CreateContextRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.CreateContextRequest)
    MergeFrom(*source);
  }
}

void CreateContextRequest::MergeFrom(const CreateContextRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.CreateContextRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  cluster_device_attributes_.MergeFrom(from.cluster_device_attributes_);
  if (from.has_server_def()) {
    mutable_server_def()->::tensorflow::ServerDef::MergeFrom(from.server_def());
  }
  if (from.async() != 0) {
    set_async(from.async());
  }
  if (from.keep_alive_secs() != 0) {
    set_keep_alive_secs(from.keep_alive_secs());
  }
  if (from.has_version_def()) {
    mutable_version_def()->::tensorflow::VersionDef::MergeFrom(from.version_def());
  }
  if (from.context_id() != 0) {
    set_context_id(from.context_id());
  }
  if (from.context_view_id() != 0) {
    set_context_view_id(from.context_view_id());
  }
  if (from.lazy_copy_remote_function_inputs() != 0) {
    set_lazy_copy_remote_function_inputs(from.lazy_copy_remote_function_inputs());
  }
}

void CreateContextRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.CreateContextRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CreateContextRequest::CopyFrom(const CreateContextRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.CreateContextRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CreateContextRequest::IsInitialized() const {

  return true;
}

void CreateContextRequest::Swap(CreateContextRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CreateContextRequest::InternalSwap(CreateContextRequest* other) {
  std::swap(server_def_, other->server_def_);
  std::swap(async_, other->async_);
  std::swap(keep_alive_secs_, other->keep_alive_secs_);
  std::swap(version_def_, other->version_def_);
  cluster_device_attributes_.UnsafeArenaSwap(&other->cluster_device_attributes_);
  std::swap(context_id_, other->context_id_);
  std::swap(context_view_id_, other->context_view_id_);
  std::swap(lazy_copy_remote_function_inputs_, other->lazy_copy_remote_function_inputs_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CreateContextRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CreateContextRequest_descriptor_;
  metadata.reflection = CreateContextRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CreateContextRequest

// optional .tensorflow.ServerDef server_def = 1;
bool CreateContextRequest::has_server_def() const {
  return !_is_default_instance_ && server_def_ != NULL;
}
void CreateContextRequest::clear_server_def() {
  if (GetArenaNoVirtual() == NULL && server_def_ != NULL) delete server_def_;
  server_def_ = NULL;
}
const ::tensorflow::ServerDef& CreateContextRequest::server_def() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CreateContextRequest.server_def)
  return server_def_ != NULL ? *server_def_ : *default_instance_->server_def_;
}
::tensorflow::ServerDef* CreateContextRequest::mutable_server_def() {
  
  if (server_def_ == NULL) {
    server_def_ = new ::tensorflow::ServerDef;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.CreateContextRequest.server_def)
  return server_def_;
}
::tensorflow::ServerDef* CreateContextRequest::release_server_def() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.CreateContextRequest.server_def)
  
  ::tensorflow::ServerDef* temp = server_def_;
  server_def_ = NULL;
  return temp;
}
void CreateContextRequest::set_allocated_server_def(::tensorflow::ServerDef* server_def) {
  delete server_def_;
  if (server_def != NULL && server_def->GetArena() != NULL) {
    ::tensorflow::ServerDef* new_server_def = new ::tensorflow::ServerDef;
    new_server_def->CopyFrom(*server_def);
    server_def = new_server_def;
  }
  server_def_ = server_def;
  if (server_def) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.CreateContextRequest.server_def)
}

// optional bool async = 2;
void CreateContextRequest::clear_async() {
  async_ = false;
}
 bool CreateContextRequest::async() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CreateContextRequest.async)
  return async_;
}
 void CreateContextRequest::set_async(bool value) {
  
  async_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.CreateContextRequest.async)
}

// optional int64 keep_alive_secs = 3;
void CreateContextRequest::clear_keep_alive_secs() {
  keep_alive_secs_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 CreateContextRequest::keep_alive_secs() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CreateContextRequest.keep_alive_secs)
  return keep_alive_secs_;
}
 void CreateContextRequest::set_keep_alive_secs(::google::protobuf::int64 value) {
  
  keep_alive_secs_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.CreateContextRequest.keep_alive_secs)
}

// optional .tensorflow.VersionDef version_def = 4;
bool CreateContextRequest::has_version_def() const {
  return !_is_default_instance_ && version_def_ != NULL;
}
void CreateContextRequest::clear_version_def() {
  if (GetArenaNoVirtual() == NULL && version_def_ != NULL) delete version_def_;
  version_def_ = NULL;
}
const ::tensorflow::VersionDef& CreateContextRequest::version_def() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CreateContextRequest.version_def)
  return version_def_ != NULL ? *version_def_ : *default_instance_->version_def_;
}
::tensorflow::VersionDef* CreateContextRequest::mutable_version_def() {
  
  if (version_def_ == NULL) {
    version_def_ = new ::tensorflow::VersionDef;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.CreateContextRequest.version_def)
  return version_def_;
}
::tensorflow::VersionDef* CreateContextRequest::release_version_def() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.CreateContextRequest.version_def)
  
  ::tensorflow::VersionDef* temp = version_def_;
  version_def_ = NULL;
  return temp;
}
void CreateContextRequest::set_allocated_version_def(::tensorflow::VersionDef* version_def) {
  delete version_def_;
  if (version_def != NULL && version_def->GetArena() != NULL) {
    ::tensorflow::VersionDef* new_version_def = new ::tensorflow::VersionDef;
    new_version_def->CopyFrom(*version_def);
    version_def = new_version_def;
  }
  version_def_ = version_def;
  if (version_def) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.CreateContextRequest.version_def)
}

// repeated .tensorflow.DeviceAttributes cluster_device_attributes = 6;
int CreateContextRequest::cluster_device_attributes_size() const {
  return cluster_device_attributes_.size();
}
void CreateContextRequest::clear_cluster_device_attributes() {
  cluster_device_attributes_.Clear();
}
const ::tensorflow::DeviceAttributes& CreateContextRequest::cluster_device_attributes(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CreateContextRequest.cluster_device_attributes)
  return cluster_device_attributes_.Get(index);
}
::tensorflow::DeviceAttributes* CreateContextRequest::mutable_cluster_device_attributes(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.CreateContextRequest.cluster_device_attributes)
  return cluster_device_attributes_.Mutable(index);
}
::tensorflow::DeviceAttributes* CreateContextRequest::add_cluster_device_attributes() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.CreateContextRequest.cluster_device_attributes)
  return cluster_device_attributes_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >*
CreateContextRequest::mutable_cluster_device_attributes() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.CreateContextRequest.cluster_device_attributes)
  return &cluster_device_attributes_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >&
CreateContextRequest::cluster_device_attributes() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.CreateContextRequest.cluster_device_attributes)
  return cluster_device_attributes_;
}

// optional fixed64 context_id = 7;
void CreateContextRequest::clear_context_id() {
  context_id_ = GOOGLE_ULONGLONG(0);
}
 ::google::protobuf::uint64 CreateContextRequest::context_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CreateContextRequest.context_id)
  return context_id_;
}
 void CreateContextRequest::set_context_id(::google::protobuf::uint64 value) {
  
  context_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.CreateContextRequest.context_id)
}

// optional fixed64 context_view_id = 8;
void CreateContextRequest::clear_context_view_id() {
  context_view_id_ = GOOGLE_ULONGLONG(0);
}
 ::google::protobuf::uint64 CreateContextRequest::context_view_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CreateContextRequest.context_view_id)
  return context_view_id_;
}
 void CreateContextRequest::set_context_view_id(::google::protobuf::uint64 value) {
  
  context_view_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.CreateContextRequest.context_view_id)
}

// optional bool lazy_copy_remote_function_inputs = 9;
void CreateContextRequest::clear_lazy_copy_remote_function_inputs() {
  lazy_copy_remote_function_inputs_ = false;
}
 bool CreateContextRequest::lazy_copy_remote_function_inputs() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CreateContextRequest.lazy_copy_remote_function_inputs)
  return lazy_copy_remote_function_inputs_;
}
 void CreateContextRequest::set_lazy_copy_remote_function_inputs(bool value) {
  
  lazy_copy_remote_function_inputs_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.CreateContextRequest.lazy_copy_remote_function_inputs)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CreateContextResponse::kDeviceAttributesFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CreateContextResponse::CreateContextResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.CreateContextResponse)
}

void CreateContextResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

CreateContextResponse::CreateContextResponse(const CreateContextResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.CreateContextResponse)
}

void CreateContextResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

CreateContextResponse::~CreateContextResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.CreateContextResponse)
  SharedDtor();
}

void CreateContextResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void CreateContextResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CreateContextResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CreateContextResponse_descriptor_;
}

const CreateContextResponse& CreateContextResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

CreateContextResponse* CreateContextResponse::default_instance_ = NULL;

CreateContextResponse* CreateContextResponse::New(::google::protobuf::Arena* arena) const {
  CreateContextResponse* n = new CreateContextResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CreateContextResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.CreateContextResponse)
  device_attributes_.Clear();
}

bool CreateContextResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.CreateContextResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.DeviceAttributes device_attributes = 2;
      case 2: {
        if (tag == 18) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_device_attributes:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_device_attributes()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_loop_device_attributes;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.CreateContextResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.CreateContextResponse)
  return false;
#undef DO_
}

void CreateContextResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.CreateContextResponse)
  // repeated .tensorflow.DeviceAttributes device_attributes = 2;
  for (unsigned int i = 0, n = this->device_attributes_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->device_attributes(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.CreateContextResponse)
}

::google::protobuf::uint8* CreateContextResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.CreateContextResponse)
  // repeated .tensorflow.DeviceAttributes device_attributes = 2;
  for (unsigned int i = 0, n = this->device_attributes_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, this->device_attributes(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.CreateContextResponse)
  return target;
}

int CreateContextResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.CreateContextResponse)
  int total_size = 0;

  // repeated .tensorflow.DeviceAttributes device_attributes = 2;
  total_size += 1 * this->device_attributes_size();
  for (int i = 0; i < this->device_attributes_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->device_attributes(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CreateContextResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.CreateContextResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const CreateContextResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CreateContextResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.CreateContextResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.CreateContextResponse)
    MergeFrom(*source);
  }
}

void CreateContextResponse::MergeFrom(const CreateContextResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.CreateContextResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  device_attributes_.MergeFrom(from.device_attributes_);
}

void CreateContextResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.CreateContextResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CreateContextResponse::CopyFrom(const CreateContextResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.CreateContextResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CreateContextResponse::IsInitialized() const {

  return true;
}

void CreateContextResponse::Swap(CreateContextResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CreateContextResponse::InternalSwap(CreateContextResponse* other) {
  device_attributes_.UnsafeArenaSwap(&other->device_attributes_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CreateContextResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CreateContextResponse_descriptor_;
  metadata.reflection = CreateContextResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CreateContextResponse

// repeated .tensorflow.DeviceAttributes device_attributes = 2;
int CreateContextResponse::device_attributes_size() const {
  return device_attributes_.size();
}
void CreateContextResponse::clear_device_attributes() {
  device_attributes_.Clear();
}
const ::tensorflow::DeviceAttributes& CreateContextResponse::device_attributes(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CreateContextResponse.device_attributes)
  return device_attributes_.Get(index);
}
::tensorflow::DeviceAttributes* CreateContextResponse::mutable_device_attributes(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.CreateContextResponse.device_attributes)
  return device_attributes_.Mutable(index);
}
::tensorflow::DeviceAttributes* CreateContextResponse::add_device_attributes() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.CreateContextResponse.device_attributes)
  return device_attributes_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >*
CreateContextResponse::mutable_device_attributes() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.CreateContextResponse.device_attributes)
  return &device_attributes_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >&
CreateContextResponse::device_attributes() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.CreateContextResponse.device_attributes)
  return device_attributes_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int UpdateContextRequest::kServerDefFieldNumber;
const int UpdateContextRequest::kClusterDeviceAttributesFieldNumber;
const int UpdateContextRequest::kContextIdFieldNumber;
const int UpdateContextRequest::kContextViewIdFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

UpdateContextRequest::UpdateContextRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.UpdateContextRequest)
}

void UpdateContextRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  server_def_ = const_cast< ::tensorflow::ServerDef*>(&::tensorflow::ServerDef::default_instance());
}

UpdateContextRequest::UpdateContextRequest(const UpdateContextRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.UpdateContextRequest)
}

void UpdateContextRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  server_def_ = NULL;
  context_id_ = GOOGLE_ULONGLONG(0);
  context_view_id_ = GOOGLE_ULONGLONG(0);
}

UpdateContextRequest::~UpdateContextRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.UpdateContextRequest)
  SharedDtor();
}

void UpdateContextRequest::SharedDtor() {
  if (this != default_instance_) {
    delete server_def_;
  }
}

void UpdateContextRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* UpdateContextRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return UpdateContextRequest_descriptor_;
}

const UpdateContextRequest& UpdateContextRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

UpdateContextRequest* UpdateContextRequest::default_instance_ = NULL;

UpdateContextRequest* UpdateContextRequest::New(::google::protobuf::Arena* arena) const {
  UpdateContextRequest* n = new UpdateContextRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void UpdateContextRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.UpdateContextRequest)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(UpdateContextRequest, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<UpdateContextRequest*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(context_id_, context_view_id_);
  if (GetArenaNoVirtual() == NULL && server_def_ != NULL) delete server_def_;
  server_def_ = NULL;

#undef ZR_HELPER_
#undef ZR_

  cluster_device_attributes_.Clear();
}

bool UpdateContextRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.UpdateContextRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.ServerDef server_def = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_server_def()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_cluster_device_attributes;
        break;
      }

      // repeated .tensorflow.DeviceAttributes cluster_device_attributes = 2;
      case 2: {
        if (tag == 18) {
         parse_cluster_device_attributes:
          DO_(input->IncrementRecursionDepth());
         parse_loop_cluster_device_attributes:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_cluster_device_attributes()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_loop_cluster_device_attributes;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(25)) goto parse_context_id;
        break;
      }

      // optional fixed64 context_id = 3;
      case 3: {
        if (tag == 25) {
         parse_context_id:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_FIXED64>(
                 input, &context_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(33)) goto parse_context_view_id;
        break;
      }

      // optional fixed64 context_view_id = 4;
      case 4: {
        if (tag == 33) {
         parse_context_view_id:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_FIXED64>(
                 input, &context_view_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.UpdateContextRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.UpdateContextRequest)
  return false;
#undef DO_
}

void UpdateContextRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.UpdateContextRequest)
  // optional .tensorflow.ServerDef server_def = 1;
  if (this->has_server_def()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->server_def_, output);
  }

  // repeated .tensorflow.DeviceAttributes cluster_device_attributes = 2;
  for (unsigned int i = 0, n = this->cluster_device_attributes_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->cluster_device_attributes(i), output);
  }

  // optional fixed64 context_id = 3;
  if (this->context_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFixed64(3, this->context_id(), output);
  }

  // optional fixed64 context_view_id = 4;
  if (this->context_view_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFixed64(4, this->context_view_id(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.UpdateContextRequest)
}

::google::protobuf::uint8* UpdateContextRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.UpdateContextRequest)
  // optional .tensorflow.ServerDef server_def = 1;
  if (this->has_server_def()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->server_def_, false, target);
  }

  // repeated .tensorflow.DeviceAttributes cluster_device_attributes = 2;
  for (unsigned int i = 0, n = this->cluster_device_attributes_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, this->cluster_device_attributes(i), false, target);
  }

  // optional fixed64 context_id = 3;
  if (this->context_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFixed64ToArray(3, this->context_id(), target);
  }

  // optional fixed64 context_view_id = 4;
  if (this->context_view_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFixed64ToArray(4, this->context_view_id(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.UpdateContextRequest)
  return target;
}

int UpdateContextRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.UpdateContextRequest)
  int total_size = 0;

  // optional .tensorflow.ServerDef server_def = 1;
  if (this->has_server_def()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->server_def_);
  }

  // optional fixed64 context_id = 3;
  if (this->context_id() != 0) {
    total_size += 1 + 8;
  }

  // optional fixed64 context_view_id = 4;
  if (this->context_view_id() != 0) {
    total_size += 1 + 8;
  }

  // repeated .tensorflow.DeviceAttributes cluster_device_attributes = 2;
  total_size += 1 * this->cluster_device_attributes_size();
  for (int i = 0; i < this->cluster_device_attributes_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->cluster_device_attributes(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void UpdateContextRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.UpdateContextRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const UpdateContextRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const UpdateContextRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.UpdateContextRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.UpdateContextRequest)
    MergeFrom(*source);
  }
}

void UpdateContextRequest::MergeFrom(const UpdateContextRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.UpdateContextRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  cluster_device_attributes_.MergeFrom(from.cluster_device_attributes_);
  if (from.has_server_def()) {
    mutable_server_def()->::tensorflow::ServerDef::MergeFrom(from.server_def());
  }
  if (from.context_id() != 0) {
    set_context_id(from.context_id());
  }
  if (from.context_view_id() != 0) {
    set_context_view_id(from.context_view_id());
  }
}

void UpdateContextRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.UpdateContextRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void UpdateContextRequest::CopyFrom(const UpdateContextRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.UpdateContextRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool UpdateContextRequest::IsInitialized() const {

  return true;
}

void UpdateContextRequest::Swap(UpdateContextRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void UpdateContextRequest::InternalSwap(UpdateContextRequest* other) {
  std::swap(server_def_, other->server_def_);
  cluster_device_attributes_.UnsafeArenaSwap(&other->cluster_device_attributes_);
  std::swap(context_id_, other->context_id_);
  std::swap(context_view_id_, other->context_view_id_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata UpdateContextRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = UpdateContextRequest_descriptor_;
  metadata.reflection = UpdateContextRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// UpdateContextRequest

// optional .tensorflow.ServerDef server_def = 1;
bool UpdateContextRequest::has_server_def() const {
  return !_is_default_instance_ && server_def_ != NULL;
}
void UpdateContextRequest::clear_server_def() {
  if (GetArenaNoVirtual() == NULL && server_def_ != NULL) delete server_def_;
  server_def_ = NULL;
}
const ::tensorflow::ServerDef& UpdateContextRequest::server_def() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.UpdateContextRequest.server_def)
  return server_def_ != NULL ? *server_def_ : *default_instance_->server_def_;
}
::tensorflow::ServerDef* UpdateContextRequest::mutable_server_def() {
  
  if (server_def_ == NULL) {
    server_def_ = new ::tensorflow::ServerDef;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.UpdateContextRequest.server_def)
  return server_def_;
}
::tensorflow::ServerDef* UpdateContextRequest::release_server_def() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.UpdateContextRequest.server_def)
  
  ::tensorflow::ServerDef* temp = server_def_;
  server_def_ = NULL;
  return temp;
}
void UpdateContextRequest::set_allocated_server_def(::tensorflow::ServerDef* server_def) {
  delete server_def_;
  if (server_def != NULL && server_def->GetArena() != NULL) {
    ::tensorflow::ServerDef* new_server_def = new ::tensorflow::ServerDef;
    new_server_def->CopyFrom(*server_def);
    server_def = new_server_def;
  }
  server_def_ = server_def;
  if (server_def) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.UpdateContextRequest.server_def)
}

// repeated .tensorflow.DeviceAttributes cluster_device_attributes = 2;
int UpdateContextRequest::cluster_device_attributes_size() const {
  return cluster_device_attributes_.size();
}
void UpdateContextRequest::clear_cluster_device_attributes() {
  cluster_device_attributes_.Clear();
}
const ::tensorflow::DeviceAttributes& UpdateContextRequest::cluster_device_attributes(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.UpdateContextRequest.cluster_device_attributes)
  return cluster_device_attributes_.Get(index);
}
::tensorflow::DeviceAttributes* UpdateContextRequest::mutable_cluster_device_attributes(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.UpdateContextRequest.cluster_device_attributes)
  return cluster_device_attributes_.Mutable(index);
}
::tensorflow::DeviceAttributes* UpdateContextRequest::add_cluster_device_attributes() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.UpdateContextRequest.cluster_device_attributes)
  return cluster_device_attributes_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >*
UpdateContextRequest::mutable_cluster_device_attributes() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.UpdateContextRequest.cluster_device_attributes)
  return &cluster_device_attributes_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >&
UpdateContextRequest::cluster_device_attributes() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.UpdateContextRequest.cluster_device_attributes)
  return cluster_device_attributes_;
}

// optional fixed64 context_id = 3;
void UpdateContextRequest::clear_context_id() {
  context_id_ = GOOGLE_ULONGLONG(0);
}
 ::google::protobuf::uint64 UpdateContextRequest::context_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.UpdateContextRequest.context_id)
  return context_id_;
}
 void UpdateContextRequest::set_context_id(::google::protobuf::uint64 value) {
  
  context_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.UpdateContextRequest.context_id)
}

// optional fixed64 context_view_id = 4;
void UpdateContextRequest::clear_context_view_id() {
  context_view_id_ = GOOGLE_ULONGLONG(0);
}
 ::google::protobuf::uint64 UpdateContextRequest::context_view_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.UpdateContextRequest.context_view_id)
  return context_view_id_;
}
 void UpdateContextRequest::set_context_view_id(::google::protobuf::uint64 value) {
  
  context_view_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.UpdateContextRequest.context_view_id)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int UpdateContextResponse::kDeviceAttributesFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

UpdateContextResponse::UpdateContextResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.UpdateContextResponse)
}

void UpdateContextResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

UpdateContextResponse::UpdateContextResponse(const UpdateContextResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.UpdateContextResponse)
}

void UpdateContextResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

UpdateContextResponse::~UpdateContextResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.UpdateContextResponse)
  SharedDtor();
}

void UpdateContextResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void UpdateContextResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* UpdateContextResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return UpdateContextResponse_descriptor_;
}

const UpdateContextResponse& UpdateContextResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

UpdateContextResponse* UpdateContextResponse::default_instance_ = NULL;

UpdateContextResponse* UpdateContextResponse::New(::google::protobuf::Arena* arena) const {
  UpdateContextResponse* n = new UpdateContextResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void UpdateContextResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.UpdateContextResponse)
  device_attributes_.Clear();
}

bool UpdateContextResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.UpdateContextResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.DeviceAttributes device_attributes = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_device_attributes:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_device_attributes()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_device_attributes;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.UpdateContextResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.UpdateContextResponse)
  return false;
#undef DO_
}

void UpdateContextResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.UpdateContextResponse)
  // repeated .tensorflow.DeviceAttributes device_attributes = 1;
  for (unsigned int i = 0, n = this->device_attributes_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->device_attributes(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.UpdateContextResponse)
}

::google::protobuf::uint8* UpdateContextResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.UpdateContextResponse)
  // repeated .tensorflow.DeviceAttributes device_attributes = 1;
  for (unsigned int i = 0, n = this->device_attributes_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, this->device_attributes(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.UpdateContextResponse)
  return target;
}

int UpdateContextResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.UpdateContextResponse)
  int total_size = 0;

  // repeated .tensorflow.DeviceAttributes device_attributes = 1;
  total_size += 1 * this->device_attributes_size();
  for (int i = 0; i < this->device_attributes_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->device_attributes(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void UpdateContextResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.UpdateContextResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const UpdateContextResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const UpdateContextResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.UpdateContextResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.UpdateContextResponse)
    MergeFrom(*source);
  }
}

void UpdateContextResponse::MergeFrom(const UpdateContextResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.UpdateContextResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  device_attributes_.MergeFrom(from.device_attributes_);
}

void UpdateContextResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.UpdateContextResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void UpdateContextResponse::CopyFrom(const UpdateContextResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.UpdateContextResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool UpdateContextResponse::IsInitialized() const {

  return true;
}

void UpdateContextResponse::Swap(UpdateContextResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void UpdateContextResponse::InternalSwap(UpdateContextResponse* other) {
  device_attributes_.UnsafeArenaSwap(&other->device_attributes_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata UpdateContextResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = UpdateContextResponse_descriptor_;
  metadata.reflection = UpdateContextResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// UpdateContextResponse

// repeated .tensorflow.DeviceAttributes device_attributes = 1;
int UpdateContextResponse::device_attributes_size() const {
  return device_attributes_.size();
}
void UpdateContextResponse::clear_device_attributes() {
  device_attributes_.Clear();
}
const ::tensorflow::DeviceAttributes& UpdateContextResponse::device_attributes(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.UpdateContextResponse.device_attributes)
  return device_attributes_.Get(index);
}
::tensorflow::DeviceAttributes* UpdateContextResponse::mutable_device_attributes(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.UpdateContextResponse.device_attributes)
  return device_attributes_.Mutable(index);
}
::tensorflow::DeviceAttributes* UpdateContextResponse::add_device_attributes() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.UpdateContextResponse.device_attributes)
  return device_attributes_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >*
UpdateContextResponse::mutable_device_attributes() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.UpdateContextResponse.device_attributes)
  return &device_attributes_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >&
UpdateContextResponse::device_attributes() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.UpdateContextResponse.device_attributes)
  return device_attributes_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int EnqueueRequest::kContextIdFieldNumber;
const int EnqueueRequest::kQueueFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

EnqueueRequest::EnqueueRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.EnqueueRequest)
}

void EnqueueRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

EnqueueRequest::EnqueueRequest(const EnqueueRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.EnqueueRequest)
}

void EnqueueRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  context_id_ = GOOGLE_ULONGLONG(0);
}

EnqueueRequest::~EnqueueRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.EnqueueRequest)
  SharedDtor();
}

void EnqueueRequest::SharedDtor() {
  if (this != default_instance_) {
  }
}

void EnqueueRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* EnqueueRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return EnqueueRequest_descriptor_;
}

const EnqueueRequest& EnqueueRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

EnqueueRequest* EnqueueRequest::default_instance_ = NULL;

EnqueueRequest* EnqueueRequest::New(::google::protobuf::Arena* arena) const {
  EnqueueRequest* n = new EnqueueRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void EnqueueRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.EnqueueRequest)
  context_id_ = GOOGLE_ULONGLONG(0);
  queue_.Clear();
}

bool EnqueueRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.EnqueueRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional fixed64 context_id = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_FIXED64>(
                 input, &context_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_queue;
        break;
      }

      // repeated .tensorflow.eager.QueueItem queue = 3;
      case 3: {
        if (tag == 26) {
         parse_queue:
          DO_(input->IncrementRecursionDepth());
         parse_loop_queue:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_queue()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_loop_queue;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.EnqueueRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.EnqueueRequest)
  return false;
#undef DO_
}

void EnqueueRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.EnqueueRequest)
  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFixed64(1, this->context_id(), output);
  }

  // repeated .tensorflow.eager.QueueItem queue = 3;
  for (unsigned int i = 0, n = this->queue_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, this->queue(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.EnqueueRequest)
}

::google::protobuf::uint8* EnqueueRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.EnqueueRequest)
  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFixed64ToArray(1, this->context_id(), target);
  }

  // repeated .tensorflow.eager.QueueItem queue = 3;
  for (unsigned int i = 0, n = this->queue_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        3, this->queue(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.EnqueueRequest)
  return target;
}

int EnqueueRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.EnqueueRequest)
  int total_size = 0;

  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    total_size += 1 + 8;
  }

  // repeated .tensorflow.eager.QueueItem queue = 3;
  total_size += 1 * this->queue_size();
  for (int i = 0; i < this->queue_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->queue(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void EnqueueRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.EnqueueRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const EnqueueRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const EnqueueRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.EnqueueRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.EnqueueRequest)
    MergeFrom(*source);
  }
}

void EnqueueRequest::MergeFrom(const EnqueueRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.EnqueueRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  queue_.MergeFrom(from.queue_);
  if (from.context_id() != 0) {
    set_context_id(from.context_id());
  }
}

void EnqueueRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.EnqueueRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void EnqueueRequest::CopyFrom(const EnqueueRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.EnqueueRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool EnqueueRequest::IsInitialized() const {

  return true;
}

void EnqueueRequest::Swap(EnqueueRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void EnqueueRequest::InternalSwap(EnqueueRequest* other) {
  std::swap(context_id_, other->context_id_);
  queue_.UnsafeArenaSwap(&other->queue_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata EnqueueRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = EnqueueRequest_descriptor_;
  metadata.reflection = EnqueueRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// EnqueueRequest

// optional fixed64 context_id = 1;
void EnqueueRequest::clear_context_id() {
  context_id_ = GOOGLE_ULONGLONG(0);
}
 ::google::protobuf::uint64 EnqueueRequest::context_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.EnqueueRequest.context_id)
  return context_id_;
}
 void EnqueueRequest::set_context_id(::google::protobuf::uint64 value) {
  
  context_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.EnqueueRequest.context_id)
}

// repeated .tensorflow.eager.QueueItem queue = 3;
int EnqueueRequest::queue_size() const {
  return queue_.size();
}
void EnqueueRequest::clear_queue() {
  queue_.Clear();
}
const ::tensorflow::eager::QueueItem& EnqueueRequest::queue(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.EnqueueRequest.queue)
  return queue_.Get(index);
}
::tensorflow::eager::QueueItem* EnqueueRequest::mutable_queue(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.EnqueueRequest.queue)
  return queue_.Mutable(index);
}
::tensorflow::eager::QueueItem* EnqueueRequest::add_queue() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.EnqueueRequest.queue)
  return queue_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::eager::QueueItem >*
EnqueueRequest::mutable_queue() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.EnqueueRequest.queue)
  return &queue_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::eager::QueueItem >&
EnqueueRequest::queue() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.EnqueueRequest.queue)
  return queue_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int EnqueueResponse::kQueueResponseFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

EnqueueResponse::EnqueueResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.EnqueueResponse)
}

void EnqueueResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

EnqueueResponse::EnqueueResponse(const EnqueueResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.EnqueueResponse)
}

void EnqueueResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

EnqueueResponse::~EnqueueResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.EnqueueResponse)
  SharedDtor();
}

void EnqueueResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void EnqueueResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* EnqueueResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return EnqueueResponse_descriptor_;
}

const EnqueueResponse& EnqueueResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

EnqueueResponse* EnqueueResponse::default_instance_ = NULL;

EnqueueResponse* EnqueueResponse::New(::google::protobuf::Arena* arena) const {
  EnqueueResponse* n = new EnqueueResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void EnqueueResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.EnqueueResponse)
  queue_response_.Clear();
}

bool EnqueueResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.EnqueueResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.eager.QueueResponse queue_response = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_queue_response:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_queue_response()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_queue_response;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.EnqueueResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.EnqueueResponse)
  return false;
#undef DO_
}

void EnqueueResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.EnqueueResponse)
  // repeated .tensorflow.eager.QueueResponse queue_response = 1;
  for (unsigned int i = 0, n = this->queue_response_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->queue_response(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.EnqueueResponse)
}

::google::protobuf::uint8* EnqueueResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.EnqueueResponse)
  // repeated .tensorflow.eager.QueueResponse queue_response = 1;
  for (unsigned int i = 0, n = this->queue_response_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, this->queue_response(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.EnqueueResponse)
  return target;
}

int EnqueueResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.EnqueueResponse)
  int total_size = 0;

  // repeated .tensorflow.eager.QueueResponse queue_response = 1;
  total_size += 1 * this->queue_response_size();
  for (int i = 0; i < this->queue_response_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->queue_response(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void EnqueueResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.EnqueueResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const EnqueueResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const EnqueueResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.EnqueueResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.EnqueueResponse)
    MergeFrom(*source);
  }
}

void EnqueueResponse::MergeFrom(const EnqueueResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.EnqueueResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  queue_response_.MergeFrom(from.queue_response_);
}

void EnqueueResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.EnqueueResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void EnqueueResponse::CopyFrom(const EnqueueResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.EnqueueResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool EnqueueResponse::IsInitialized() const {

  return true;
}

void EnqueueResponse::Swap(EnqueueResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void EnqueueResponse::InternalSwap(EnqueueResponse* other) {
  queue_response_.UnsafeArenaSwap(&other->queue_response_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata EnqueueResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = EnqueueResponse_descriptor_;
  metadata.reflection = EnqueueResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// EnqueueResponse

// repeated .tensorflow.eager.QueueResponse queue_response = 1;
int EnqueueResponse::queue_response_size() const {
  return queue_response_.size();
}
void EnqueueResponse::clear_queue_response() {
  queue_response_.Clear();
}
const ::tensorflow::eager::QueueResponse& EnqueueResponse::queue_response(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.EnqueueResponse.queue_response)
  return queue_response_.Get(index);
}
::tensorflow::eager::QueueResponse* EnqueueResponse::mutable_queue_response(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.EnqueueResponse.queue_response)
  return queue_response_.Mutable(index);
}
::tensorflow::eager::QueueResponse* EnqueueResponse::add_queue_response() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.EnqueueResponse.queue_response)
  return queue_response_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::eager::QueueResponse >*
EnqueueResponse::mutable_queue_response() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.EnqueueResponse.queue_response)
  return &queue_response_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::eager::QueueResponse >&
EnqueueResponse::queue_response() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.EnqueueResponse.queue_response)
  return queue_response_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int WaitQueueDoneRequest::kContextIdFieldNumber;
const int WaitQueueDoneRequest::kOpIdFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

WaitQueueDoneRequest::WaitQueueDoneRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.WaitQueueDoneRequest)
}

void WaitQueueDoneRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

WaitQueueDoneRequest::WaitQueueDoneRequest(const WaitQueueDoneRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.WaitQueueDoneRequest)
}

void WaitQueueDoneRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  context_id_ = GOOGLE_ULONGLONG(0);
}

WaitQueueDoneRequest::~WaitQueueDoneRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.WaitQueueDoneRequest)
  SharedDtor();
}

void WaitQueueDoneRequest::SharedDtor() {
  if (this != default_instance_) {
  }
}

void WaitQueueDoneRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* WaitQueueDoneRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return WaitQueueDoneRequest_descriptor_;
}

const WaitQueueDoneRequest& WaitQueueDoneRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

WaitQueueDoneRequest* WaitQueueDoneRequest::default_instance_ = NULL;

WaitQueueDoneRequest* WaitQueueDoneRequest::New(::google::protobuf::Arena* arena) const {
  WaitQueueDoneRequest* n = new WaitQueueDoneRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void WaitQueueDoneRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.WaitQueueDoneRequest)
  context_id_ = GOOGLE_ULONGLONG(0);
  op_id_.Clear();
}

bool WaitQueueDoneRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.WaitQueueDoneRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional fixed64 context_id = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_FIXED64>(
                 input, &context_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_op_id;
        break;
      }

      // repeated int64 op_id = 2;
      case 2: {
        if (tag == 18) {
         parse_op_id:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPackedPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, this->mutable_op_id())));
        } else if (tag == 16) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadRepeatedPrimitiveNoInline<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 1, 18, input, this->mutable_op_id())));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.WaitQueueDoneRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.WaitQueueDoneRequest)
  return false;
#undef DO_
}

void WaitQueueDoneRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.WaitQueueDoneRequest)
  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFixed64(1, this->context_id(), output);
  }

  // repeated int64 op_id = 2;
  if (this->op_id_size() > 0) {
    ::google::protobuf::internal::WireFormatLite::WriteTag(2, ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED, output);
    output->WriteVarint32(_op_id_cached_byte_size_);
  }
  for (int i = 0; i < this->op_id_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64NoTag(
      this->op_id(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.WaitQueueDoneRequest)
}

::google::protobuf::uint8* WaitQueueDoneRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.WaitQueueDoneRequest)
  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFixed64ToArray(1, this->context_id(), target);
  }

  // repeated int64 op_id = 2;
  if (this->op_id_size() > 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteTagToArray(
      2,
      ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED,
      target);
    target = ::google::protobuf::io::CodedOutputStream::WriteVarint32ToArray(
      _op_id_cached_byte_size_, target);
  }
  for (int i = 0; i < this->op_id_size(); i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteInt64NoTagToArray(this->op_id(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.WaitQueueDoneRequest)
  return target;
}

int WaitQueueDoneRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.WaitQueueDoneRequest)
  int total_size = 0;

  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    total_size += 1 + 8;
  }

  // repeated int64 op_id = 2;
  {
    int data_size = 0;
    for (int i = 0; i < this->op_id_size(); i++) {
      data_size += ::google::protobuf::internal::WireFormatLite::
        Int64Size(this->op_id(i));
    }
    if (data_size > 0) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(data_size);
    }
    GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
    _op_id_cached_byte_size_ = data_size;
    GOOGLE_SAFE_CONCURRENT_WRITES_END();
    total_size += data_size;
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void WaitQueueDoneRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.WaitQueueDoneRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const WaitQueueDoneRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const WaitQueueDoneRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.WaitQueueDoneRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.WaitQueueDoneRequest)
    MergeFrom(*source);
  }
}

void WaitQueueDoneRequest::MergeFrom(const WaitQueueDoneRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.WaitQueueDoneRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  op_id_.MergeFrom(from.op_id_);
  if (from.context_id() != 0) {
    set_context_id(from.context_id());
  }
}

void WaitQueueDoneRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.WaitQueueDoneRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void WaitQueueDoneRequest::CopyFrom(const WaitQueueDoneRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.WaitQueueDoneRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool WaitQueueDoneRequest::IsInitialized() const {

  return true;
}

void WaitQueueDoneRequest::Swap(WaitQueueDoneRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void WaitQueueDoneRequest::InternalSwap(WaitQueueDoneRequest* other) {
  std::swap(context_id_, other->context_id_);
  op_id_.UnsafeArenaSwap(&other->op_id_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata WaitQueueDoneRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = WaitQueueDoneRequest_descriptor_;
  metadata.reflection = WaitQueueDoneRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// WaitQueueDoneRequest

// optional fixed64 context_id = 1;
void WaitQueueDoneRequest::clear_context_id() {
  context_id_ = GOOGLE_ULONGLONG(0);
}
 ::google::protobuf::uint64 WaitQueueDoneRequest::context_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.WaitQueueDoneRequest.context_id)
  return context_id_;
}
 void WaitQueueDoneRequest::set_context_id(::google::protobuf::uint64 value) {
  
  context_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.WaitQueueDoneRequest.context_id)
}

// repeated int64 op_id = 2;
int WaitQueueDoneRequest::op_id_size() const {
  return op_id_.size();
}
void WaitQueueDoneRequest::clear_op_id() {
  op_id_.Clear();
}
 ::google::protobuf::int64 WaitQueueDoneRequest::op_id(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.WaitQueueDoneRequest.op_id)
  return op_id_.Get(index);
}
 void WaitQueueDoneRequest::set_op_id(int index, ::google::protobuf::int64 value) {
  op_id_.Set(index, value);
  // @@protoc_insertion_point(field_set:tensorflow.eager.WaitQueueDoneRequest.op_id)
}
 void WaitQueueDoneRequest::add_op_id(::google::protobuf::int64 value) {
  op_id_.Add(value);
  // @@protoc_insertion_point(field_add:tensorflow.eager.WaitQueueDoneRequest.op_id)
}
 const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
WaitQueueDoneRequest::op_id() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.WaitQueueDoneRequest.op_id)
  return op_id_;
}
 ::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
WaitQueueDoneRequest::mutable_op_id() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.WaitQueueDoneRequest.op_id)
  return &op_id_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

WaitQueueDoneResponse::WaitQueueDoneResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.WaitQueueDoneResponse)
}

void WaitQueueDoneResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

WaitQueueDoneResponse::WaitQueueDoneResponse(const WaitQueueDoneResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.WaitQueueDoneResponse)
}

void WaitQueueDoneResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

WaitQueueDoneResponse::~WaitQueueDoneResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.WaitQueueDoneResponse)
  SharedDtor();
}

void WaitQueueDoneResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void WaitQueueDoneResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* WaitQueueDoneResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return WaitQueueDoneResponse_descriptor_;
}

const WaitQueueDoneResponse& WaitQueueDoneResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

WaitQueueDoneResponse* WaitQueueDoneResponse::default_instance_ = NULL;

WaitQueueDoneResponse* WaitQueueDoneResponse::New(::google::protobuf::Arena* arena) const {
  WaitQueueDoneResponse* n = new WaitQueueDoneResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void WaitQueueDoneResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.WaitQueueDoneResponse)
}

bool WaitQueueDoneResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.WaitQueueDoneResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.WaitQueueDoneResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.WaitQueueDoneResponse)
  return false;
#undef DO_
}

void WaitQueueDoneResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.WaitQueueDoneResponse)
  // @@protoc_insertion_point(serialize_end:tensorflow.eager.WaitQueueDoneResponse)
}

::google::protobuf::uint8* WaitQueueDoneResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.WaitQueueDoneResponse)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.WaitQueueDoneResponse)
  return target;
}

int WaitQueueDoneResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.WaitQueueDoneResponse)
  int total_size = 0;

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void WaitQueueDoneResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.WaitQueueDoneResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const WaitQueueDoneResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const WaitQueueDoneResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.WaitQueueDoneResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.WaitQueueDoneResponse)
    MergeFrom(*source);
  }
}

void WaitQueueDoneResponse::MergeFrom(const WaitQueueDoneResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.WaitQueueDoneResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
}

void WaitQueueDoneResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.WaitQueueDoneResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void WaitQueueDoneResponse::CopyFrom(const WaitQueueDoneResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.WaitQueueDoneResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool WaitQueueDoneResponse::IsInitialized() const {

  return true;
}

void WaitQueueDoneResponse::Swap(WaitQueueDoneResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void WaitQueueDoneResponse::InternalSwap(WaitQueueDoneResponse* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata WaitQueueDoneResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = WaitQueueDoneResponse_descriptor_;
  metadata.reflection = WaitQueueDoneResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// WaitQueueDoneResponse

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RunComponentFunctionRequest::kContextIdFieldNumber;
const int RunComponentFunctionRequest::kOperationFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RunComponentFunctionRequest::RunComponentFunctionRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.RunComponentFunctionRequest)
}

void RunComponentFunctionRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  operation_ = const_cast< ::tensorflow::eager::Operation*>(&::tensorflow::eager::Operation::default_instance());
}

RunComponentFunctionRequest::RunComponentFunctionRequest(const RunComponentFunctionRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.RunComponentFunctionRequest)
}

void RunComponentFunctionRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  context_id_ = GOOGLE_ULONGLONG(0);
  operation_ = NULL;
}

RunComponentFunctionRequest::~RunComponentFunctionRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.RunComponentFunctionRequest)
  SharedDtor();
}

void RunComponentFunctionRequest::SharedDtor() {
  if (this != default_instance_) {
    delete operation_;
  }
}

void RunComponentFunctionRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RunComponentFunctionRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RunComponentFunctionRequest_descriptor_;
}

const RunComponentFunctionRequest& RunComponentFunctionRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

RunComponentFunctionRequest* RunComponentFunctionRequest::default_instance_ = NULL;

RunComponentFunctionRequest* RunComponentFunctionRequest::New(::google::protobuf::Arena* arena) const {
  RunComponentFunctionRequest* n = new RunComponentFunctionRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RunComponentFunctionRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.RunComponentFunctionRequest)
  context_id_ = GOOGLE_ULONGLONG(0);
  if (GetArenaNoVirtual() == NULL && operation_ != NULL) delete operation_;
  operation_ = NULL;
}

bool RunComponentFunctionRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.RunComponentFunctionRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional fixed64 context_id = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_FIXED64>(
                 input, &context_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_operation;
        break;
      }

      // optional .tensorflow.eager.Operation operation = 2;
      case 2: {
        if (tag == 18) {
         parse_operation:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_operation()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.RunComponentFunctionRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.RunComponentFunctionRequest)
  return false;
#undef DO_
}

void RunComponentFunctionRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.RunComponentFunctionRequest)
  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFixed64(1, this->context_id(), output);
  }

  // optional .tensorflow.eager.Operation operation = 2;
  if (this->has_operation()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->operation_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.RunComponentFunctionRequest)
}

::google::protobuf::uint8* RunComponentFunctionRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.RunComponentFunctionRequest)
  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFixed64ToArray(1, this->context_id(), target);
  }

  // optional .tensorflow.eager.Operation operation = 2;
  if (this->has_operation()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *this->operation_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.RunComponentFunctionRequest)
  return target;
}

int RunComponentFunctionRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.RunComponentFunctionRequest)
  int total_size = 0;

  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    total_size += 1 + 8;
  }

  // optional .tensorflow.eager.Operation operation = 2;
  if (this->has_operation()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->operation_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RunComponentFunctionRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.RunComponentFunctionRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const RunComponentFunctionRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RunComponentFunctionRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.RunComponentFunctionRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.RunComponentFunctionRequest)
    MergeFrom(*source);
  }
}

void RunComponentFunctionRequest::MergeFrom(const RunComponentFunctionRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.RunComponentFunctionRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  if (from.context_id() != 0) {
    set_context_id(from.context_id());
  }
  if (from.has_operation()) {
    mutable_operation()->::tensorflow::eager::Operation::MergeFrom(from.operation());
  }
}

void RunComponentFunctionRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.RunComponentFunctionRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RunComponentFunctionRequest::CopyFrom(const RunComponentFunctionRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.RunComponentFunctionRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RunComponentFunctionRequest::IsInitialized() const {

  return true;
}

void RunComponentFunctionRequest::Swap(RunComponentFunctionRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RunComponentFunctionRequest::InternalSwap(RunComponentFunctionRequest* other) {
  std::swap(context_id_, other->context_id_);
  std::swap(operation_, other->operation_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RunComponentFunctionRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RunComponentFunctionRequest_descriptor_;
  metadata.reflection = RunComponentFunctionRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RunComponentFunctionRequest

// optional fixed64 context_id = 1;
void RunComponentFunctionRequest::clear_context_id() {
  context_id_ = GOOGLE_ULONGLONG(0);
}
 ::google::protobuf::uint64 RunComponentFunctionRequest::context_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.RunComponentFunctionRequest.context_id)
  return context_id_;
}
 void RunComponentFunctionRequest::set_context_id(::google::protobuf::uint64 value) {
  
  context_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.RunComponentFunctionRequest.context_id)
}

// optional .tensorflow.eager.Operation operation = 2;
bool RunComponentFunctionRequest::has_operation() const {
  return !_is_default_instance_ && operation_ != NULL;
}
void RunComponentFunctionRequest::clear_operation() {
  if (GetArenaNoVirtual() == NULL && operation_ != NULL) delete operation_;
  operation_ = NULL;
}
const ::tensorflow::eager::Operation& RunComponentFunctionRequest::operation() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.RunComponentFunctionRequest.operation)
  return operation_ != NULL ? *operation_ : *default_instance_->operation_;
}
::tensorflow::eager::Operation* RunComponentFunctionRequest::mutable_operation() {
  
  if (operation_ == NULL) {
    operation_ = new ::tensorflow::eager::Operation;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.RunComponentFunctionRequest.operation)
  return operation_;
}
::tensorflow::eager::Operation* RunComponentFunctionRequest::release_operation() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.RunComponentFunctionRequest.operation)
  
  ::tensorflow::eager::Operation* temp = operation_;
  operation_ = NULL;
  return temp;
}
void RunComponentFunctionRequest::set_allocated_operation(::tensorflow::eager::Operation* operation) {
  delete operation_;
  operation_ = operation;
  if (operation) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.RunComponentFunctionRequest.operation)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RunComponentFunctionResponse::kShapeFieldNumber;
const int RunComponentFunctionResponse::kTensorFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RunComponentFunctionResponse::RunComponentFunctionResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.RunComponentFunctionResponse)
}

void RunComponentFunctionResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

RunComponentFunctionResponse::RunComponentFunctionResponse(const RunComponentFunctionResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.RunComponentFunctionResponse)
}

void RunComponentFunctionResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

RunComponentFunctionResponse::~RunComponentFunctionResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.RunComponentFunctionResponse)
  SharedDtor();
}

void RunComponentFunctionResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void RunComponentFunctionResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RunComponentFunctionResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RunComponentFunctionResponse_descriptor_;
}

const RunComponentFunctionResponse& RunComponentFunctionResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

RunComponentFunctionResponse* RunComponentFunctionResponse::default_instance_ = NULL;

RunComponentFunctionResponse* RunComponentFunctionResponse::New(::google::protobuf::Arena* arena) const {
  RunComponentFunctionResponse* n = new RunComponentFunctionResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RunComponentFunctionResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.RunComponentFunctionResponse)
  shape_.Clear();
  tensor_.Clear();
}

bool RunComponentFunctionResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.RunComponentFunctionResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.TensorShapeProto shape = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_shape:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_shape()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_shape;
        if (input->ExpectTag(18)) goto parse_loop_tensor;
        input->UnsafeDecrementRecursionDepth();
        break;
      }

      // repeated .tensorflow.TensorProto tensor = 2;
      case 2: {
        if (tag == 18) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_tensor:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_tensor()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_loop_tensor;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.RunComponentFunctionResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.RunComponentFunctionResponse)
  return false;
#undef DO_
}

void RunComponentFunctionResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.RunComponentFunctionResponse)
  // repeated .tensorflow.TensorShapeProto shape = 1;
  for (unsigned int i = 0, n = this->shape_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->shape(i), output);
  }

  // repeated .tensorflow.TensorProto tensor = 2;
  for (unsigned int i = 0, n = this->tensor_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->tensor(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.RunComponentFunctionResponse)
}

::google::protobuf::uint8* RunComponentFunctionResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.RunComponentFunctionResponse)
  // repeated .tensorflow.TensorShapeProto shape = 1;
  for (unsigned int i = 0, n = this->shape_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, this->shape(i), false, target);
  }

  // repeated .tensorflow.TensorProto tensor = 2;
  for (unsigned int i = 0, n = this->tensor_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, this->tensor(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.RunComponentFunctionResponse)
  return target;
}

int RunComponentFunctionResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.RunComponentFunctionResponse)
  int total_size = 0;

  // repeated .tensorflow.TensorShapeProto shape = 1;
  total_size += 1 * this->shape_size();
  for (int i = 0; i < this->shape_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->shape(i));
  }

  // repeated .tensorflow.TensorProto tensor = 2;
  total_size += 1 * this->tensor_size();
  for (int i = 0; i < this->tensor_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->tensor(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RunComponentFunctionResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.RunComponentFunctionResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const RunComponentFunctionResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RunComponentFunctionResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.RunComponentFunctionResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.RunComponentFunctionResponse)
    MergeFrom(*source);
  }
}

void RunComponentFunctionResponse::MergeFrom(const RunComponentFunctionResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.RunComponentFunctionResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  shape_.MergeFrom(from.shape_);
  tensor_.MergeFrom(from.tensor_);
}

void RunComponentFunctionResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.RunComponentFunctionResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RunComponentFunctionResponse::CopyFrom(const RunComponentFunctionResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.RunComponentFunctionResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RunComponentFunctionResponse::IsInitialized() const {

  return true;
}

void RunComponentFunctionResponse::Swap(RunComponentFunctionResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RunComponentFunctionResponse::InternalSwap(RunComponentFunctionResponse* other) {
  shape_.UnsafeArenaSwap(&other->shape_);
  tensor_.UnsafeArenaSwap(&other->tensor_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RunComponentFunctionResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RunComponentFunctionResponse_descriptor_;
  metadata.reflection = RunComponentFunctionResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RunComponentFunctionResponse

// repeated .tensorflow.TensorShapeProto shape = 1;
int RunComponentFunctionResponse::shape_size() const {
  return shape_.size();
}
void RunComponentFunctionResponse::clear_shape() {
  shape_.Clear();
}
const ::tensorflow::TensorShapeProto& RunComponentFunctionResponse::shape(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.RunComponentFunctionResponse.shape)
  return shape_.Get(index);
}
::tensorflow::TensorShapeProto* RunComponentFunctionResponse::mutable_shape(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.RunComponentFunctionResponse.shape)
  return shape_.Mutable(index);
}
::tensorflow::TensorShapeProto* RunComponentFunctionResponse::add_shape() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.RunComponentFunctionResponse.shape)
  return shape_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::TensorShapeProto >*
RunComponentFunctionResponse::mutable_shape() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.RunComponentFunctionResponse.shape)
  return &shape_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::TensorShapeProto >&
RunComponentFunctionResponse::shape() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.RunComponentFunctionResponse.shape)
  return shape_;
}

// repeated .tensorflow.TensorProto tensor = 2;
int RunComponentFunctionResponse::tensor_size() const {
  return tensor_.size();
}
void RunComponentFunctionResponse::clear_tensor() {
  tensor_.Clear();
}
const ::tensorflow::TensorProto& RunComponentFunctionResponse::tensor(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.RunComponentFunctionResponse.tensor)
  return tensor_.Get(index);
}
::tensorflow::TensorProto* RunComponentFunctionResponse::mutable_tensor(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.RunComponentFunctionResponse.tensor)
  return tensor_.Mutable(index);
}
::tensorflow::TensorProto* RunComponentFunctionResponse::add_tensor() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.RunComponentFunctionResponse.tensor)
  return tensor_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::TensorProto >*
RunComponentFunctionResponse::mutable_tensor() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.RunComponentFunctionResponse.tensor)
  return &tensor_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::TensorProto >&
RunComponentFunctionResponse::tensor() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.RunComponentFunctionResponse.tensor)
  return tensor_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int KeepAliveRequest::kContextIdFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

KeepAliveRequest::KeepAliveRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.KeepAliveRequest)
}

void KeepAliveRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

KeepAliveRequest::KeepAliveRequest(const KeepAliveRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.KeepAliveRequest)
}

void KeepAliveRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  context_id_ = GOOGLE_ULONGLONG(0);
}

KeepAliveRequest::~KeepAliveRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.KeepAliveRequest)
  SharedDtor();
}

void KeepAliveRequest::SharedDtor() {
  if (this != default_instance_) {
  }
}

void KeepAliveRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* KeepAliveRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return KeepAliveRequest_descriptor_;
}

const KeepAliveRequest& KeepAliveRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

KeepAliveRequest* KeepAliveRequest::default_instance_ = NULL;

KeepAliveRequest* KeepAliveRequest::New(::google::protobuf::Arena* arena) const {
  KeepAliveRequest* n = new KeepAliveRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void KeepAliveRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.KeepAliveRequest)
  context_id_ = GOOGLE_ULONGLONG(0);
}

bool KeepAliveRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.KeepAliveRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional fixed64 context_id = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_FIXED64>(
                 input, &context_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.KeepAliveRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.KeepAliveRequest)
  return false;
#undef DO_
}

void KeepAliveRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.KeepAliveRequest)
  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFixed64(1, this->context_id(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.KeepAliveRequest)
}

::google::protobuf::uint8* KeepAliveRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.KeepAliveRequest)
  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFixed64ToArray(1, this->context_id(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.KeepAliveRequest)
  return target;
}

int KeepAliveRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.KeepAliveRequest)
  int total_size = 0;

  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    total_size += 1 + 8;
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void KeepAliveRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.KeepAliveRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const KeepAliveRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const KeepAliveRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.KeepAliveRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.KeepAliveRequest)
    MergeFrom(*source);
  }
}

void KeepAliveRequest::MergeFrom(const KeepAliveRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.KeepAliveRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  if (from.context_id() != 0) {
    set_context_id(from.context_id());
  }
}

void KeepAliveRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.KeepAliveRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void KeepAliveRequest::CopyFrom(const KeepAliveRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.KeepAliveRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool KeepAliveRequest::IsInitialized() const {

  return true;
}

void KeepAliveRequest::Swap(KeepAliveRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void KeepAliveRequest::InternalSwap(KeepAliveRequest* other) {
  std::swap(context_id_, other->context_id_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata KeepAliveRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = KeepAliveRequest_descriptor_;
  metadata.reflection = KeepAliveRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// KeepAliveRequest

// optional fixed64 context_id = 1;
void KeepAliveRequest::clear_context_id() {
  context_id_ = GOOGLE_ULONGLONG(0);
}
 ::google::protobuf::uint64 KeepAliveRequest::context_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.KeepAliveRequest.context_id)
  return context_id_;
}
 void KeepAliveRequest::set_context_id(::google::protobuf::uint64 value) {
  
  context_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.KeepAliveRequest.context_id)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int KeepAliveResponse::kContextViewIdFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

KeepAliveResponse::KeepAliveResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.KeepAliveResponse)
}

void KeepAliveResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

KeepAliveResponse::KeepAliveResponse(const KeepAliveResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.KeepAliveResponse)
}

void KeepAliveResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  context_view_id_ = GOOGLE_ULONGLONG(0);
}

KeepAliveResponse::~KeepAliveResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.KeepAliveResponse)
  SharedDtor();
}

void KeepAliveResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void KeepAliveResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* KeepAliveResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return KeepAliveResponse_descriptor_;
}

const KeepAliveResponse& KeepAliveResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

KeepAliveResponse* KeepAliveResponse::default_instance_ = NULL;

KeepAliveResponse* KeepAliveResponse::New(::google::protobuf::Arena* arena) const {
  KeepAliveResponse* n = new KeepAliveResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void KeepAliveResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.KeepAliveResponse)
  context_view_id_ = GOOGLE_ULONGLONG(0);
}

bool KeepAliveResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.KeepAliveResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional fixed64 context_view_id = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_FIXED64>(
                 input, &context_view_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.KeepAliveResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.KeepAliveResponse)
  return false;
#undef DO_
}

void KeepAliveResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.KeepAliveResponse)
  // optional fixed64 context_view_id = 1;
  if (this->context_view_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFixed64(1, this->context_view_id(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.KeepAliveResponse)
}

::google::protobuf::uint8* KeepAliveResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.KeepAliveResponse)
  // optional fixed64 context_view_id = 1;
  if (this->context_view_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFixed64ToArray(1, this->context_view_id(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.KeepAliveResponse)
  return target;
}

int KeepAliveResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.KeepAliveResponse)
  int total_size = 0;

  // optional fixed64 context_view_id = 1;
  if (this->context_view_id() != 0) {
    total_size += 1 + 8;
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void KeepAliveResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.KeepAliveResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const KeepAliveResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const KeepAliveResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.KeepAliveResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.KeepAliveResponse)
    MergeFrom(*source);
  }
}

void KeepAliveResponse::MergeFrom(const KeepAliveResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.KeepAliveResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  if (from.context_view_id() != 0) {
    set_context_view_id(from.context_view_id());
  }
}

void KeepAliveResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.KeepAliveResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void KeepAliveResponse::CopyFrom(const KeepAliveResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.KeepAliveResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool KeepAliveResponse::IsInitialized() const {

  return true;
}

void KeepAliveResponse::Swap(KeepAliveResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void KeepAliveResponse::InternalSwap(KeepAliveResponse* other) {
  std::swap(context_view_id_, other->context_view_id_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata KeepAliveResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = KeepAliveResponse_descriptor_;
  metadata.reflection = KeepAliveResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// KeepAliveResponse

// optional fixed64 context_view_id = 1;
void KeepAliveResponse::clear_context_view_id() {
  context_view_id_ = GOOGLE_ULONGLONG(0);
}
 ::google::protobuf::uint64 KeepAliveResponse::context_view_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.KeepAliveResponse.context_view_id)
  return context_view_id_;
}
 void KeepAliveResponse::set_context_view_id(::google::protobuf::uint64 value) {
  
  context_view_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.KeepAliveResponse.context_view_id)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CloseContextRequest::kContextIdFieldNumber;
const int CloseContextRequest::kContextViewIdFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CloseContextRequest::CloseContextRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.CloseContextRequest)
}

void CloseContextRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

CloseContextRequest::CloseContextRequest(const CloseContextRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.CloseContextRequest)
}

void CloseContextRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  context_id_ = GOOGLE_ULONGLONG(0);
  context_view_id_ = GOOGLE_ULONGLONG(0);
}

CloseContextRequest::~CloseContextRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.CloseContextRequest)
  SharedDtor();
}

void CloseContextRequest::SharedDtor() {
  if (this != default_instance_) {
  }
}

void CloseContextRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CloseContextRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CloseContextRequest_descriptor_;
}

const CloseContextRequest& CloseContextRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

CloseContextRequest* CloseContextRequest::default_instance_ = NULL;

CloseContextRequest* CloseContextRequest::New(::google::protobuf::Arena* arena) const {
  CloseContextRequest* n = new CloseContextRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CloseContextRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.CloseContextRequest)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(CloseContextRequest, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<CloseContextRequest*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(context_id_, context_view_id_);

#undef ZR_HELPER_
#undef ZR_

}

bool CloseContextRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.CloseContextRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional fixed64 context_id = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_FIXED64>(
                 input, &context_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(17)) goto parse_context_view_id;
        break;
      }

      // optional fixed64 context_view_id = 2;
      case 2: {
        if (tag == 17) {
         parse_context_view_id:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_FIXED64>(
                 input, &context_view_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.CloseContextRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.CloseContextRequest)
  return false;
#undef DO_
}

void CloseContextRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.CloseContextRequest)
  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFixed64(1, this->context_id(), output);
  }

  // optional fixed64 context_view_id = 2;
  if (this->context_view_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFixed64(2, this->context_view_id(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.CloseContextRequest)
}

::google::protobuf::uint8* CloseContextRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.CloseContextRequest)
  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFixed64ToArray(1, this->context_id(), target);
  }

  // optional fixed64 context_view_id = 2;
  if (this->context_view_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFixed64ToArray(2, this->context_view_id(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.CloseContextRequest)
  return target;
}

int CloseContextRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.CloseContextRequest)
  int total_size = 0;

  // optional fixed64 context_id = 1;
  if (this->context_id() != 0) {
    total_size += 1 + 8;
  }

  // optional fixed64 context_view_id = 2;
  if (this->context_view_id() != 0) {
    total_size += 1 + 8;
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CloseContextRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.CloseContextRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const CloseContextRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CloseContextRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.CloseContextRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.CloseContextRequest)
    MergeFrom(*source);
  }
}

void CloseContextRequest::MergeFrom(const CloseContextRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.CloseContextRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  if (from.context_id() != 0) {
    set_context_id(from.context_id());
  }
  if (from.context_view_id() != 0) {
    set_context_view_id(from.context_view_id());
  }
}

void CloseContextRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.CloseContextRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CloseContextRequest::CopyFrom(const CloseContextRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.CloseContextRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CloseContextRequest::IsInitialized() const {

  return true;
}

void CloseContextRequest::Swap(CloseContextRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CloseContextRequest::InternalSwap(CloseContextRequest* other) {
  std::swap(context_id_, other->context_id_);
  std::swap(context_view_id_, other->context_view_id_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CloseContextRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CloseContextRequest_descriptor_;
  metadata.reflection = CloseContextRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CloseContextRequest

// optional fixed64 context_id = 1;
void CloseContextRequest::clear_context_id() {
  context_id_ = GOOGLE_ULONGLONG(0);
}
 ::google::protobuf::uint64 CloseContextRequest::context_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CloseContextRequest.context_id)
  return context_id_;
}
 void CloseContextRequest::set_context_id(::google::protobuf::uint64 value) {
  
  context_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.CloseContextRequest.context_id)
}

// optional fixed64 context_view_id = 2;
void CloseContextRequest::clear_context_view_id() {
  context_view_id_ = GOOGLE_ULONGLONG(0);
}
 ::google::protobuf::uint64 CloseContextRequest::context_view_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CloseContextRequest.context_view_id)
  return context_view_id_;
}
 void CloseContextRequest::set_context_view_id(::google::protobuf::uint64 value) {
  
  context_view_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.CloseContextRequest.context_view_id)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CloseContextResponse::CloseContextResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.CloseContextResponse)
}

void CloseContextResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

CloseContextResponse::CloseContextResponse(const CloseContextResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.CloseContextResponse)
}

void CloseContextResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

CloseContextResponse::~CloseContextResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.CloseContextResponse)
  SharedDtor();
}

void CloseContextResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void CloseContextResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CloseContextResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CloseContextResponse_descriptor_;
}

const CloseContextResponse& CloseContextResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

CloseContextResponse* CloseContextResponse::default_instance_ = NULL;

CloseContextResponse* CloseContextResponse::New(::google::protobuf::Arena* arena) const {
  CloseContextResponse* n = new CloseContextResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CloseContextResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.CloseContextResponse)
}

bool CloseContextResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.CloseContextResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.CloseContextResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.CloseContextResponse)
  return false;
#undef DO_
}

void CloseContextResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.CloseContextResponse)
  // @@protoc_insertion_point(serialize_end:tensorflow.eager.CloseContextResponse)
}

::google::protobuf::uint8* CloseContextResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.CloseContextResponse)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.CloseContextResponse)
  return target;
}

int CloseContextResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.CloseContextResponse)
  int total_size = 0;

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CloseContextResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.CloseContextResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const CloseContextResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CloseContextResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.CloseContextResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.CloseContextResponse)
    MergeFrom(*source);
  }
}

void CloseContextResponse::MergeFrom(const CloseContextResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.CloseContextResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
}

void CloseContextResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.CloseContextResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CloseContextResponse::CopyFrom(const CloseContextResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.CloseContextResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CloseContextResponse::IsInitialized() const {

  return true;
}

void CloseContextResponse::Swap(CloseContextResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CloseContextResponse::InternalSwap(CloseContextResponse* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CloseContextResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CloseContextResponse_descriptor_;
  metadata.reflection = CloseContextResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CloseContextResponse

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RegisterFunctionOp::kFunctionDefFieldNumber;
const int RegisterFunctionOp::kIsComponentFunctionFieldNumber;
const int RegisterFunctionOp::kLibraryFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RegisterFunctionOp::RegisterFunctionOp()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.RegisterFunctionOp)
}

void RegisterFunctionOp::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  function_def_ = const_cast< ::tensorflow::FunctionDef*>(&::tensorflow::FunctionDef::default_instance());
  library_ = const_cast< ::tensorflow::FunctionDefLibrary*>(&::tensorflow::FunctionDefLibrary::default_instance());
}

RegisterFunctionOp::RegisterFunctionOp(const RegisterFunctionOp& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.RegisterFunctionOp)
}

void RegisterFunctionOp::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  function_def_ = NULL;
  is_component_function_ = false;
  library_ = NULL;
}

RegisterFunctionOp::~RegisterFunctionOp() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.RegisterFunctionOp)
  SharedDtor();
}

void RegisterFunctionOp::SharedDtor() {
  if (this != default_instance_) {
    delete function_def_;
    delete library_;
  }
}

void RegisterFunctionOp::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RegisterFunctionOp::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RegisterFunctionOp_descriptor_;
}

const RegisterFunctionOp& RegisterFunctionOp::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

RegisterFunctionOp* RegisterFunctionOp::default_instance_ = NULL;

RegisterFunctionOp* RegisterFunctionOp::New(::google::protobuf::Arena* arena) const {
  RegisterFunctionOp* n = new RegisterFunctionOp;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RegisterFunctionOp::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.RegisterFunctionOp)
  if (GetArenaNoVirtual() == NULL && function_def_ != NULL) delete function_def_;
  function_def_ = NULL;
  is_component_function_ = false;
  if (GetArenaNoVirtual() == NULL && library_ != NULL) delete library_;
  library_ = NULL;
}

bool RegisterFunctionOp::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.RegisterFunctionOp)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.FunctionDef function_def = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_function_def()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_is_component_function;
        break;
      }

      // optional bool is_component_function = 2;
      case 2: {
        if (tag == 16) {
         parse_is_component_function:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &is_component_function_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_library;
        break;
      }

      // optional .tensorflow.FunctionDefLibrary library = 3;
      case 3: {
        if (tag == 26) {
         parse_library:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_library()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.RegisterFunctionOp)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.RegisterFunctionOp)
  return false;
#undef DO_
}

void RegisterFunctionOp::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.RegisterFunctionOp)
  // optional .tensorflow.FunctionDef function_def = 1;
  if (this->has_function_def()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->function_def_, output);
  }

  // optional bool is_component_function = 2;
  if (this->is_component_function() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->is_component_function(), output);
  }

  // optional .tensorflow.FunctionDefLibrary library = 3;
  if (this->has_library()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, *this->library_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.RegisterFunctionOp)
}

::google::protobuf::uint8* RegisterFunctionOp::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.RegisterFunctionOp)
  // optional .tensorflow.FunctionDef function_def = 1;
  if (this->has_function_def()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->function_def_, false, target);
  }

  // optional bool is_component_function = 2;
  if (this->is_component_function() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->is_component_function(), target);
  }

  // optional .tensorflow.FunctionDefLibrary library = 3;
  if (this->has_library()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        3, *this->library_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.RegisterFunctionOp)
  return target;
}

int RegisterFunctionOp::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.RegisterFunctionOp)
  int total_size = 0;

  // optional .tensorflow.FunctionDef function_def = 1;
  if (this->has_function_def()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->function_def_);
  }

  // optional bool is_component_function = 2;
  if (this->is_component_function() != 0) {
    total_size += 1 + 1;
  }

  // optional .tensorflow.FunctionDefLibrary library = 3;
  if (this->has_library()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->library_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RegisterFunctionOp::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.RegisterFunctionOp)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const RegisterFunctionOp* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RegisterFunctionOp>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.RegisterFunctionOp)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.RegisterFunctionOp)
    MergeFrom(*source);
  }
}

void RegisterFunctionOp::MergeFrom(const RegisterFunctionOp& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.RegisterFunctionOp)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  if (from.has_function_def()) {
    mutable_function_def()->::tensorflow::FunctionDef::MergeFrom(from.function_def());
  }
  if (from.is_component_function() != 0) {
    set_is_component_function(from.is_component_function());
  }
  if (from.has_library()) {
    mutable_library()->::tensorflow::FunctionDefLibrary::MergeFrom(from.library());
  }
}

void RegisterFunctionOp::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.RegisterFunctionOp)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RegisterFunctionOp::CopyFrom(const RegisterFunctionOp& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.RegisterFunctionOp)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RegisterFunctionOp::IsInitialized() const {

  return true;
}

void RegisterFunctionOp::Swap(RegisterFunctionOp* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RegisterFunctionOp::InternalSwap(RegisterFunctionOp* other) {
  std::swap(function_def_, other->function_def_);
  std::swap(is_component_function_, other->is_component_function_);
  std::swap(library_, other->library_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RegisterFunctionOp::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RegisterFunctionOp_descriptor_;
  metadata.reflection = RegisterFunctionOp_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RegisterFunctionOp

// optional .tensorflow.FunctionDef function_def = 1;
bool RegisterFunctionOp::has_function_def() const {
  return !_is_default_instance_ && function_def_ != NULL;
}
void RegisterFunctionOp::clear_function_def() {
  if (GetArenaNoVirtual() == NULL && function_def_ != NULL) delete function_def_;
  function_def_ = NULL;
}
const ::tensorflow::FunctionDef& RegisterFunctionOp::function_def() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.RegisterFunctionOp.function_def)
  return function_def_ != NULL ? *function_def_ : *default_instance_->function_def_;
}
::tensorflow::FunctionDef* RegisterFunctionOp::mutable_function_def() {
  
  if (function_def_ == NULL) {
    function_def_ = new ::tensorflow::FunctionDef;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.RegisterFunctionOp.function_def)
  return function_def_;
}
::tensorflow::FunctionDef* RegisterFunctionOp::release_function_def() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.RegisterFunctionOp.function_def)
  
  ::tensorflow::FunctionDef* temp = function_def_;
  function_def_ = NULL;
  return temp;
}
void RegisterFunctionOp::set_allocated_function_def(::tensorflow::FunctionDef* function_def) {
  delete function_def_;
  if (function_def != NULL && function_def->GetArena() != NULL) {
    ::tensorflow::FunctionDef* new_function_def = new ::tensorflow::FunctionDef;
    new_function_def->CopyFrom(*function_def);
    function_def = new_function_def;
  }
  function_def_ = function_def;
  if (function_def) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.RegisterFunctionOp.function_def)
}

// optional bool is_component_function = 2;
void RegisterFunctionOp::clear_is_component_function() {
  is_component_function_ = false;
}
 bool RegisterFunctionOp::is_component_function() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.RegisterFunctionOp.is_component_function)
  return is_component_function_;
}
 void RegisterFunctionOp::set_is_component_function(bool value) {
  
  is_component_function_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.RegisterFunctionOp.is_component_function)
}

// optional .tensorflow.FunctionDefLibrary library = 3;
bool RegisterFunctionOp::has_library() const {
  return !_is_default_instance_ && library_ != NULL;
}
void RegisterFunctionOp::clear_library() {
  if (GetArenaNoVirtual() == NULL && library_ != NULL) delete library_;
  library_ = NULL;
}
const ::tensorflow::FunctionDefLibrary& RegisterFunctionOp::library() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.RegisterFunctionOp.library)
  return library_ != NULL ? *library_ : *default_instance_->library_;
}
::tensorflow::FunctionDefLibrary* RegisterFunctionOp::mutable_library() {
  
  if (library_ == NULL) {
    library_ = new ::tensorflow::FunctionDefLibrary;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.RegisterFunctionOp.library)
  return library_;
}
::tensorflow::FunctionDefLibrary* RegisterFunctionOp::release_library() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.RegisterFunctionOp.library)
  
  ::tensorflow::FunctionDefLibrary* temp = library_;
  library_ = NULL;
  return temp;
}
void RegisterFunctionOp::set_allocated_library(::tensorflow::FunctionDefLibrary* library) {
  delete library_;
  if (library != NULL && library->GetArena() != NULL) {
    ::tensorflow::FunctionDefLibrary* new_library = new ::tensorflow::FunctionDefLibrary;
    new_library->CopyFrom(*library);
    library = new_library;
  }
  library_ = library;
  if (library) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.RegisterFunctionOp.library)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CleanupFunctionOp::kStepIdFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CleanupFunctionOp::CleanupFunctionOp()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.CleanupFunctionOp)
}

void CleanupFunctionOp::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

CleanupFunctionOp::CleanupFunctionOp(const CleanupFunctionOp& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.CleanupFunctionOp)
}

void CleanupFunctionOp::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  step_id_ = GOOGLE_LONGLONG(0);
}

CleanupFunctionOp::~CleanupFunctionOp() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.CleanupFunctionOp)
  SharedDtor();
}

void CleanupFunctionOp::SharedDtor() {
  if (this != default_instance_) {
  }
}

void CleanupFunctionOp::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CleanupFunctionOp::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CleanupFunctionOp_descriptor_;
}

const CleanupFunctionOp& CleanupFunctionOp::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

CleanupFunctionOp* CleanupFunctionOp::default_instance_ = NULL;

CleanupFunctionOp* CleanupFunctionOp::New(::google::protobuf::Arena* arena) const {
  CleanupFunctionOp* n = new CleanupFunctionOp;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CleanupFunctionOp::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.CleanupFunctionOp)
  step_id_ = GOOGLE_LONGLONG(0);
}

bool CleanupFunctionOp::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.CleanupFunctionOp)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int64 step_id = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &step_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.CleanupFunctionOp)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.CleanupFunctionOp)
  return false;
#undef DO_
}

void CleanupFunctionOp::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.CleanupFunctionOp)
  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(1, this->step_id(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.CleanupFunctionOp)
}

::google::protobuf::uint8* CleanupFunctionOp::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.CleanupFunctionOp)
  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(1, this->step_id(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.CleanupFunctionOp)
  return target;
}

int CleanupFunctionOp::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.CleanupFunctionOp)
  int total_size = 0;

  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->step_id());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CleanupFunctionOp::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.CleanupFunctionOp)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const CleanupFunctionOp* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CleanupFunctionOp>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.CleanupFunctionOp)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.CleanupFunctionOp)
    MergeFrom(*source);
  }
}

void CleanupFunctionOp::MergeFrom(const CleanupFunctionOp& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.CleanupFunctionOp)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  if (from.step_id() != 0) {
    set_step_id(from.step_id());
  }
}

void CleanupFunctionOp::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.CleanupFunctionOp)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CleanupFunctionOp::CopyFrom(const CleanupFunctionOp& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.CleanupFunctionOp)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CleanupFunctionOp::IsInitialized() const {

  return true;
}

void CleanupFunctionOp::Swap(CleanupFunctionOp* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CleanupFunctionOp::InternalSwap(CleanupFunctionOp* other) {
  std::swap(step_id_, other->step_id_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CleanupFunctionOp::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CleanupFunctionOp_descriptor_;
  metadata.reflection = CleanupFunctionOp_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CleanupFunctionOp

// optional int64 step_id = 1;
void CleanupFunctionOp::clear_step_id() {
  step_id_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 CleanupFunctionOp::step_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.CleanupFunctionOp.step_id)
  return step_id_;
}
 void CleanupFunctionOp::set_step_id(::google::protobuf::int64 value) {
  
  step_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.CleanupFunctionOp.step_id)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SyncRemoteExecutorForStream::SyncRemoteExecutorForStream()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.SyncRemoteExecutorForStream)
}

void SyncRemoteExecutorForStream::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

SyncRemoteExecutorForStream::SyncRemoteExecutorForStream(const SyncRemoteExecutorForStream& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.SyncRemoteExecutorForStream)
}

void SyncRemoteExecutorForStream::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

SyncRemoteExecutorForStream::~SyncRemoteExecutorForStream() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.SyncRemoteExecutorForStream)
  SharedDtor();
}

void SyncRemoteExecutorForStream::SharedDtor() {
  if (this != default_instance_) {
  }
}

void SyncRemoteExecutorForStream::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SyncRemoteExecutorForStream::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return SyncRemoteExecutorForStream_descriptor_;
}

const SyncRemoteExecutorForStream& SyncRemoteExecutorForStream::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

SyncRemoteExecutorForStream* SyncRemoteExecutorForStream::default_instance_ = NULL;

SyncRemoteExecutorForStream* SyncRemoteExecutorForStream::New(::google::protobuf::Arena* arena) const {
  SyncRemoteExecutorForStream* n = new SyncRemoteExecutorForStream;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SyncRemoteExecutorForStream::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.SyncRemoteExecutorForStream)
}

bool SyncRemoteExecutorForStream::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.SyncRemoteExecutorForStream)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.SyncRemoteExecutorForStream)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.SyncRemoteExecutorForStream)
  return false;
#undef DO_
}

void SyncRemoteExecutorForStream::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.SyncRemoteExecutorForStream)
  // @@protoc_insertion_point(serialize_end:tensorflow.eager.SyncRemoteExecutorForStream)
}

::google::protobuf::uint8* SyncRemoteExecutorForStream::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.SyncRemoteExecutorForStream)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.SyncRemoteExecutorForStream)
  return target;
}

int SyncRemoteExecutorForStream::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.SyncRemoteExecutorForStream)
  int total_size = 0;

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SyncRemoteExecutorForStream::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.SyncRemoteExecutorForStream)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const SyncRemoteExecutorForStream* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const SyncRemoteExecutorForStream>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.SyncRemoteExecutorForStream)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.SyncRemoteExecutorForStream)
    MergeFrom(*source);
  }
}

void SyncRemoteExecutorForStream::MergeFrom(const SyncRemoteExecutorForStream& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.SyncRemoteExecutorForStream)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
}

void SyncRemoteExecutorForStream::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.SyncRemoteExecutorForStream)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SyncRemoteExecutorForStream::CopyFrom(const SyncRemoteExecutorForStream& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.SyncRemoteExecutorForStream)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SyncRemoteExecutorForStream::IsInitialized() const {

  return true;
}

void SyncRemoteExecutorForStream::Swap(SyncRemoteExecutorForStream* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SyncRemoteExecutorForStream::InternalSwap(SyncRemoteExecutorForStream* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SyncRemoteExecutorForStream::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = SyncRemoteExecutorForStream_descriptor_;
  metadata.reflection = SyncRemoteExecutorForStream_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SyncRemoteExecutorForStream

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SendTensorOp::kOpIdFieldNumber;
const int SendTensorOp::kTensorsFieldNumber;
const int SendTensorOp::kDeviceNameFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SendTensorOp::SendTensorOp()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.SendTensorOp)
}

void SendTensorOp::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

SendTensorOp::SendTensorOp(const SendTensorOp& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.SendTensorOp)
}

void SendTensorOp::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  op_id_ = GOOGLE_LONGLONG(0);
  device_name_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

SendTensorOp::~SendTensorOp() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.SendTensorOp)
  SharedDtor();
}

void SendTensorOp::SharedDtor() {
  device_name_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
  }
}

void SendTensorOp::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SendTensorOp::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return SendTensorOp_descriptor_;
}

const SendTensorOp& SendTensorOp::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

SendTensorOp* SendTensorOp::default_instance_ = NULL;

SendTensorOp* SendTensorOp::New(::google::protobuf::Arena* arena) const {
  SendTensorOp* n = new SendTensorOp;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SendTensorOp::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.SendTensorOp)
  op_id_ = GOOGLE_LONGLONG(0);
  device_name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  tensors_.Clear();
}

bool SendTensorOp::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.SendTensorOp)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int64 op_id = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &op_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_tensors;
        break;
      }

      // repeated .tensorflow.TensorProto tensors = 2;
      case 2: {
        if (tag == 18) {
         parse_tensors:
          DO_(input->IncrementRecursionDepth());
         parse_loop_tensors:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_tensors()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_loop_tensors;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(26)) goto parse_device_name;
        break;
      }

      // optional string device_name = 3;
      case 3: {
        if (tag == 26) {
         parse_device_name:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_device_name()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->device_name().data(), this->device_name().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.eager.SendTensorOp.device_name"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.SendTensorOp)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.SendTensorOp)
  return false;
#undef DO_
}

void SendTensorOp::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.SendTensorOp)
  // optional int64 op_id = 1;
  if (this->op_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(1, this->op_id(), output);
  }

  // repeated .tensorflow.TensorProto tensors = 2;
  for (unsigned int i = 0, n = this->tensors_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->tensors(i), output);
  }

  // optional string device_name = 3;
  if (this->device_name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device_name().data(), this->device_name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.eager.SendTensorOp.device_name");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      3, this->device_name(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.SendTensorOp)
}

::google::protobuf::uint8* SendTensorOp::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.SendTensorOp)
  // optional int64 op_id = 1;
  if (this->op_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(1, this->op_id(), target);
  }

  // repeated .tensorflow.TensorProto tensors = 2;
  for (unsigned int i = 0, n = this->tensors_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, this->tensors(i), false, target);
  }

  // optional string device_name = 3;
  if (this->device_name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device_name().data(), this->device_name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.eager.SendTensorOp.device_name");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        3, this->device_name(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.SendTensorOp)
  return target;
}

int SendTensorOp::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.SendTensorOp)
  int total_size = 0;

  // optional int64 op_id = 1;
  if (this->op_id() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->op_id());
  }

  // optional string device_name = 3;
  if (this->device_name().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->device_name());
  }

  // repeated .tensorflow.TensorProto tensors = 2;
  total_size += 1 * this->tensors_size();
  for (int i = 0; i < this->tensors_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->tensors(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SendTensorOp::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.SendTensorOp)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const SendTensorOp* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const SendTensorOp>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.SendTensorOp)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.SendTensorOp)
    MergeFrom(*source);
  }
}

void SendTensorOp::MergeFrom(const SendTensorOp& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.SendTensorOp)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  tensors_.MergeFrom(from.tensors_);
  if (from.op_id() != 0) {
    set_op_id(from.op_id());
  }
  if (from.device_name().size() > 0) {

    device_name_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.device_name_);
  }
}

void SendTensorOp::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.SendTensorOp)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SendTensorOp::CopyFrom(const SendTensorOp& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.SendTensorOp)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SendTensorOp::IsInitialized() const {

  return true;
}

void SendTensorOp::Swap(SendTensorOp* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SendTensorOp::InternalSwap(SendTensorOp* other) {
  std::swap(op_id_, other->op_id_);
  tensors_.UnsafeArenaSwap(&other->tensors_);
  device_name_.Swap(&other->device_name_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SendTensorOp::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = SendTensorOp_descriptor_;
  metadata.reflection = SendTensorOp_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SendTensorOp

// optional int64 op_id = 1;
void SendTensorOp::clear_op_id() {
  op_id_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 SendTensorOp::op_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.SendTensorOp.op_id)
  return op_id_;
}
 void SendTensorOp::set_op_id(::google::protobuf::int64 value) {
  
  op_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.SendTensorOp.op_id)
}

// repeated .tensorflow.TensorProto tensors = 2;
int SendTensorOp::tensors_size() const {
  return tensors_.size();
}
void SendTensorOp::clear_tensors() {
  tensors_.Clear();
}
const ::tensorflow::TensorProto& SendTensorOp::tensors(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.SendTensorOp.tensors)
  return tensors_.Get(index);
}
::tensorflow::TensorProto* SendTensorOp::mutable_tensors(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.SendTensorOp.tensors)
  return tensors_.Mutable(index);
}
::tensorflow::TensorProto* SendTensorOp::add_tensors() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.SendTensorOp.tensors)
  return tensors_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::TensorProto >*
SendTensorOp::mutable_tensors() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.SendTensorOp.tensors)
  return &tensors_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::TensorProto >&
SendTensorOp::tensors() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.SendTensorOp.tensors)
  return tensors_;
}

// optional string device_name = 3;
void SendTensorOp::clear_device_name() {
  device_name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& SendTensorOp::device_name() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.SendTensorOp.device_name)
  return device_name_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void SendTensorOp::set_device_name(const ::std::string& value) {
  
  device_name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.eager.SendTensorOp.device_name)
}
 void SendTensorOp::set_device_name(const char* value) {
  
  device_name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.eager.SendTensorOp.device_name)
}
 void SendTensorOp::set_device_name(const char* value, size_t size) {
  
  device_name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.eager.SendTensorOp.device_name)
}
 ::std::string* SendTensorOp::mutable_device_name() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.SendTensorOp.device_name)
  return device_name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* SendTensorOp::release_device_name() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.SendTensorOp.device_name)
  
  return device_name_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void SendTensorOp::set_allocated_device_name(::std::string* device_name) {
  if (device_name != NULL) {
    
  } else {
    
  }
  device_name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), device_name);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.SendTensorOp.device_name)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SendPackedHandleOp_LocalTensorHandle::kTensorFieldNumber;
const int SendPackedHandleOp_LocalTensorHandle::kDeviceFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SendPackedHandleOp_LocalTensorHandle::SendPackedHandleOp_LocalTensorHandle()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
}

void SendPackedHandleOp_LocalTensorHandle::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  tensor_ = const_cast< ::tensorflow::TensorProto*>(&::tensorflow::TensorProto::default_instance());
}

SendPackedHandleOp_LocalTensorHandle::SendPackedHandleOp_LocalTensorHandle(const SendPackedHandleOp_LocalTensorHandle& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
}

void SendPackedHandleOp_LocalTensorHandle::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  tensor_ = NULL;
  device_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

SendPackedHandleOp_LocalTensorHandle::~SendPackedHandleOp_LocalTensorHandle() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  SharedDtor();
}

void SendPackedHandleOp_LocalTensorHandle::SharedDtor() {
  device_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
    delete tensor_;
  }
}

void SendPackedHandleOp_LocalTensorHandle::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SendPackedHandleOp_LocalTensorHandle::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return SendPackedHandleOp_LocalTensorHandle_descriptor_;
}

const SendPackedHandleOp_LocalTensorHandle& SendPackedHandleOp_LocalTensorHandle::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

SendPackedHandleOp_LocalTensorHandle* SendPackedHandleOp_LocalTensorHandle::default_instance_ = NULL;

SendPackedHandleOp_LocalTensorHandle* SendPackedHandleOp_LocalTensorHandle::New(::google::protobuf::Arena* arena) const {
  SendPackedHandleOp_LocalTensorHandle* n = new SendPackedHandleOp_LocalTensorHandle;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SendPackedHandleOp_LocalTensorHandle::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  if (GetArenaNoVirtual() == NULL && tensor_ != NULL) delete tensor_;
  tensor_ = NULL;
  device_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

bool SendPackedHandleOp_LocalTensorHandle::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.TensorProto tensor = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_tensor()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_device;
        break;
      }

      // optional string device = 2;
      case 2: {
        if (tag == 18) {
         parse_device:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_device()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->device().data(), this->device().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.device"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  return false;
#undef DO_
}

void SendPackedHandleOp_LocalTensorHandle::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  // optional .tensorflow.TensorProto tensor = 1;
  if (this->has_tensor()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->tensor_, output);
  }

  // optional string device = 2;
  if (this->device().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device().data(), this->device().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.device");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      2, this->device(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
}

::google::protobuf::uint8* SendPackedHandleOp_LocalTensorHandle::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  // optional .tensorflow.TensorProto tensor = 1;
  if (this->has_tensor()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->tensor_, false, target);
  }

  // optional string device = 2;
  if (this->device().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device().data(), this->device().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.device");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        2, this->device(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  return target;
}

int SendPackedHandleOp_LocalTensorHandle::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  int total_size = 0;

  // optional .tensorflow.TensorProto tensor = 1;
  if (this->has_tensor()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->tensor_);
  }

  // optional string device = 2;
  if (this->device().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->device());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SendPackedHandleOp_LocalTensorHandle::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const SendPackedHandleOp_LocalTensorHandle* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const SendPackedHandleOp_LocalTensorHandle>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
    MergeFrom(*source);
  }
}

void SendPackedHandleOp_LocalTensorHandle::MergeFrom(const SendPackedHandleOp_LocalTensorHandle& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  if (from.has_tensor()) {
    mutable_tensor()->::tensorflow::TensorProto::MergeFrom(from.tensor());
  }
  if (from.device().size() > 0) {

    device_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.device_);
  }
}

void SendPackedHandleOp_LocalTensorHandle::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SendPackedHandleOp_LocalTensorHandle::CopyFrom(const SendPackedHandleOp_LocalTensorHandle& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SendPackedHandleOp_LocalTensorHandle::IsInitialized() const {

  return true;
}

void SendPackedHandleOp_LocalTensorHandle::Swap(SendPackedHandleOp_LocalTensorHandle* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SendPackedHandleOp_LocalTensorHandle::InternalSwap(SendPackedHandleOp_LocalTensorHandle* other) {
  std::swap(tensor_, other->tensor_);
  device_.Swap(&other->device_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SendPackedHandleOp_LocalTensorHandle::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = SendPackedHandleOp_LocalTensorHandle_descriptor_;
  metadata.reflection = SendPackedHandleOp_LocalTensorHandle_reflection_;
  return metadata;
}


// -------------------------------------------------------------------

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SendPackedHandleOp_Handle::kLocalHandleFieldNumber;
const int SendPackedHandleOp_Handle::kRemoteHandleFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SendPackedHandleOp_Handle::SendPackedHandleOp_Handle()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.SendPackedHandleOp.Handle)
}

void SendPackedHandleOp_Handle::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  SendPackedHandleOp_Handle_default_oneof_instance_->local_handle_ = const_cast< ::tensorflow::eager::SendPackedHandleOp_LocalTensorHandle*>(&::tensorflow::eager::SendPackedHandleOp_LocalTensorHandle::default_instance());
  SendPackedHandleOp_Handle_default_oneof_instance_->remote_handle_ = const_cast< ::tensorflow::eager::RemoteTensorHandle*>(&::tensorflow::eager::RemoteTensorHandle::default_instance());
}

SendPackedHandleOp_Handle::SendPackedHandleOp_Handle(const SendPackedHandleOp_Handle& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.SendPackedHandleOp.Handle)
}

void SendPackedHandleOp_Handle::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  clear_has_item();
}

SendPackedHandleOp_Handle::~SendPackedHandleOp_Handle() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.SendPackedHandleOp.Handle)
  SharedDtor();
}

void SendPackedHandleOp_Handle::SharedDtor() {
  if (has_item()) {
    clear_item();
  }
  if (this != default_instance_) {
  }
}

void SendPackedHandleOp_Handle::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SendPackedHandleOp_Handle::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return SendPackedHandleOp_Handle_descriptor_;
}

const SendPackedHandleOp_Handle& SendPackedHandleOp_Handle::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

SendPackedHandleOp_Handle* SendPackedHandleOp_Handle::default_instance_ = NULL;

SendPackedHandleOp_Handle* SendPackedHandleOp_Handle::New(::google::protobuf::Arena* arena) const {
  SendPackedHandleOp_Handle* n = new SendPackedHandleOp_Handle;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SendPackedHandleOp_Handle::clear_item() {
// @@protoc_insertion_point(one_of_clear_start:tensorflow.eager.SendPackedHandleOp.Handle)
  switch(item_case()) {
    case kLocalHandle: {
      delete item_.local_handle_;
      break;
    }
    case kRemoteHandle: {
      delete item_.remote_handle_;
      break;
    }
    case ITEM_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = ITEM_NOT_SET;
}


void SendPackedHandleOp_Handle::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.SendPackedHandleOp.Handle)
  clear_item();
}

bool SendPackedHandleOp_Handle::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.SendPackedHandleOp.Handle)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.eager.SendPackedHandleOp.LocalTensorHandle local_handle = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_local_handle()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_remote_handle;
        break;
      }

      // optional .tensorflow.eager.RemoteTensorHandle remote_handle = 2;
      case 2: {
        if (tag == 18) {
         parse_remote_handle:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_remote_handle()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.SendPackedHandleOp.Handle)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.SendPackedHandleOp.Handle)
  return false;
#undef DO_
}

void SendPackedHandleOp_Handle::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.SendPackedHandleOp.Handle)
  // optional .tensorflow.eager.SendPackedHandleOp.LocalTensorHandle local_handle = 1;
  if (has_local_handle()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *item_.local_handle_, output);
  }

  // optional .tensorflow.eager.RemoteTensorHandle remote_handle = 2;
  if (has_remote_handle()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *item_.remote_handle_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.SendPackedHandleOp.Handle)
}

::google::protobuf::uint8* SendPackedHandleOp_Handle::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.SendPackedHandleOp.Handle)
  // optional .tensorflow.eager.SendPackedHandleOp.LocalTensorHandle local_handle = 1;
  if (has_local_handle()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *item_.local_handle_, false, target);
  }

  // optional .tensorflow.eager.RemoteTensorHandle remote_handle = 2;
  if (has_remote_handle()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *item_.remote_handle_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.SendPackedHandleOp.Handle)
  return target;
}

int SendPackedHandleOp_Handle::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.SendPackedHandleOp.Handle)
  int total_size = 0;

  switch (item_case()) {
    // optional .tensorflow.eager.SendPackedHandleOp.LocalTensorHandle local_handle = 1;
    case kLocalHandle: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *item_.local_handle_);
      break;
    }
    // optional .tensorflow.eager.RemoteTensorHandle remote_handle = 2;
    case kRemoteHandle: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *item_.remote_handle_);
      break;
    }
    case ITEM_NOT_SET: {
      break;
    }
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SendPackedHandleOp_Handle::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.SendPackedHandleOp.Handle)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const SendPackedHandleOp_Handle* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const SendPackedHandleOp_Handle>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.SendPackedHandleOp.Handle)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.SendPackedHandleOp.Handle)
    MergeFrom(*source);
  }
}

void SendPackedHandleOp_Handle::MergeFrom(const SendPackedHandleOp_Handle& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.SendPackedHandleOp.Handle)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  switch (from.item_case()) {
    case kLocalHandle: {
      mutable_local_handle()->::tensorflow::eager::SendPackedHandleOp_LocalTensorHandle::MergeFrom(from.local_handle());
      break;
    }
    case kRemoteHandle: {
      mutable_remote_handle()->::tensorflow::eager::RemoteTensorHandle::MergeFrom(from.remote_handle());
      break;
    }
    case ITEM_NOT_SET: {
      break;
    }
  }
}

void SendPackedHandleOp_Handle::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.SendPackedHandleOp.Handle)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SendPackedHandleOp_Handle::CopyFrom(const SendPackedHandleOp_Handle& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.SendPackedHandleOp.Handle)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SendPackedHandleOp_Handle::IsInitialized() const {

  return true;
}

void SendPackedHandleOp_Handle::Swap(SendPackedHandleOp_Handle* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SendPackedHandleOp_Handle::InternalSwap(SendPackedHandleOp_Handle* other) {
  std::swap(item_, other->item_);
  std::swap(_oneof_case_[0], other->_oneof_case_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SendPackedHandleOp_Handle::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = SendPackedHandleOp_Handle_descriptor_;
  metadata.reflection = SendPackedHandleOp_Handle_reflection_;
  return metadata;
}


// -------------------------------------------------------------------

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SendPackedHandleOp::kOpIdFieldNumber;
const int SendPackedHandleOp::kHandlesFieldNumber;
const int SendPackedHandleOp::kDeviceNameFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SendPackedHandleOp::SendPackedHandleOp()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.eager.SendPackedHandleOp)
}

void SendPackedHandleOp::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

SendPackedHandleOp::SendPackedHandleOp(const SendPackedHandleOp& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.eager.SendPackedHandleOp)
}

void SendPackedHandleOp::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  op_id_ = GOOGLE_LONGLONG(0);
  device_name_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

SendPackedHandleOp::~SendPackedHandleOp() {
  // @@protoc_insertion_point(destructor:tensorflow.eager.SendPackedHandleOp)
  SharedDtor();
}

void SendPackedHandleOp::SharedDtor() {
  device_name_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
  }
}

void SendPackedHandleOp::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SendPackedHandleOp::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return SendPackedHandleOp_descriptor_;
}

const SendPackedHandleOp& SendPackedHandleOp::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2feager_5fservice_2eproto();
  return *default_instance_;
}

SendPackedHandleOp* SendPackedHandleOp::default_instance_ = NULL;

SendPackedHandleOp* SendPackedHandleOp::New(::google::protobuf::Arena* arena) const {
  SendPackedHandleOp* n = new SendPackedHandleOp;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SendPackedHandleOp::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.eager.SendPackedHandleOp)
  op_id_ = GOOGLE_LONGLONG(0);
  device_name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  handles_.Clear();
}

bool SendPackedHandleOp::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.eager.SendPackedHandleOp)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int64 op_id = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &op_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_handles;
        break;
      }

      // repeated .tensorflow.eager.SendPackedHandleOp.Handle handles = 2;
      case 2: {
        if (tag == 18) {
         parse_handles:
          DO_(input->IncrementRecursionDepth());
         parse_loop_handles:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_handles()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_loop_handles;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(26)) goto parse_device_name;
        break;
      }

      // optional string device_name = 3;
      case 3: {
        if (tag == 26) {
         parse_device_name:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_device_name()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->device_name().data(), this->device_name().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.eager.SendPackedHandleOp.device_name"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.eager.SendPackedHandleOp)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.eager.SendPackedHandleOp)
  return false;
#undef DO_
}

void SendPackedHandleOp::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.eager.SendPackedHandleOp)
  // optional int64 op_id = 1;
  if (this->op_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(1, this->op_id(), output);
  }

  // repeated .tensorflow.eager.SendPackedHandleOp.Handle handles = 2;
  for (unsigned int i = 0, n = this->handles_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->handles(i), output);
  }

  // optional string device_name = 3;
  if (this->device_name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device_name().data(), this->device_name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.eager.SendPackedHandleOp.device_name");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      3, this->device_name(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.eager.SendPackedHandleOp)
}

::google::protobuf::uint8* SendPackedHandleOp::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.eager.SendPackedHandleOp)
  // optional int64 op_id = 1;
  if (this->op_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(1, this->op_id(), target);
  }

  // repeated .tensorflow.eager.SendPackedHandleOp.Handle handles = 2;
  for (unsigned int i = 0, n = this->handles_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, this->handles(i), false, target);
  }

  // optional string device_name = 3;
  if (this->device_name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device_name().data(), this->device_name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.eager.SendPackedHandleOp.device_name");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        3, this->device_name(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.eager.SendPackedHandleOp)
  return target;
}

int SendPackedHandleOp::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.eager.SendPackedHandleOp)
  int total_size = 0;

  // optional int64 op_id = 1;
  if (this->op_id() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->op_id());
  }

  // optional string device_name = 3;
  if (this->device_name().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->device_name());
  }

  // repeated .tensorflow.eager.SendPackedHandleOp.Handle handles = 2;
  total_size += 1 * this->handles_size();
  for (int i = 0; i < this->handles_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->handles(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SendPackedHandleOp::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.eager.SendPackedHandleOp)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  const SendPackedHandleOp* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const SendPackedHandleOp>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.eager.SendPackedHandleOp)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.eager.SendPackedHandleOp)
    MergeFrom(*source);
  }
}

void SendPackedHandleOp::MergeFrom(const SendPackedHandleOp& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.eager.SendPackedHandleOp)
  if (GOOGLE_PREDICT_FALSE(&from == this)) {
    ::google::protobuf::internal::MergeFromFail(__FILE__, __LINE__);
  }
  handles_.MergeFrom(from.handles_);
  if (from.op_id() != 0) {
    set_op_id(from.op_id());
  }
  if (from.device_name().size() > 0) {

    device_name_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.device_name_);
  }
}

void SendPackedHandleOp::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.eager.SendPackedHandleOp)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SendPackedHandleOp::CopyFrom(const SendPackedHandleOp& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.eager.SendPackedHandleOp)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SendPackedHandleOp::IsInitialized() const {

  return true;
}

void SendPackedHandleOp::Swap(SendPackedHandleOp* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SendPackedHandleOp::InternalSwap(SendPackedHandleOp* other) {
  std::swap(op_id_, other->op_id_);
  handles_.UnsafeArenaSwap(&other->handles_);
  device_name_.Swap(&other->device_name_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SendPackedHandleOp::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = SendPackedHandleOp_descriptor_;
  metadata.reflection = SendPackedHandleOp_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SendPackedHandleOp_LocalTensorHandle

// optional .tensorflow.TensorProto tensor = 1;
bool SendPackedHandleOp_LocalTensorHandle::has_tensor() const {
  return !_is_default_instance_ && tensor_ != NULL;
}
void SendPackedHandleOp_LocalTensorHandle::clear_tensor() {
  if (GetArenaNoVirtual() == NULL && tensor_ != NULL) delete tensor_;
  tensor_ = NULL;
}
const ::tensorflow::TensorProto& SendPackedHandleOp_LocalTensorHandle::tensor() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.tensor)
  return tensor_ != NULL ? *tensor_ : *default_instance_->tensor_;
}
::tensorflow::TensorProto* SendPackedHandleOp_LocalTensorHandle::mutable_tensor() {
  
  if (tensor_ == NULL) {
    tensor_ = new ::tensorflow::TensorProto;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.tensor)
  return tensor_;
}
::tensorflow::TensorProto* SendPackedHandleOp_LocalTensorHandle::release_tensor() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.tensor)
  
  ::tensorflow::TensorProto* temp = tensor_;
  tensor_ = NULL;
  return temp;
}
void SendPackedHandleOp_LocalTensorHandle::set_allocated_tensor(::tensorflow::TensorProto* tensor) {
  delete tensor_;
  if (tensor != NULL && tensor->GetArena() != NULL) {
    ::tensorflow::TensorProto* new_tensor = new ::tensorflow::TensorProto;
    new_tensor->CopyFrom(*tensor);
    tensor = new_tensor;
  }
  tensor_ = tensor;
  if (tensor) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.tensor)
}

// optional string device = 2;
void SendPackedHandleOp_LocalTensorHandle::clear_device() {
  device_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& SendPackedHandleOp_LocalTensorHandle::device() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.device)
  return device_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void SendPackedHandleOp_LocalTensorHandle::set_device(const ::std::string& value) {
  
  device_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.device)
}
 void SendPackedHandleOp_LocalTensorHandle::set_device(const char* value) {
  
  device_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.device)
}
 void SendPackedHandleOp_LocalTensorHandle::set_device(const char* value, size_t size) {
  
  device_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.device)
}
 ::std::string* SendPackedHandleOp_LocalTensorHandle::mutable_device() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.device)
  return device_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* SendPackedHandleOp_LocalTensorHandle::release_device() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.device)
  
  return device_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void SendPackedHandleOp_LocalTensorHandle::set_allocated_device(::std::string* device) {
  if (device != NULL) {
    
  } else {
    
  }
  device_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), device);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.SendPackedHandleOp.LocalTensorHandle.device)
}

// -------------------------------------------------------------------

// SendPackedHandleOp_Handle

// optional .tensorflow.eager.SendPackedHandleOp.LocalTensorHandle local_handle = 1;
bool SendPackedHandleOp_Handle::has_local_handle() const {
  return item_case() == kLocalHandle;
}
void SendPackedHandleOp_Handle::set_has_local_handle() {
  _oneof_case_[0] = kLocalHandle;
}
void SendPackedHandleOp_Handle::clear_local_handle() {
  if (has_local_handle()) {
    delete item_.local_handle_;
    clear_has_item();
  }
}
 const ::tensorflow::eager::SendPackedHandleOp_LocalTensorHandle& SendPackedHandleOp_Handle::local_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.SendPackedHandleOp.Handle.local_handle)
  return has_local_handle()
      ? *item_.local_handle_
      : ::tensorflow::eager::SendPackedHandleOp_LocalTensorHandle::default_instance();
}
::tensorflow::eager::SendPackedHandleOp_LocalTensorHandle* SendPackedHandleOp_Handle::mutable_local_handle() {
  if (!has_local_handle()) {
    clear_item();
    set_has_local_handle();
    item_.local_handle_ = new ::tensorflow::eager::SendPackedHandleOp_LocalTensorHandle;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.SendPackedHandleOp.Handle.local_handle)
  return item_.local_handle_;
}
::tensorflow::eager::SendPackedHandleOp_LocalTensorHandle* SendPackedHandleOp_Handle::release_local_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.SendPackedHandleOp.Handle.local_handle)
  if (has_local_handle()) {
    clear_has_item();
    ::tensorflow::eager::SendPackedHandleOp_LocalTensorHandle* temp = item_.local_handle_;
    item_.local_handle_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void SendPackedHandleOp_Handle::set_allocated_local_handle(::tensorflow::eager::SendPackedHandleOp_LocalTensorHandle* local_handle) {
  clear_item();
  if (local_handle) {
    set_has_local_handle();
    item_.local_handle_ = local_handle;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.SendPackedHandleOp.Handle.local_handle)
}

// optional .tensorflow.eager.RemoteTensorHandle remote_handle = 2;
bool SendPackedHandleOp_Handle::has_remote_handle() const {
  return item_case() == kRemoteHandle;
}
void SendPackedHandleOp_Handle::set_has_remote_handle() {
  _oneof_case_[0] = kRemoteHandle;
}
void SendPackedHandleOp_Handle::clear_remote_handle() {
  if (has_remote_handle()) {
    delete item_.remote_handle_;
    clear_has_item();
  }
}
 const ::tensorflow::eager::RemoteTensorHandle& SendPackedHandleOp_Handle::remote_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.SendPackedHandleOp.Handle.remote_handle)
  return has_remote_handle()
      ? *item_.remote_handle_
      : ::tensorflow::eager::RemoteTensorHandle::default_instance();
}
::tensorflow::eager::RemoteTensorHandle* SendPackedHandleOp_Handle::mutable_remote_handle() {
  if (!has_remote_handle()) {
    clear_item();
    set_has_remote_handle();
    item_.remote_handle_ = new ::tensorflow::eager::RemoteTensorHandle;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.SendPackedHandleOp.Handle.remote_handle)
  return item_.remote_handle_;
}
::tensorflow::eager::RemoteTensorHandle* SendPackedHandleOp_Handle::release_remote_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.SendPackedHandleOp.Handle.remote_handle)
  if (has_remote_handle()) {
    clear_has_item();
    ::tensorflow::eager::RemoteTensorHandle* temp = item_.remote_handle_;
    item_.remote_handle_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void SendPackedHandleOp_Handle::set_allocated_remote_handle(::tensorflow::eager::RemoteTensorHandle* remote_handle) {
  clear_item();
  if (remote_handle) {
    if (static_cast< ::tensorflow::eager::RemoteTensorHandle*>(remote_handle)->GetArena() != NULL) {
      ::tensorflow::eager::RemoteTensorHandle* new_remote_handle = new ::tensorflow::eager::RemoteTensorHandle;
      new_remote_handle->CopyFrom(*remote_handle);
      remote_handle = new_remote_handle;
    }
    set_has_remote_handle();
    item_.remote_handle_ = remote_handle;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.SendPackedHandleOp.Handle.remote_handle)
}

bool SendPackedHandleOp_Handle::has_item() const {
  return item_case() != ITEM_NOT_SET;
}
void SendPackedHandleOp_Handle::clear_has_item() {
  _oneof_case_[0] = ITEM_NOT_SET;
}
SendPackedHandleOp_Handle::ItemCase SendPackedHandleOp_Handle::item_case() const {
  return SendPackedHandleOp_Handle::ItemCase(_oneof_case_[0]);
}
// -------------------------------------------------------------------

// SendPackedHandleOp

// optional int64 op_id = 1;
void SendPackedHandleOp::clear_op_id() {
  op_id_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 SendPackedHandleOp::op_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.SendPackedHandleOp.op_id)
  return op_id_;
}
 void SendPackedHandleOp::set_op_id(::google::protobuf::int64 value) {
  
  op_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.eager.SendPackedHandleOp.op_id)
}

// repeated .tensorflow.eager.SendPackedHandleOp.Handle handles = 2;
int SendPackedHandleOp::handles_size() const {
  return handles_.size();
}
void SendPackedHandleOp::clear_handles() {
  handles_.Clear();
}
const ::tensorflow::eager::SendPackedHandleOp_Handle& SendPackedHandleOp::handles(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.SendPackedHandleOp.handles)
  return handles_.Get(index);
}
::tensorflow::eager::SendPackedHandleOp_Handle* SendPackedHandleOp::mutable_handles(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.SendPackedHandleOp.handles)
  return handles_.Mutable(index);
}
::tensorflow::eager::SendPackedHandleOp_Handle* SendPackedHandleOp::add_handles() {
  // @@protoc_insertion_point(field_add:tensorflow.eager.SendPackedHandleOp.handles)
  return handles_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::eager::SendPackedHandleOp_Handle >*
SendPackedHandleOp::mutable_handles() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.eager.SendPackedHandleOp.handles)
  return &handles_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::eager::SendPackedHandleOp_Handle >&
SendPackedHandleOp::handles() const {
  // @@protoc_insertion_point(field_list:tensorflow.eager.SendPackedHandleOp.handles)
  return handles_;
}

// optional string device_name = 3;
void SendPackedHandleOp::clear_device_name() {
  device_name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& SendPackedHandleOp::device_name() const {
  // @@protoc_insertion_point(field_get:tensorflow.eager.SendPackedHandleOp.device_name)
  return device_name_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void SendPackedHandleOp::set_device_name(const ::std::string& value) {
  
  device_name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.eager.SendPackedHandleOp.device_name)
}
 void SendPackedHandleOp::set_device_name(const char* value) {
  
  device_name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.eager.SendPackedHandleOp.device_name)
}
 void SendPackedHandleOp::set_device_name(const char* value, size_t size) {
  
  device_name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.eager.SendPackedHandleOp.device_name)
}
 ::std::string* SendPackedHandleOp::mutable_device_name() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.eager.SendPackedHandleOp.device_name)
  return device_name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* SendPackedHandleOp::release_device_name() {
  // @@protoc_insertion_point(field_release:tensorflow.eager.SendPackedHandleOp.device_name)
  
  return device_name_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void SendPackedHandleOp::set_allocated_device_name(::std::string* device_name) {
  if (device_name != NULL) {
    
  } else {
    
  }
  device_name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), device_name);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.eager.SendPackedHandleOp.device_name)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace eager
}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
